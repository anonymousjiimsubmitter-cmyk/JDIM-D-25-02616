{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c15be28-a556-4abe-a87c-235d18a2f19a",
   "metadata": {},
   "source": [
    "# Running External Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "761f0aac-6b85-432e-acaf-ff019f1470b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from timm import create_model\n",
    "import sys, os, json\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_recall_curve, auc, roc_curve\n",
    "from scipy.special import expit #Note: this is a stable implementation of sigmoid\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from run_external_validation import load_dataset, PercentileDomainAdaptation, XrayDataset\n",
    "\n",
    "seed_value = 9999 # setting seed for bootstrapping reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d24e0fb9-4a49-478d-b2cf-111b5020d17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results: 12\n"
     ]
    }
   ],
   "source": [
    "choiPath = '/extra/xielab0/nhchoi1/xrays/'\n",
    "with open(choiPath+\"grid_winners-weights.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "print(\"Model results:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4677656e-ee62-422f-9f6c-0444c812576d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grid_idx': 6,\n",
       " 'name': 'convnextv2_nano',\n",
       " 'weight_decay': 2.5,\n",
       " 'mean': 0.8381306010457822,\n",
       " 'std': 0.09031020512304658,\n",
       " 'logits': 'weight_decay_large/convnextv2_nano/objects/logits/0-fold-logits.pth',\n",
       " 'weights': ['weight_decay_large/convnextv2_nano/objects/checkpoints/0-fold-0-state.pth',\n",
       "  'weight_decay_large/convnextv2_nano/objects/checkpoints/0-fold-1-state.pth',\n",
       "  'weight_decay_large/convnextv2_nano/objects/checkpoints/0-fold-2-state.pth',\n",
       "  'weight_decay_large/convnextv2_nano/objects/checkpoints/0-fold-3-state.pth',\n",
       "  'weight_decay_large/convnextv2_nano/objects/checkpoints/0-fold-4-state.pth']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bc00773-735c-4be2-8949-7c44d5acb3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = np.load(r\"/extra/xielab0/wuat2/AryaQualityViewProjectData/ExternalValData/file_paths.npy\")\n",
    "labels = np.load(r\"/extra/xielab0/wuat2/AryaQualityViewProjectData/ExternalValData/labels.npy\")\n",
    "trPercentiles = np.load(r\"/extra/xielab0/wuat2/AryaQualityViewProjectData/ExternalValData/trainClamp1-99Range.npy\")\n",
    "config_path = r\"/extra/xielab0/wuat2/AryaQualityViewProjectData/ExternalValData/ext_val_torch_loader_config.json\"\n",
    "\n",
    "with open(config_path) as f:\n",
    "        cfg = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21fecfb6-1c48-4cdd-a3b1-08420ef27246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior external validation results loaded for analysis.\n"
     ]
    }
   ],
   "source": [
    "runInference = False\n",
    "\n",
    "if not runInference: #load previously saved results if inference not rerun\n",
    "    results = torch.load(\"external_validation_results.pt\")\n",
    "    print(\"prior external validation results loaded for analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c405574-0d23-4553-8c9e-af376b1918e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runInference not enabled. Please enable if this was not intended.\n"
     ]
    }
   ],
   "source": [
    "def adapt_batch_norm(model, data_loader, device):\n",
    "    model.train()  # Update BN, but not step optimizer (no gradients)\n",
    "    \n",
    "    print(\"Adapting Batch Norm statistics to external domain...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, _ in data_loader:\n",
    "            x = x.to(device)\n",
    "            _ = model(x) \n",
    "            \n",
    "    print(\"Adaptation complete.\")\n",
    "    model.eval() # Switch back to eval for actual prediction\n",
    "    return model\n",
    "\n",
    "def safe_generator(iterable):\n",
    "    iterator = iter(iterable)\n",
    "    while True:\n",
    "        try:\n",
    "            yield next(iterator)\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Skipping corrupt batch/image: {e}\")\n",
    "            continue\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "def create_actual_model(model_name, num_classes=1):\n",
    "    model = create_model(\n",
    "        model_name,\n",
    "        pretrained=False, num_classes=1\n",
    "    ).to(device).eval()\n",
    "    return model\n",
    "        \n",
    "if runInference:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")    \n",
    "    results = []\n",
    "    \n",
    "    for pick in data:\n",
    "        # Build paths dynamically based on your logic\n",
    "        try:\n",
    "            logits_path_str = pick[\"logits\"]\n",
    "            idx = logits_path_str.index(\"objects/\")\n",
    "            objects_path = logits_path_str[:idx] + \"objects/\"\n",
    "        except (ValueError, KeyError):\n",
    "            print(\"Could not find 'objects/' in path, skipping this pick.\")\n",
    "            continue\n",
    "    \n",
    "        # Load JSON settings\n",
    "        try:\n",
    "            with open(os.path.join(objects_path, \"0-dataset_settings.json\"), \"r\") as f:\n",
    "                settings = json.load(f)\n",
    "            with open(os.path.join(objects_path, \"0-model_details.json\"), \"r\") as f:\n",
    "                model_details = json.load(f)\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Metadata file missing: {e}\")\n",
    "            continue\n",
    "    \n",
    "        # Prepare Data\n",
    "        image_size = settings[\"image_size\"][0]\n",
    "        \n",
    "        test_transformer = transforms.Compose([\n",
    "                transforms.Resize((image_size, image_size), antialias=True),\n",
    "                transforms.ConvertImageDtype(torch.float32), #float conversion\n",
    "                PercentileDomainAdaptation(trPercentiles[0], trPercentiles[1]),\n",
    "            ])\n",
    "        \n",
    "        dataset, loader = load_dataset(image_size, test_transform = test_transformer)\n",
    "        \n",
    "        # Initialize Model\n",
    "        print(f\"\\n--- Loading Model: {model_details['model_name']} ---\")\n",
    "        model = create_actual_model(model_details[\"model_name\"]).to(device)\n",
    "        model.eval()\n",
    "    \n",
    "        pick[\"external_validation_results\"] = []\n",
    "    \n",
    "        # Iterate through weight checkpoints\n",
    "        for weight_file in pick.get(\"weights\", []):\n",
    "            full_weight_path = os.path.join(choiPath, weight_file)\n",
    "            \n",
    "            if not os.path.exists(full_weight_path):\n",
    "                print(f\"Weight file not found: {full_weight_path}\")\n",
    "                continue\n",
    "    \n",
    "            # Map location ensures weights load to the correct device\n",
    "            state_dict = torch.load(full_weight_path, map_location=device)\n",
    "            model.load_state_dict(state_dict)\n",
    "            print(f\"Loaded weights: {weight_file}\")\n",
    "            \n",
    "            y_logits = []\n",
    "            model = adapt_batch_norm(model, loader, device) #adapting batch normalization\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for x, _ in loader:\n",
    "                # for x, _ in safe_generator(loader):\n",
    "                    x = x.to(device)\n",
    "                    output = model(x)\n",
    "                    \n",
    "                    # Assuming binary/regression (output shape [batch, 1])\n",
    "                    y_logits.extend(output.view(-1).cpu().numpy())\n",
    "    \n",
    "            # Save results for this weight set\n",
    "            pick[\"external_validation_results\"].append(np.array(y_logits))\n",
    "    \n",
    "        results.append(pick)\n",
    "    \n",
    "    # --- 5. Final Save ---\n",
    "    if results:\n",
    "        torch.save(results, \"external_validation_results.pt\")\n",
    "        print(\"\\nProcessing complete. Results saved.\")\n",
    "    else:\n",
    "        print(\"\\nNo results generated.\")\n",
    "else:\n",
    "    print('runInference not enabled. Please enable if this was not intended.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb5fd9a9-9bc2-4742-8381-b845d0c87f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting random seed and bootstrapping indices. For reproducibility, only run this ONCE. \n",
      "If accidentally ran again, restart kernel and try again.\n",
      "Bootstrapping indices set.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(f\"\"\"Bootstrapping variable already set (value={needBootStrapping}). Are you sure you didn't already run this?\n",
    "bootstrap indices are stored in 'bootStrapIdxs'.\"\"\")\n",
    "\n",
    "except:\n",
    "    needBootStrapping = True\n",
    "    rng = np.random.default_rng(seed=seed_value)\n",
    "    B = 5000\n",
    "    bootStrapIdxs = []\n",
    "    extValSize = len(labels)\n",
    "    \n",
    "    if needBootStrapping:\n",
    "        print(\"\"\"setting random seed and bootstrapping indices. For reproducibility, only run this ONCE. \n",
    "If accidentally ran again, restart kernel and try again.\"\"\")\n",
    "        for _ in range(B):\n",
    "            idx = np.random.randint(0, extValSize, extValSize)\n",
    "            while True:\n",
    "                if len(np.unique(labels[idx])) == 2:\n",
    "                    break #if samples only have one label, try again\n",
    "                idx = np.random.randint(0, extValSize, extValSize)\n",
    "            bootStrapIdxs.append(idx)\n",
    "        print(\"Bootstrapping indices set.\")\n",
    "    else:\n",
    "        print(\"Bootstrapping not enabled. Remember, only run this ONCE in script for reproducibility.\")\n",
    "    needBootstrapping = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99da5f83-2599-4ea5-bd6c-afab594f6d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext_val_metrics(y_true, probs, target_value=0.90): # sensitivity at specificity and vice versa and PR/ROC AUCs\n",
    "\n",
    "    fpr, tpr, roc_thresh = roc_curve(y_true, probs)\n",
    "    precision, recall, pr_thresh = precision_recall_curve(y_true, probs)\n",
    "    rocAUC = roc_auc_score(y_true, probs)\n",
    "    prAUC = auc(recall[::-1], precision[::-1]) #need to flip precision and recall to calculate auc\n",
    "    \n",
    "    target_fpr = 1 - target_value\n",
    "    calculated_sensitivity = np.interp(target_fpr, fpr, tpr)\n",
    "\n",
    "    # Ensure monotonicity for finding specificity at sensitivity\n",
    "    tpr_monotonic, idx = np.unique(tpr, return_index=True)\n",
    "    fpr_at_tpr = fpr[idx]\n",
    "    fpr_at_target = np.interp(target_value, tpr_monotonic, fpr_at_tpr)\n",
    "    calculated_specificity = 1 - fpr_at_target\n",
    "\n",
    "    return rocAUC, prAUC, calculated_sensitivity, calculated_specificity\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da3d13fe-0cc4-4917-af02-55689d966951",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: efficientnetv2_m\n",
      "Int Val ROC AUC: 0.953\n",
      "Ext Test ROC AUC: 0.800\n",
      "Ext Test PR AUC: 0.441\n",
      "Ext Test sens @spec90%: 0.467\n",
      "Ext Test spec @sens90%: 0.533\n",
      "                ----------\n",
      "Fold corr coeff -- mean: 0.753| std dev: 0.051\n",
      "----------\n",
      "Starting Bootstrapping:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_600572/3841849734.py:48: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  bootMetrics = pd.concat([bootMetrics, currMetrics], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocAUC CIs (2.5,97.5): 0.713, 0.876\n",
      "----------\n",
      "prAUC CIs (2.5,97.5): 0.292, 0.647\n",
      "----------\n",
      "sensAtSpec CIs (2.5,97.5): 0.231, 0.656\n",
      "----------\n",
      "specAtSens CIs (2.5,97.5): 0.396, 0.733\n",
      "----------\n",
      "Model name: fastvit_ma36\n",
      "Int Val ROC AUC: 0.976\n",
      "Ext Test ROC AUC: 0.812\n",
      "Ext Test PR AUC: 0.563\n",
      "Ext Test sens @spec90%: 0.433\n",
      "Ext Test spec @sens90%: 0.475\n",
      "                ----------\n",
      "Fold corr coeff -- mean: 0.829| std dev: 0.026\n",
      "----------\n",
      "Starting Bootstrapping:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_600572/3841849734.py:48: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  bootMetrics = pd.concat([bootMetrics, currMetrics], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocAUC CIs (2.5,97.5): 0.722, 0.890\n",
      "----------\n",
      "prAUC CIs (2.5,97.5): 0.374, 0.745\n",
      "----------\n",
      "sensAtSpec CIs (2.5,97.5): 0.261, 0.682\n",
      "----------\n",
      "specAtSens CIs (2.5,97.5): 0.360, 0.755\n",
      "----------\n",
      "Model name: mobilenetv4_conv_large\n",
      "Int Val ROC AUC: 0.944\n",
      "Ext Test ROC AUC: 0.772\n",
      "Ext Test PR AUC: 0.501\n",
      "Ext Test sens @spec90%: 0.533\n",
      "Ext Test spec @sens90%: 0.383\n",
      "                ----------\n",
      "Fold corr coeff -- mean: 0.676| std dev: 0.115\n",
      "----------\n",
      "Starting Bootstrapping:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_600572/3841849734.py:48: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  bootMetrics = pd.concat([bootMetrics, currMetrics], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocAUC CIs (2.5,97.5): 0.663, 0.871\n",
      "----------\n",
      "prAUC CIs (2.5,97.5): 0.323, 0.697\n",
      "----------\n",
      "sensAtSpec CIs (2.5,97.5): 0.333, 0.719\n",
      "----------\n",
      "specAtSens CIs (2.5,97.5): 0.109, 0.700\n",
      "----------\n",
      "Model name: repvit_m3.native\n",
      "Int Val ROC AUC: 0.948\n",
      "Ext Test ROC AUC: 0.832\n",
      "Ext Test PR AUC: 0.603\n",
      "Ext Test sens @spec90%: 0.533\n",
      "Ext Test spec @sens90%: 0.550\n",
      "                ----------\n",
      "Fold corr coeff -- mean: 0.706| std dev: 0.059\n",
      "----------\n",
      "Starting Bootstrapping:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_600572/3841849734.py:48: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  bootMetrics = pd.concat([bootMetrics, currMetrics], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocAUC CIs (2.5,97.5): 0.751, 0.903\n",
      "----------\n",
      "prAUC CIs (2.5,97.5): 0.421, 0.759\n",
      "----------\n",
      "sensAtSpec CIs (2.5,97.5): 0.323, 0.739\n",
      "----------\n",
      "specAtSens CIs (2.5,97.5): 0.455, 0.754\n",
      "----------\n",
      "Model name: resnetv2_34\n",
      "Int Val ROC AUC: 0.959\n",
      "Ext Test ROC AUC: 0.809\n",
      "Ext Test PR AUC: 0.530\n",
      "Ext Test sens @spec90%: 0.500\n",
      "Ext Test spec @sens90%: 0.525\n",
      "                ----------\n",
      "Fold corr coeff -- mean: 0.695| std dev: 0.054\n",
      "----------\n",
      "Starting Bootstrapping:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_600572/3841849734.py:48: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  bootMetrics = pd.concat([bootMetrics, currMetrics], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocAUC CIs (2.5,97.5): 0.719, 0.888\n",
      "----------\n",
      "prAUC CIs (2.5,97.5): 0.344, 0.722\n",
      "----------\n",
      "sensAtSpec CIs (2.5,97.5): 0.300, 0.731\n",
      "----------\n",
      "specAtSens CIs (2.5,97.5): 0.367, 0.712\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "ensembleModels = ['efficientnetv2_m', 'fastvit_ma36', 'mobilenetv4_conv_large', 'repvit_m3.native', 'resnetv2_34']\n",
    "ensembleProb = np.zeros(len(labels))\n",
    "ensembleIndivPreds = []\n",
    "ensembleProbBoot = np.zeros((B, len(labels)))\n",
    "\n",
    "for modelData in results:\n",
    "    if modelData['name'] in ensembleModels:\n",
    "        # probs = expit(modelData['external_validation_results'][0]) #NOTE: this is just looking at one fold\n",
    "        probs = np.zeros(len(labels))\n",
    "        for fold in range(5):\n",
    "            probs = probs + modelData['external_validation_results'][fold]\n",
    "        probs = expit(probs/5) #average of the five folds\n",
    "\n",
    "        rocAUC, prAUC, sensAtSpec, specAtSens = ext_val_metrics(labels, probs, target_value=0.90)\n",
    "        # print(len(modelData['external_validation_results'][0]))\n",
    "        print(f\"\"\"Model name: {modelData['name']}\\nInt Val ROC AUC: {modelData['mean']:.3f}\n",
    "Ext Test ROC AUC: {rocAUC:.3f}\n",
    "Ext Test PR AUC: {prAUC:.3f}\n",
    "Ext Test sens @spec90%: {sensAtSpec:.3f}\n",
    "Ext Test spec @sens90%: {specAtSens:.3f}\n",
    "                ----------\"\"\")\n",
    "        foldSimilarity = []\n",
    "        for i in range(5): #correlation analysis between folds\n",
    "            for j in range(i+1, 5):\n",
    "                p_i = expit(modelData['external_validation_results'][i])\n",
    "                p_j = expit(modelData['external_validation_results'][j])\n",
    "                foldSimilarity.append(np.corrcoef(p_i, p_j)[0,1])\n",
    "        foldSimilarity = np.array(foldSimilarity)\n",
    "        print(f\"Fold corr coeff -- mean: {foldSimilarity.mean():.3f}| std dev: {foldSimilarity.std():.3f}\")\n",
    "\n",
    "        ensembleProb = ensembleProb + probs\n",
    "        ensembleIndivPreds.append(probs)\n",
    "\n",
    "        metricNames = [\"rocAUC\",\"prAUC\",\"sensAtSpec\",\"specAtSens\"]\n",
    "        bootMetrics = pd.DataFrame(columns=metricNames)\n",
    "        print(f\"----------\\nStarting Bootstrapping:\")\n",
    "        for bootNum in range(B):\n",
    "            bootIdx = bootStrapIdxs[bootNum] #indices for this bootstrap\n",
    "            bootLabels = labels[bootIdx]\n",
    "            bootProbs = np.zeros(len(bootLabels))\n",
    "            for fold in range(5):\n",
    "                bootProbs = bootProbs + modelData['external_validation_results'][fold][bootIdx]\n",
    "            bootProbs = expit(bootProbs/5) #average of the five folds\n",
    "            ensembleProbBoot[bootNum] = ensembleProbBoot[bootNum] + bootProbs\n",
    "            \n",
    "            rocAUC, prAUC, sensAtSpec, specAtSens = ext_val_metrics(bootLabels, bootProbs, target_value=0.90)\n",
    "            currMetrics = pd.DataFrame([{\"rocAUC\": rocAUC, \"prAUC\": prAUC, \"sensAtSpec\": sensAtSpec, \"specAtSens\": specAtSens}])\n",
    "            bootMetrics = pd.concat([bootMetrics, currMetrics], ignore_index=True)\n",
    "        # print(bootMetrics)\n",
    "        CIs = pd.DataFrame(columns=metricNames)\n",
    "        for metric in metricNames:\n",
    "            lower = np.percentile(bootMetrics[metric], 2.5)\n",
    "            upper = np.percentile(bootMetrics[metric], 97.5)\n",
    "            CIs[metric] = [lower, upper]\n",
    "            print(f\"{metric} CIs (2.5,97.5): {lower:.3f}, {upper:.3f}\\n----------\")\n",
    "\n",
    "ensembleProbBoot = ensembleProbBoot/len(ensembleModels)\n",
    "ensembleProb = ensembleProb/len(ensembleModels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55decfde-85ff-40eb-b28a-0f27b3c794e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: Ensemble (soft)\n",
      "Ext Test ROC AUC: 0.821\n",
      "Ext Test PR AUC: 0.601\n",
      "Ext Test sens @spec90%: 0.533\n",
      "Ext Test spec @sens90%: 0.433\n",
      "                ----------\n",
      "Fold corr coeff -- mean: 0.813| std dev: 0.044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_600572/748961801.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  ensBootMetrics = pd.concat([ensBootMetrics, currMetrics], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocAUC CIs (2.5,97.5): 0.735, 0.897\n",
      "----------\n",
      "prAUC CIs (2.5,97.5): 0.416, 0.760\n",
      "----------\n",
      "sensAtSpec CIs (2.5,97.5): 0.344, 0.720\n",
      "----------\n",
      "specAtSens CIs (2.5,97.5): 0.356, 0.770\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "rocAUC, prAUC, sensAtSpec, specAtSens = ext_val_metrics(labels, ensembleProb, target_value=0.90)\n",
    "# print(len(modelData['external_validation_results'][0]))\n",
    "print(f\"\"\"Model name: Ensemble (soft)\n",
    "Ext Test ROC AUC: {rocAUC:.3f}\n",
    "Ext Test PR AUC: {prAUC:.3f}\n",
    "Ext Test sens @spec90%: {sensAtSpec:.3f}\n",
    "Ext Test spec @sens90%: {specAtSens:.3f}\n",
    "                ----------\"\"\")\n",
    "foldSimilarity = []\n",
    "for i in range(5): #correlation analysis between folds\n",
    "    for j in range(i+1, 5):\n",
    "        p_i = expit(ensembleIndivPreds[i])\n",
    "        p_j = expit(ensembleIndivPreds[j])\n",
    "        foldSimilarity.append(np.corrcoef(p_i, p_j)[0,1])\n",
    "foldSimilarity = np.array(foldSimilarity)\n",
    "print(f\"Fold corr coeff -- mean: {foldSimilarity.mean():.3f}| std dev: {foldSimilarity.std():.3f}\")\n",
    "\n",
    "metricNames = [\"rocAUC\",\"prAUC\",\"sensAtSpec\",\"specAtSens\"]\n",
    "ensBootMetrics = pd.DataFrame(columns=metricNames)\n",
    "for bootNum in range(B):\n",
    "    bootIdx = bootStrapIdxs[bootNum] #indices for this bootstrap\n",
    "    bootLabels = labels[bootIdx]\n",
    "    \n",
    "    rocAUC, prAUC, sensAtSpec, specAtSens = ext_val_metrics(bootLabels, ensembleProbBoot[bootNum], target_value=0.90)\n",
    "    currMetrics = pd.DataFrame([{\"rocAUC\": rocAUC, \"prAUC\": prAUC, \"sensAtSpec\": sensAtSpec, \"specAtSens\": specAtSens}])\n",
    "    ensBootMetrics = pd.concat([ensBootMetrics, currMetrics], ignore_index=True)\n",
    "\n",
    "bootCIs = pd.DataFrame(columns=metricNames)\n",
    "for metric in metricNames:\n",
    "    lower = np.percentile(ensBootMetrics[metric], 2.5)\n",
    "    upper = np.percentile(ensBootMetrics[metric], 97.5)\n",
    "    bootCIs[metric] = [lower, upper]\n",
    "    print(f\"{metric} CIs (2.5,97.5): {lower:.3f}, {upper:.3f}\\n----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cd25a2-8a41-45f9-a9ee-a2d1350dda5e",
   "metadata": {},
   "source": [
    "# Test Few-shot Learning\n",
    "## 1:2 ratio of fine tuning to true test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15cee364-01e2-40fb-ad91-3a81101e76be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def stratified_fewshot_split(file_paths, labels, n_fewshot=50, seed=9999):\n",
    "    sss = StratifiedShuffleSplit(\n",
    "        n_splits=1,\n",
    "        test_size=len(labels) - n_fewshot,\n",
    "        random_state=seed\n",
    "    )\n",
    "    fewshot_idx, test_idx = next(sss.split(file_paths, labels))\n",
    "\n",
    "    fewshot_paths = [file_paths[i] for i in fewshot_idx]\n",
    "    fewshot_labels = labels[fewshot_idx]\n",
    "\n",
    "    test_paths = [file_paths[i] for i in test_idx]\n",
    "    test_labels = labels[test_idx]\n",
    "\n",
    "    return fewshot_paths, fewshot_labels, test_paths, test_labels\n",
    "    \n",
    "def fewshot_finetune(model, fewshot_loader, device,\n",
    "                     lr=1e-4, epochs=30, pos_weight=4.0):\n",
    "\n",
    "    # Freeze backbone\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"classifier\" not in name and \"head\" not in name:\n",
    "            param.requires_grad = False\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=lr,\n",
    "        weight_decay=1e-4\n",
    "    )\n",
    "\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(\n",
    "        pos_weight=torch.tensor([pos_weight]).to(device)\n",
    "    )\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for x, y in fewshot_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.float().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x).view(-1)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_subset_dataset(image_size, file_paths, labels, batch_size: int = 32, test_transform = None, cfg = None):\n",
    "    dataset = XrayDataset(\n",
    "        file_paths=file_paths,\n",
    "        labels=labels,\n",
    "        transform=test_transform\n",
    "    )\n",
    "    if cfg:\n",
    "        loader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=cfg[\"batch_size\"],\n",
    "            shuffle=cfg[\"shuffle\"],\n",
    "            pin_memory=True\n",
    "        )\n",
    "    else:\n",
    "        loader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            pin_memory=True\n",
    "        )\n",
    "    return dataset, loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b6e2c97-ee83-467b-a789-59060237861c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior few-shot external validation results loaded for analysis.\n"
     ]
    }
   ],
   "source": [
    "runTest = False\n",
    "\n",
    "if not runTest: #load previously saved results if inference not rerun\n",
    "    fewShotResults = torch.load(\"external_validation_fewShotResults.pt\")\n",
    "    print(\"prior few-shot external validation results loaded for analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d4d3f4e-1d73-4998-b0ac-31cab8e09f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fewShotResults not enabled. Did you already load previous results? Please enable if this was not intended.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if runTest:\n",
    "    ensembleModels = ['efficientnetv2_m.in21k_ft_in1k', 'fastvit_ma36.apple_dist_in1k', 'mobilenetv4_conv_large.e600_r384_in1k', \n",
    "                  'repvit_m3.dist_in1k', 'resnetv2_34.ra4_e3600_r224_in1k']\n",
    "    fewShotResults = []\n",
    "\n",
    "    for pick in data:\n",
    "        try:\n",
    "            logits_path_str = pick[\"logits\"]\n",
    "            idx = logits_path_str.index(\"objects/\")\n",
    "            objects_path = logits_path_str[:idx] + \"objects/\"\n",
    "        except (ValueError, KeyError):\n",
    "            print(\"Could not find 'objects/' in path, skipping this pick.\")\n",
    "            continue\n",
    "\n",
    "        # --- Load JSON settings ---\n",
    "        try:\n",
    "            with open(os.path.join(objects_path, \"0-dataset_settings.json\"), \"r\") as f:\n",
    "                settings = json.load(f)\n",
    "            with open(os.path.join(objects_path, \"0-model_details.json\"), \"r\") as f:\n",
    "                model_details = json.load(f)\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Metadata file missing: {e}\")\n",
    "            continue\n",
    "\n",
    "        # --- Initialize model ---\n",
    "        if model_details['model_name'] not in ensembleModels:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n--- Loading Model: {model_details['model_name']} ---\")\n",
    "        model = create_actual_model(model_details[\"model_name\"]).to(device)\n",
    "        model.eval()\n",
    "\n",
    "        image_size = settings[\"image_size\"][0]\n",
    "\n",
    "        test_transformer = transforms.Compose([\n",
    "            transforms.Resize((image_size, image_size), antialias=True),\n",
    "            transforms.ConvertImageDtype(torch.float32),\n",
    "            PercentileDomainAdaptation(trPercentiles[0], trPercentiles[1]),\n",
    "        ])\n",
    "\n",
    "        # --- Load full external dataset ---\n",
    "        full_dataset, full_loader = load_dataset(\n",
    "            image_size,\n",
    "            test_transform=test_transformer\n",
    "        )\n",
    "\n",
    "        file_paths = full_dataset.file_paths\n",
    "        labels = np.array(full_dataset.labels)\n",
    "\n",
    "        # --- Stratified few-shot split ---\n",
    "        fewshot_paths, fewshot_labels, test_paths, test_labels = \\\n",
    "            stratified_fewshot_split(\n",
    "                file_paths,\n",
    "                labels,\n",
    "                n_fewshot=50,\n",
    "                seed=seed_value\n",
    "            )\n",
    "\n",
    "        fewshot_dataset, fewshot_loader = load_subset_dataset(\n",
    "            image_size = image_size,\n",
    "            file_paths = fewshot_paths,\n",
    "            labels = fewshot_labels,\n",
    "            test_transform = test_transformer,\n",
    "            cfg=cfgFewShot\n",
    "        )\n",
    "\n",
    "        test_dataset, test_loader = load_subset_dataset(\n",
    "            image_size = image_size,\n",
    "            file_paths = test_paths,\n",
    "            labels = test_labels,\n",
    "            test_transform = test_transformer,\n",
    "            cfg=cfgFewShot\n",
    "        )\n",
    "\n",
    "        pick[\"external_validation_fewShotResults\"] = []\n",
    "\n",
    "        # --- Iterate through weight checkpoints ---\n",
    "        for weight_file in pick.get(\"weights\", []):\n",
    "            full_weight_path = os.path.join(choiPath, weight_file)\n",
    "\n",
    "            if not os.path.exists(full_weight_path):\n",
    "                print(f\"Weight file not found: {full_weight_path}\")\n",
    "                continue\n",
    "\n",
    "            state_dict = torch.load(full_weight_path, map_location=device)\n",
    "            model.load_state_dict(state_dict)\n",
    "            print(f\"Loaded weights: {weight_file}\")\n",
    "\n",
    "            # --- BN adaptation using ALL external images (unlabeled) ---\n",
    "            model = adapt_batch_norm(model, full_loader, device)\n",
    "\n",
    "            # --- Few-shot head-only fine-tuning ---\n",
    "            pos_weight = (len(labels) - labels.sum()) / labels.sum()  #weighted tuning to account for data imbalance\n",
    "            model = fewshot_finetune(\n",
    "                model,\n",
    "                fewshot_loader,\n",
    "                device,\n",
    "                lr=1e-4,\n",
    "                epochs=30,\n",
    "                pos_weight=pos_weight\n",
    "            )\n",
    "\n",
    "            # --- Predict on HELD-OUT external test subset ---\n",
    "            y_logits = []\n",
    "            with torch.no_grad():\n",
    "                for x, _ in test_loader:\n",
    "                    x = x.to(device)\n",
    "                    output = model(x)\n",
    "                    y_logits.extend(output.view(-1).cpu().numpy())\n",
    "\n",
    "            pick[\"external_validation_fewShotResults\"].append(\n",
    "                np.array(y_logits)\n",
    "            )\n",
    "\n",
    "        fewShotResults.append({\n",
    "            \"name\": model_details[\"model_name\"],\n",
    "            \"fewshot_idx\": fewshot_paths,\n",
    "            \"test_idx\": test_paths,\n",
    "            \"fewshot_labels\": fewshot_labels,\n",
    "            \"test_labels\": test_labels,\n",
    "            \"external_validation_fewShotResults\": pick[\"external_validation_fewShotResults\"],\n",
    "        })\n",
    "\n",
    "    # --- Final Save ---\n",
    "    if fewShotResults:\n",
    "        torch.save(fewShotResults, \"external_validation_fewShotResults.pt\")\n",
    "        print(\"\\nProcessing complete. Few-shot test results saved.\")\n",
    "    else:\n",
    "        print(\"\\nNo results generated.\")\n",
    "\n",
    "else:\n",
    "    print(\"fewShotResults not enabled. Did you already load previous results? Please enable if this was not intended.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ee6d977-7471-492f-9cbb-9fae02b5ed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsFewShot = fewShotResults[0]['test_labels'] #same for every fold and architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5edf51a8-3506-4a2d-a81a-c60705f70f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting random seed and needFewShotBootStrapping indices. For reproducibility, only run this ONCE. \n",
      "If accidentally ran again, restart kernel and try again.\n",
      "needFewShotBootStrapping indices set.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(f\"\"\"Bootstrapping variable already set (value={needFewShotBootStrapping}). Are you sure you didn't already run this?\n",
    "bootstrap indices are stored in 'fewShotBootStrapIdxs'.\"\"\")\n",
    "\n",
    "except:\n",
    "    needFewShotBootStrapping = True\n",
    "    rng = np.random.default_rng(seed=seed_value)\n",
    "    B = 5000\n",
    "    fewShotBootStrapIdxs = []\n",
    "    extFewShotValSize = len(labelsFewShot)\n",
    "    \n",
    "    if needFewShotBootStrapping:\n",
    "        print(\"\"\"setting random seed and needFewShotBootStrapping indices. For reproducibility, only run this ONCE. \n",
    "If accidentally ran again, restart kernel and try again.\"\"\")\n",
    "        for _ in range(B):\n",
    "            idx = np.random.randint(0, extFewShotValSize, extFewShotValSize)\n",
    "            while True:\n",
    "                if len(np.unique(labelsFewShot[idx])) == 2:\n",
    "                    break #if samples only have one label, try again\n",
    "                idx = np.random.randint(0, extFewShotValSize, extFewShotValSize)\n",
    "            fewShotBootStrapIdxs.append(idx)\n",
    "        print(\"needFewShotBootStrapping indices set.\")\n",
    "    else:\n",
    "        print(\"needFewShotBootStrapping not enabled. Remember, only run this ONCE in script for reproducibility.\")\n",
    "    needFewShotBootStrapping = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e643a0d3-1756-477c-a57f-840df6c3fd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: tf_efficientnetv2_m.in21k_ft_in1k\n",
      "\n",
      "Ext Test ROC AUC: 0.605\n",
      "Ext Test PR AUC: 0.424\n",
      "Ext Test sens @spec90%: 0.300\n",
      "Ext Test spec @sens90%: 0.075\n",
      "                ----------\n",
      "Fold corr coeff -- mean: 0.452| std dev: 0.185\n",
      "----------\n",
      "Starting Bootstrapping for Few Shot Results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_600572/847809350.py:50: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  bootMetrics = pd.concat([bootMetrics, currMetrics], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocAUC CIs (2.5,97.5): 0.435, 0.767\n",
      "----------\n",
      "prAUC CIs (2.5,97.5): 0.213, 0.632\n",
      "----------\n",
      "sensAtSpec CIs (2.5,97.5): 0.133, 0.600\n",
      "----------\n",
      "specAtSens CIs (2.5,97.5): 0.026, 0.463\n",
      "----------\n",
      "Model name: fastvit_ma36.apple_dist_in1k\n",
      "\n",
      "Ext Test ROC AUC: 0.859\n",
      "Ext Test PR AUC: 0.651\n",
      "Ext Test sens @spec90%: 0.550\n",
      "Ext Test spec @sens90%: 0.594\n",
      "                ----------\n",
      "Fold corr coeff -- mean: 0.650| std dev: 0.036\n",
      "----------\n",
      "Starting Bootstrapping for Few Shot Results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_600572/847809350.py:50: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  bootMetrics = pd.concat([bootMetrics, currMetrics], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocAUC CIs (2.5,97.5): 0.770, 0.935\n",
      "----------\n",
      "prAUC CIs (2.5,97.5): 0.424, 0.836\n",
      "----------\n",
      "sensAtSpec CIs (2.5,97.5): 0.316, 0.800\n",
      "----------\n",
      "specAtSens CIs (2.5,97.5): 0.486, 0.849\n",
      "----------\n",
      "Model name: mobilenetv4_conv_large.e600_r384_in1k\n",
      "\n",
      "Ext Test ROC AUC: 0.781\n",
      "Ext Test PR AUC: 0.550\n",
      "Ext Test sens @spec90%: 0.450\n",
      "Ext Test spec @sens90%: 0.488\n",
      "                ----------\n",
      "Fold corr coeff -- mean: 0.461| std dev: 0.084\n",
      "----------\n",
      "Starting Bootstrapping for Few Shot Results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_600572/847809350.py:50: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  bootMetrics = pd.concat([bootMetrics, currMetrics], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocAUC CIs (2.5,97.5): 0.652, 0.895\n",
      "----------\n",
      "prAUC CIs (2.5,97.5): 0.321, 0.760\n",
      "----------\n",
      "sensAtSpec CIs (2.5,97.5): 0.227, 0.720\n",
      "----------\n",
      "specAtSens CIs (2.5,97.5): 0.250, 0.772\n",
      "----------\n",
      "Model name: repvit_m3.dist_in1k\n",
      "\n",
      "Ext Test ROC AUC: 0.854\n",
      "Ext Test PR AUC: 0.648\n",
      "Ext Test sens @spec90%: 0.550\n",
      "Ext Test spec @sens90%: 0.650\n",
      "                ----------\n",
      "Fold corr coeff -- mean: 0.713| std dev: 0.051\n",
      "----------\n",
      "Starting Bootstrapping for Few Shot Results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_600572/847809350.py:50: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  bootMetrics = pd.concat([bootMetrics, currMetrics], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocAUC CIs (2.5,97.5): 0.763, 0.930\n",
      "----------\n",
      "prAUC CIs (2.5,97.5): 0.435, 0.821\n",
      "----------\n",
      "sensAtSpec CIs (2.5,97.5): 0.296, 0.800\n",
      "----------\n",
      "specAtSens CIs (2.5,97.5): 0.512, 0.832\n",
      "----------\n",
      "Model name: resnetv2_34.ra4_e3600_r224_in1k\n",
      "\n",
      "Ext Test ROC AUC: 0.823\n",
      "Ext Test PR AUC: 0.574\n",
      "Ext Test sens @spec90%: 0.600\n",
      "Ext Test spec @sens90%: 0.562\n",
      "                ----------\n",
      "Fold corr coeff -- mean: 0.811| std dev: 0.027\n",
      "----------\n",
      "Starting Bootstrapping for Few Shot Results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_600572/847809350.py:50: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  bootMetrics = pd.concat([bootMetrics, currMetrics], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocAUC CIs (2.5,97.5): 0.709, 0.920\n",
      "----------\n",
      "prAUC CIs (2.5,97.5): 0.348, 0.789\n",
      "----------\n",
      "sensAtSpec CIs (2.5,97.5): 0.316, 0.821\n",
      "----------\n",
      "specAtSens CIs (2.5,97.5): 0.300, 0.842\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "ensembleModels = ['tf_efficientnetv2_m.in21k_ft_in1k', 'fastvit_ma36.apple_dist_in1k', 'mobilenetv4_conv_large.e600_r384_in1k', \n",
    "                  'repvit_m3.dist_in1k', 'resnetv2_34.ra4_e3600_r224_in1k']\n",
    "#same models as before, full name vs truncated name\n",
    "ensembleProbFewShot = np.zeros(len(fewShotResults[0]['test_labels']))\n",
    "ensembleListPredsFewShot = []\n",
    "ensembleProbBootFewShot = np.zeros((B, len(fewShotResults[0]['test_labels'])))\n",
    "\n",
    "for modelData in fewShotResults:\n",
    "    if modelData['name'] in ensembleModels:\n",
    "        probs = np.zeros(len(labelsFewShot))\n",
    "        for fold in range(5):\n",
    "            probs = probs + modelData['external_validation_fewShotResults'][fold]\n",
    "        probs = expit(probs/5) #average of the five folds\n",
    "\n",
    "        rocAUC, prAUC, sensAtSpec, specAtSens = ext_val_metrics(labelsFewShot, probs, target_value=0.90)\n",
    "        # print(len(modelData['external_validation_results'][0]))\n",
    "        print(f\"\"\"Model name: {modelData['name']}\\n\n",
    "Ext Test ROC AUC: {rocAUC:.3f}\n",
    "Ext Test PR AUC: {prAUC:.3f}\n",
    "Ext Test sens @spec90%: {sensAtSpec:.3f}\n",
    "Ext Test spec @sens90%: {specAtSens:.3f}\n",
    "                ----------\"\"\")\n",
    "        foldSimilarity = []\n",
    "        for i in range(5): #correlation analysis between folds\n",
    "            for j in range(i+1, 5):\n",
    "                p_i = expit(modelData['external_validation_fewShotResults'][i])\n",
    "                p_j = expit(modelData['external_validation_fewShotResults'][j])\n",
    "                foldSimilarity.append(np.corrcoef(p_i, p_j)[0,1])\n",
    "        foldSimilarity = np.array(foldSimilarity)\n",
    "        print(f\"Fold corr coeff -- mean: {foldSimilarity.mean():.3f}| std dev: {foldSimilarity.std():.3f}\")\n",
    "\n",
    "        ensembleProbFewShot = ensembleProbFewShot + probs\n",
    "        ensembleListPredsFewShot.append(probs)\n",
    "\n",
    "        metricNames = [\"rocAUC\",\"prAUC\",\"sensAtSpec\",\"specAtSens\"]\n",
    "        bootMetrics = pd.DataFrame(columns=metricNames)\n",
    "        print(f\"----------\\nStarting Bootstrapping for Few Shot Results:\")\n",
    "        for bootNum in range(B):\n",
    "            bootIdx = fewShotBootStrapIdxs[bootNum] #indices for this bootstrap\n",
    "            bootLabels = labelsFewShot[bootIdx]\n",
    "            bootProbs = np.zeros(len(bootLabels))\n",
    "            for fold in range(5):\n",
    "                bootProbs = bootProbs + modelData['external_validation_fewShotResults'][fold][bootIdx]\n",
    "            bootProbs = expit(bootProbs/5) #average of the five folds\n",
    "            if modelData['name'] in ensembleModels:\n",
    "                ensembleProbBootFewShot[bootNum] = ensembleProbBootFewShot[bootNum] + bootProbs\n",
    "            \n",
    "            rocAUC, prAUC, sensAtSpec, specAtSens = ext_val_metrics(bootLabels, bootProbs, target_value=0.90)\n",
    "            currMetrics = pd.DataFrame([{\"rocAUC\": rocAUC, \"prAUC\": prAUC, \"sensAtSpec\": sensAtSpec, \"specAtSens\": specAtSens}])\n",
    "            bootMetrics = pd.concat([bootMetrics, currMetrics], ignore_index=True)\n",
    "        # print(bootMetrics)\n",
    "        CIs = pd.DataFrame(columns=metricNames)\n",
    "        for metric in metricNames:\n",
    "            lower = np.percentile(bootMetrics[metric], 2.5)\n",
    "            upper = np.percentile(bootMetrics[metric], 97.5)\n",
    "            CIs[metric] = [lower, upper]\n",
    "            print(f\"{metric} CIs (2.5,97.5): {lower:.3f}, {upper:.3f}\\n----------\")\n",
    "    # else:\n",
    "    #     print(modelData['name'])\n",
    "ensembleProbBootFewShot = ensembleProbBootFewShot/len(ensembleModels)\n",
    "ensembleProbFewShot = ensembleProbFewShot/len(ensembleModels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "89733447-52e7-4350-86c7-0d4ee1f92413",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ensembleFewShotProbs.npy', ensembleProbFewShot)\n",
    "np.save('ensembleZeroShotProbs.npy', ensembleProb)\n",
    "np.save('fewShotEnsembleGTs.npy', fewShotResults[0]['test_labels'])\n",
    "np.save('zeroShotEnsembleGTs.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e75f5b0-70e8-4c72-9cae-726800f7883e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: Ensemble (soft; Few Shot)\n",
      "Ext Test ROC AUC: 0.847\n",
      "Ext Test PR AUC: 0.601\n",
      "Ext Test sens @spec90%: 0.500\n",
      "Ext Test spec @sens90%: 0.650\n",
      "                ----------\n",
      "Fold corr coeff -- mean: 0.667| std dev: 0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_600572/2385383613.py:27: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  ensBootMetricsFewShot = pd.concat([ensBootMetricsFewShot, currMetrics], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocAUC CIs (2.5,97.5): 0.757, 0.924\n",
      "----------\n",
      "prAUC CIs (2.5,97.5): 0.375, 0.796\n",
      "----------\n",
      "sensAtSpec CIs (2.5,97.5): 0.238, 0.783\n",
      "----------\n",
      "specAtSens CIs (2.5,97.5): 0.511, 0.831\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "rocAUC, prAUC, sensAtSpec, specAtSens = ext_val_metrics(labelsFewShot, ensembleProbFewShot, target_value=0.90)\n",
    "# print(len(modelData['external_validation_results'][0]))\n",
    "print(f\"\"\"Model name: Ensemble (soft; Few Shot)\n",
    "Ext Test ROC AUC: {rocAUC:.3f}\n",
    "Ext Test PR AUC: {prAUC:.3f}\n",
    "Ext Test sens @spec90%: {sensAtSpec:.3f}\n",
    "Ext Test spec @sens90%: {specAtSens:.3f}\n",
    "                ----------\"\"\")\n",
    "\n",
    "foldSimilarity = []\n",
    "for i in range(5): #correlation analysis between folds\n",
    "    for j in range(i+1, 5):\n",
    "        p_i = expit(ensembleListPredsFewShot[i])\n",
    "        p_j = expit(ensembleListPredsFewShot[j])\n",
    "        foldSimilarity.append(np.corrcoef(p_i, p_j)[0,1])\n",
    "foldSimilarity = np.array(foldSimilarity)\n",
    "print(f\"Fold corr coeff -- mean: {foldSimilarity.mean():.3f}| std dev: {foldSimilarity.std():.3f}\")\n",
    "\n",
    "metricNames = [\"rocAUC\",\"prAUC\",\"sensAtSpec\",\"specAtSens\"]\n",
    "ensBootMetricsFewShot = pd.DataFrame(columns=metricNames)\n",
    "for bootNum in range(B):\n",
    "    bootIdx = fewShotBootStrapIdxs[bootNum] #indices for this bootstrap\n",
    "    bootLabels = labelsFewShot[bootIdx]\n",
    "    \n",
    "    rocAUC, prAUC, sensAtSpec, specAtSens = ext_val_metrics(bootLabels, ensembleProbBootFewShot[bootNum], target_value=0.90)\n",
    "    currMetrics = pd.DataFrame([{\"rocAUC\": rocAUC, \"prAUC\": prAUC, \"sensAtSpec\": sensAtSpec, \"specAtSens\": specAtSens}])\n",
    "    ensBootMetricsFewShot = pd.concat([ensBootMetricsFewShot, currMetrics], ignore_index=True)\n",
    "\n",
    "bootFewShotCIs = pd.DataFrame(columns=metricNames)\n",
    "for metric in metricNames:\n",
    "    lower = np.percentile(ensBootMetricsFewShot[metric], 2.5)\n",
    "    upper = np.percentile(ensBootMetricsFewShot[metric], 97.5)\n",
    "    bootFewShotCIs[metric] = [lower, upper]\n",
    "    print(f\"{metric} CIs (2.5,97.5): {lower:.3f}, {upper:.3f}\\n----------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
