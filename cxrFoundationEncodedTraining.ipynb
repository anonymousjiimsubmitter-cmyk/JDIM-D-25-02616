{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06e1ede4-507e-4fb9-a1a3-cf2f1d07b555",
   "metadata": {},
   "source": [
    "# Encode Training/Validation data using google cxr-foundation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6b9b33a-6460-4047-999a-aa909aacd7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-26 18:09:16.768481: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-26 18:09:16.790723: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1769479756.816106 1046088 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1769479756.823909 1046088 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1769479756.842922 1046088 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769479756.842941 1046088 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769479756.842943 1046088 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769479756.842944 1046088 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2026-01-26 18:09:16.849734: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully force-loaded cuDNN 9.3.0 into memory.\n",
      "✅ Memory growth enabled for 8 GPU(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1769479773.958139 1046088 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 39866 MB memory:  -> device: 0, name: NVIDIA L40, pci bus id: 0000:3d:00.0, compute capability: 8.9\n",
      "I0000 00:00:1769479773.960654 1046088 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 43224 MB memory:  -> device: 1, name: NVIDIA L40, pci bus id: 0000:b2:00.0, compute capability: 8.9\n",
      "I0000 00:00:1769479773.961530 1046088 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 9553 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5\n",
      "I0000 00:00:1769479773.962386 1046088 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 9553 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1b:00.0, compute capability: 7.5\n",
      "I0000 00:00:1769479773.963239 1046088 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 9553 MB memory:  -> device: 4, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:3e:00.0, compute capability: 7.5\n",
      "I0000 00:00:1769479773.964127 1046088 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 9553 MB memory:  -> device: 5, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:88:00.0, compute capability: 7.5\n",
      "I0000 00:00:1769479773.964976 1046088 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 9553 MB memory:  -> device: 6, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:89:00.0, compute capability: 7.5\n",
      "I0000 00:00:1769479773.965853 1046088 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 9553 MB memory:  -> device: 7, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:b1:00.0, compute capability: 7.5\n",
      "I0000 00:00:1769479779.022544 1046088 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ cuDNN 9.3.0 is functional and verified for Google CXR Foundation Model.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ctypes\n",
    "import tensorflow as tf\n",
    "from scipy.special import expit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_recall_curve, auc, roc_curve\n",
    "\n",
    "# 1. Force-load the correct cuDNN 9.3.0 library\n",
    "lib_path = \"/home/wuat2/anaconda3/pkgs/cudnn-9.3.0.75-cuda12.6/lib/libcudnn.so.9\"\n",
    "try:\n",
    "    ctypes.CDLL(lib_path, mode=ctypes.RTLD_GLOBAL)\n",
    "    os.environ['LD_LIBRARY_PATH'] = \"/home/wuat2/anaconda3/pkgs/cudnn-9.3.0.75-cuda12.6/lib:\" + os.environ.get('LD_LIBRARY_PATH', '')\n",
    "    print(\"✅ Successfully force-loaded cuDNN 9.3.0 into memory.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Could not load library: {e}\")\n",
    "\n",
    "# 2. Configure Memory Growth IMMEDIATELY after import\n",
    "# This MUST happen before the Conv2D test\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"✅ Memory growth enabled for {len(gpus)} GPU(s).\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"❌ Configuration Error: {e}\")\n",
    "\n",
    "# 3. NOW run the Functional Test\n",
    "# This will use the loaded cuDNN 9.3 and honor the memory growth setting\n",
    "try:\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        # Dummy op to trigger cuDNN kernels\n",
    "        _ = tf.keras.layers.Conv2D(2, 3)(tf.random.normal((1, 28, 28, 1)))\n",
    "    print(\"✅ cuDNN 9.3.0 is functional and verified for Google CXR Foundation Model.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Functional Test Failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbadcf2a-5c7b-4460-b700-d1e37ec5b803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to set cudnn path here; DO NOT IMPORT TENSORFLOW HERE\n",
    "from load_dataset import data_summary, make_dataset, set_seeds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from timm.models import create_model, list_models\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, train_test_split\n",
    "\n",
    "SEED = 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684f5ca8-0b08-4036-b9b6-b2b542d26b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = r\"/extra/xielab0/wuat2/AryaQualityViewProjectData\"\n",
    "\n",
    "image_dir = os.path.join(base_dir, r\"images\")\n",
    "encoded_dir = os.path.join(base_dir, r\"encodedImgs\")\n",
    "ext_encoded_dir = os.path.join(base_dir, r\"encodedExtImgs\")\n",
    "\n",
    "IMAGE_RESOLUTION = 384\n",
    "\n",
    "dataset_settings = {\n",
    "    \"image_size\": (IMAGE_RESOLUTION, IMAGE_RESOLUTION),\n",
    "    \"label_map\": {\n",
    "        'diagnostic quality': 0,\n",
    "        'repeat needed': 1,\n",
    "    }\n",
    "}\n",
    "\n",
    "dataset = make_dataset(base_dir, image_dir, \n",
    "                       image_size=dataset_settings[\"image_size\"],\n",
    "                       label_map=dataset_settings[\"label_map\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deac318-4b5b-45ca-94f0-066e9267796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2523c071-4d27-43a9-a648-8f8e87d18ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "import tensorflow_text as tf_text\n",
    "\n",
    "snapshot_download(repo_id=\"google/cxr-foundation\",local_dir='./content/hf',\n",
    "                  allow_patterns=['elixr-c-v2-pooled/*', 'pax-elixr-b-text/*'])\n",
    "\n",
    "if 'elixrc_model' not in locals():\n",
    "    elixrc_model = tf.saved_model.load('./content/hf/elixr-c-v2-pooled')\n",
    "    elixrc_infer = elixrc_model.signatures['serving_default']\n",
    "\n",
    "if 'qformer_model' not in locals():\n",
    "    qformer_model = tf.saved_model.load(\"./content/hf/pax-elixr-b-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e12774b5-f4e6-41e7-bc41-f7a4f5f64c72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # USE TO FOR EMBEDDING INT VAL IMAGES USING GOOGLE CXR FOUNDATION MODEL; ELIXR-B\n",
    "\n",
    "# def create_tf_example(image_bytes):\n",
    "#     feature = {\n",
    "#         'image/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_bytes]))\n",
    "#     }\n",
    "#     example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "#     return example_proto.SerializeToString()\n",
    "    \n",
    "# for imgIndex in range(len(dataset.images)):\n",
    "#     imageName = dataset.images[imgIndex]\n",
    "#     saveName = imageName.replace('.png', '.npy').replace('/', '_')\n",
    "#     # imageLabel = dataset.labels[imgIndex]\n",
    "    \n",
    "#     imagePath = os.path.join(image_dir, imageName)\n",
    "    \n",
    "#     try:\n",
    "#         image_bytes = tf.io.read_file(imagePath).numpy()\n",
    "#         serialized_example = create_tf_example(image_bytes)\n",
    "\n",
    "#         # 3. ELIXR-C Inference (expects a 1D tensor of serialized strings)\n",
    "#         elixrc_output = elixrc_infer(input_example=tf.constant([serialized_example]))\n",
    "#         elixrc_embedding = elixrc_output['feature_maps_0'].numpy()\n",
    "\n",
    "#         qformer_input = {\n",
    "#             'image_feature': elixrc_embedding.tolist(),\n",
    "#             'ids': np.zeros((1, 1, 128), dtype=np.int32).tolist(),\n",
    "#             'paddings':np.zeros((1, 1, 128), dtype=np.float32).tolist(),\n",
    "#         }\n",
    "        \n",
    "#         qformer_output = qformer_model.signatures['serving_default'](**qformer_input)\n",
    "#         elixrb_embeddings = qformer_output['all_contrastive_img_emb']\n",
    "        \n",
    "#         # print(\"ELIXR-B - embedding shape: \", elixrb_embeddings.shape)\n",
    "\n",
    "#         saveFileName = os.path.join(encoded_dir, saveName)\n",
    "#         np.save(saveFileName, elixrb_embeddings)\n",
    "#         # new_row_data = {'fileName': imageName, 'Encoded': elixrc_embedding, 'Label': imageLabel}\n",
    "#         # transformedData.loc[imgIndex] = new_row_data\n",
    "    \n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"Error: The file '{imagePath}' was not found.\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "\n",
    "# print(\"successfully embedded data with Google CXR Foundation Model. Img Tensor --> ELIXR-C --> ELIXR-B (embedding shape 1x32x128).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf31d629-8618-44fb-8654-393fd7449ceb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-26 16:02:59.630686: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_207_0', 240 bytes spill stores, 716 bytes spill loads\n",
      "\n",
      "2026-01-26 16:02:59.649717: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_209', 468 bytes spill stores, 468 bytes spill loads\n",
      "\n",
      "2026-01-26 16:02:59.813502: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_211_0', 112 bytes spill stores, 148 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:00.052456: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_207', 496 bytes spill stores, 496 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:00.116154: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_207_0', 852 bytes spill stores, 1164 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:00.178492: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_207', 1016 bytes spill stores, 1080 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:00.268468: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_209', 900 bytes spill stores, 908 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:00.866241: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_209', 648 bytes spill stores, 648 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:00.891287: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_211', 540 bytes spill stores, 416 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:00.914630: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_209_0', 1176 bytes spill stores, 2548 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:01.250701: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_207', 776 bytes spill stores, 776 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:01.251804: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_207', 3236 bytes spill stores, 3208 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:01.432061: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_161', 388 bytes spill stores, 388 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:01.461829: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_162', 2140 bytes spill stores, 1960 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:01.533775: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_211', 888 bytes spill stores, 888 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:01.809735: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_209_0', 2552 bytes spill stores, 3260 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:02.077562: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_161', 400 bytes spill stores, 404 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:02.617841: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_211_0', 2720 bytes spill stores, 3552 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:02.760374: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_162', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:02.969315: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_162', 548 bytes spill stores, 548 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:03.482991: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_158_0', 420 bytes spill stores, 632 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:04.450078: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_26', 496 bytes spill stores, 496 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:04.474533: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_211', 248 bytes spill stores, 248 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:04.543841: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_209', 3292 bytes spill stores, 3272 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:04.578892: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_211', 240 bytes spill stores, 240 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:04.593620: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_211', 432 bytes spill stores, 344 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:04.695801: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_158', 652 bytes spill stores, 652 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:05.134409: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_162', 424 bytes spill stores, 424 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:05.136350: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_162', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:05.151916: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_26', 776 bytes spill stores, 776 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:05.323082: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_26_0', 444 bytes spill stores, 496 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:05.583281: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_158', 488 bytes spill stores, 488 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:05.684293: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_211', 428 bytes spill stores, 340 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:05.697942: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_162', 876 bytes spill stores, 876 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:05.709046: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_211', 632 bytes spill stores, 632 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:05.709134: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_158', 916 bytes spill stores, 936 bytes spill loads\n",
      "\n",
      "2026-01-26 16:03:05.815105: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_26', 1016 bytes spill stores, 1080 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully embedded ext val data with Google CXR Foundation Model. Img Tensor --> ELIXR-C --> ELIXR-B (embedding shape 1x32x128).\n"
     ]
    }
   ],
   "source": [
    "# # # USE TO FOR EMBEDDING EXT VAL IMAGES USING GOOGLE CXR FOUNDATION MODEL; ELIXR-B\n",
    "# def create_tf_example(image_bytes):\n",
    "#     feature = {\n",
    "#         'image/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_bytes]))\n",
    "#     }\n",
    "#     example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "#     return example_proto.SerializeToString()\n",
    "\n",
    "# os.makedirs(ext_encoded_dir, exist_ok=True)\n",
    "# file_paths\n",
    "\n",
    "# for imgIndex in range(len(file_paths)):\n",
    "#     imagePath = file_paths[imgIndex]\n",
    "#     imageName = os.path.basename(imagePath)\n",
    "#     saveName = imageName.replace('.png', '.npy').replace('/', '_')\n",
    "    \n",
    "#     try:\n",
    "#         image_bytes = tf.io.read_file(imagePath).numpy()\n",
    "#         serialized_example = create_tf_example(image_bytes)\n",
    "\n",
    "#         # 3. ELIXR-C Inference (expects a 1D tensor of serialized strings)\n",
    "#         elixrc_output = elixrc_infer(input_example=tf.constant([serialized_example]))\n",
    "#         elixrc_embedding = elixrc_output['feature_maps_0'].numpy()\n",
    "\n",
    "#         qformer_input = {\n",
    "#             'image_feature': elixrc_embedding.tolist(),\n",
    "#             'ids': np.zeros((1, 1, 128), dtype=np.int32).tolist(),\n",
    "#             'paddings':np.zeros((1, 1, 128), dtype=np.float32).tolist(),\n",
    "#         }\n",
    "        \n",
    "#         qformer_output = qformer_model.signatures['serving_default'](**qformer_input)\n",
    "#         elixrb_embeddings = qformer_output['all_contrastive_img_emb']\n",
    "        \n",
    "#         # print(\"ELIXR-B - embedding shape: \", elixrb_embeddings.shape)\n",
    "\n",
    "#         saveFileName = os.path.join(ext_encoded_dir, saveName)\n",
    "#         np.save(saveFileName, elixrb_embeddings)\n",
    "#         # new_row_data = {'fileName': imageName, 'Encoded': elixrc_embedding, 'Label': imageLabel}\n",
    "#         # transformedData.loc[imgIndex] = new_row_data\n",
    "    \n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"Error: The file '{imagePath}' was not found.\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "\n",
    "# print(\"successfully embedded ext val data with Google CXR Foundation Model. Img Tensor --> ELIXR-C --> ELIXR-B (embedding shape 1x32x128).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fdd019-40e8-497e-bcb5-c8a745110f41",
   "metadata": {},
   "source": [
    "# Create model and define F1 Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd77ddd2-1c1a-4a51-b087-853b68b28726",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxF1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='max_f1_score', **kwargs):\n",
    "        super(MaxF1Score, self).__init__(name=name, **kwargs)\n",
    "        # Define the exact thresholds you used in your PyTorch loop (0.01 to 1.00)\n",
    "        self.thresholds = tf.constant(tf.linspace(0.01, 1.00, 100))\n",
    "        \n",
    "        self.tp = self.add_weight(name='tp', shape=(100,), initializer='zeros')\n",
    "        self.fp = self.add_weight(name='fp', shape=(100,), initializer='zeros')\n",
    "        self.fn = self.add_weight(name='fn', shape=(100,), initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None): #Updates cm stats for all thresholds.\n",
    "        \n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "        \n",
    "        pred_binary = tf.cast(y_pred > self.thresholds, tf.float32)\n",
    "        \n",
    "        # 2. Broadcast ground truth to match (Batch_Size, 100)\n",
    "        true_broadcast = tf.tile(y_true, [1, 100])\n",
    "        \n",
    "        # 3. Calculate TP, FP, FN for all thresholds\n",
    "        # We sum over axis 0 (the batch dimension) to get totals per threshold\n",
    "        true_positives = tf.reduce_sum(true_broadcast * pred_binary, axis=0)\n",
    "        false_positives = tf.reduce_sum((1 - true_broadcast) * pred_binary, axis=0)\n",
    "        false_negatives = tf.reduce_sum(true_broadcast * (1 - pred_binary), axis=0)\n",
    "        \n",
    "        # 4. Update the state variables\n",
    "        self.tp.assign_add(true_positives)\n",
    "        self.fp.assign_add(false_positives)\n",
    "        self.fn.assign_add(false_negatives)\n",
    "\n",
    "    def result(self):\n",
    "        precision = tf.math.divide_no_nan(self.tp, self.tp + self.fp)\n",
    "        recall = tf.math.divide_no_nan(self.tp, self.tp + self.fn)\n",
    "        \n",
    "        f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "        \n",
    "        # Return the single highest F1 score found across all 100 thresholds\n",
    "        return tf.reduce_max(f1_scores)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.tp.assign(tf.zeros((100,)))\n",
    "        self.fp.assign(tf.zeros((100,)))\n",
    "        self.fn.assign(tf.zeros((100,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9beb807-91f3-4c69-9715-4ccdf994b219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model creation adapted from Google CXR foundation model github documentation:\n",
    "# https://github.com/Google-Health/imaging-research/blob/master/cxr-foundation/CXR_Foundation_Demo.ipynb\n",
    "# note: using Adam vs LARS for stability within small-data regimes and consistency across other models tested\n",
    "\n",
    "def create_model(heads,\n",
    "                 token_num=32, # ELIXR-B uses 32x128\n",
    "                 embeddings_size=128,\n",
    "                 learning_rate=1e-4, # Standard for AdamW\n",
    "                 end_lr_factor=0.1,\n",
    "                 dropout=0.3,\n",
    "                 decay_steps=1000,\n",
    "                 loss_weights=None,\n",
    "                 hidden_layer_sizes=[256, 128], # 4 factor lower sizes to accommodate small dataset\n",
    "                 weight_decay=1e-4, # Standard for AdamW\n",
    "                 activation='Sigmoid',\n",
    "                 loss='binary_crossentropy',\n",
    "                 seed=None) -> tf.keras.Model:\n",
    "\n",
    "    # 1. Flattened input for ELIXR-B\n",
    "    inputs = tf.keras.Input(shape=(token_num * embeddings_size,))\n",
    "    \n",
    "    # 2. Reshape and Pooling\n",
    "    inputs_reshape = tf.keras.layers.Reshape((token_num, embeddings_size))(inputs)\n",
    "    hidden = tf.keras.layers.GlobalAveragePooling1D()(inputs_reshape)\n",
    "\n",
    "    # 3. Narrower MLP Layers\n",
    "    for size in hidden_layer_sizes:\n",
    "        hidden = tf.keras.layers.Dense(\n",
    "            size,\n",
    "            activation='relu',\n",
    "            kernel_initializer=tf.keras.initializers.HeUniform(seed=seed),\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l2=weight_decay)\n",
    "        )(hidden)\n",
    "        hidden = tf.keras.layers.BatchNormalization()(hidden)\n",
    "        hidden = tf.keras.layers.Dropout(dropout, seed=seed)(hidden)\n",
    "\n",
    "    # 4. Multi-head Output\n",
    "    output_raw = tf.keras.layers.Dense(\n",
    "        units=len(heads),\n",
    "        activation=activation,\n",
    "        kernel_initializer=tf.keras.initializers.HeUniform(seed=seed)\n",
    "    )(hidden)\n",
    "\n",
    "    outputs = {}\n",
    "    for i, head in enumerate(heads):\n",
    "        # Create label dictionary entries\n",
    "        outputs[head] = tf.keras.layers.Lambda(\n",
    "            lambda x: x[..., i:i + 1], name=head)(output_raw)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    learning_rate_fn = tf.keras.optimizers.schedules.CosineDecay(\n",
    "        initial_learning_rate=tf.cast(learning_rate, tf.float32),\n",
    "        decay_steps=tf.cast(decay_steps, tf.float32),\n",
    "        alpha=tf.cast(end_lr_factor, tf.float32))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.AdamW(learning_rate=learning_rate_fn, weight_decay=weight_decay),\n",
    "        loss='binary_crossentropy',\n",
    "          weighted_metrics=[\n",
    "            MaxF1Score(),\n",
    "            tf.keras.metrics.AUC(name='auc_roc'),\n",
    "            tf.keras.metrics.AUC(curve='PR', name='auc_pr')\n",
    "          ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd90d9c4-3733-4ce5-82dc-ab02e5eb128e",
   "metadata": {},
   "source": [
    "## Build arrays containing all data for 5-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d19c4b8a-9343-487e-8970-56d7462260ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "labels = [] #should be exactly the same order as the original pytorch dataset\n",
    "\n",
    "head_name = 'repeatNeeded'\n",
    "for imgIdx in range(len(dataset.images)):\n",
    "    imageName = dataset.images[imgIdx]\n",
    "    saveName = imageName.replace('.png', '.npy').replace('/', '_')\n",
    "    embeddedDataPath = os.path.join(encoded_dir, saveName)\n",
    "    if os.path.exists(embeddedDataPath):\n",
    "        emb = np.load(embeddedDataPath)\n",
    "        features.append(emb.flatten())\n",
    "        labels.append(dataset.labels[imgIdx])\n",
    "    else:\n",
    "        print(f'data file {embeddedDataPath} cannot be found. Please revise loop logic.')\n",
    "\n",
    "features = np.array(features).astype('float32')\n",
    "labels = np.array(labels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f74da82-4a2f-49ff-9c07-badcf29e35c8",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b39bc007-f691-490c-9f04-6f4979166ddc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 290ms/step - auc_pr: 0.4537 - auc_roc: 0.4025 - loss: 1.2418 - max_f1_score: 0.6663 - val_auc_pr: 0.5500 - val_auc_roc: 0.5622 - val_loss: 0.7705 - val_max_f1_score: 0.6636\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.5720 - auc_roc: 0.5372 - loss: 0.9589 - max_f1_score: 0.6782 - val_auc_pr: 0.6807 - val_auc_roc: 0.7124 - val_loss: 0.7766 - val_max_f1_score: 0.7135\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.6503 - auc_roc: 0.6662 - loss: 0.8196 - max_f1_score: 0.6994 - val_auc_pr: 0.7304 - val_auc_roc: 0.7752 - val_loss: 0.7912 - val_max_f1_score: 0.7286\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.6609 - auc_roc: 0.6498 - loss: 0.8405 - max_f1_score: 0.6849 - val_auc_pr: 0.7498 - val_auc_roc: 0.8071 - val_loss: 0.8115 - val_max_f1_score: 0.7692\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.7671 - auc_roc: 0.7504 - loss: 0.7147 - max_f1_score: 0.7176 - val_auc_pr: 0.7662 - val_auc_roc: 0.8192 - val_loss: 0.8346 - val_max_f1_score: 0.7857\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7238 - auc_roc: 0.7127 - loss: 0.7475 - max_f1_score: 0.6998 - val_auc_pr: 0.7641 - val_auc_roc: 0.8267 - val_loss: 0.8569 - val_max_f1_score: 0.7771\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.7226 - auc_roc: 0.7720 - loss: 0.7023 - max_f1_score: 0.7475 - val_auc_pr: 0.7760 - val_auc_roc: 0.8343 - val_loss: 0.8807 - val_max_f1_score: 0.8098\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7473 - auc_roc: 0.7271 - loss: 0.7414 - max_f1_score: 0.6884 - val_auc_pr: 0.7774 - val_auc_roc: 0.8367 - val_loss: 0.9022 - val_max_f1_score: 0.8049\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7968 - auc_roc: 0.8064 - loss: 0.6313 - max_f1_score: 0.7431 - val_auc_pr: 0.7749 - val_auc_roc: 0.8376 - val_loss: 0.9226 - val_max_f1_score: 0.7952\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8027 - auc_roc: 0.7878 - loss: 0.6632 - max_f1_score: 0.7637 - val_auc_pr: 0.7849 - val_auc_roc: 0.8421 - val_loss: 0.9380 - val_max_f1_score: 0.8075\n",
      "Epoch 11/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7974 - auc_roc: 0.7681 - loss: 0.6901 - max_f1_score: 0.7292 - val_auc_pr: 0.7804 - val_auc_roc: 0.8369 - val_loss: 0.9497 - val_max_f1_score: 0.7975\n",
      "Epoch 12/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7752 - auc_roc: 0.7746 - loss: 0.6939 - max_f1_score: 0.7417 - val_auc_pr: 0.7824 - val_auc_roc: 0.8359 - val_loss: 0.9555 - val_max_f1_score: 0.7875\n",
      "Epoch 13/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8257 - auc_roc: 0.8050 - loss: 0.6229 - max_f1_score: 0.7431 - val_auc_pr: 0.7833 - val_auc_roc: 0.8345 - val_loss: 0.9562 - val_max_f1_score: 0.7895\n",
      "Epoch 14/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.7963 - auc_roc: 0.7880 - loss: 0.6648 - max_f1_score: 0.7450 - val_auc_pr: 0.7795 - val_auc_roc: 0.8327 - val_loss: 0.9553 - val_max_f1_score: 0.7898\n",
      "Epoch 15/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8287 - auc_roc: 0.7907 - loss: 0.6619 - max_f1_score: 0.7597 - val_auc_pr: 0.7830 - val_auc_roc: 0.8383 - val_loss: 0.9505 - val_max_f1_score: 0.7949\n",
      "Epoch 16/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8071 - auc_roc: 0.8063 - loss: 0.6468 - max_f1_score: 0.7683 - val_auc_pr: 0.7835 - val_auc_roc: 0.8381 - val_loss: 0.9471 - val_max_f1_score: 0.7832\n",
      "Epoch 17/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8195 - auc_roc: 0.8099 - loss: 0.6137 - max_f1_score: 0.7453 - val_auc_pr: 0.7829 - val_auc_roc: 0.8354 - val_loss: 0.9428 - val_max_f1_score: 0.7848\n",
      "Epoch 18/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7651 - auc_roc: 0.7754 - loss: 0.6803 - max_f1_score: 0.7378 - val_auc_pr: 0.7836 - val_auc_roc: 0.8353 - val_loss: 0.9297 - val_max_f1_score: 0.7898\n",
      "Epoch 19/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8118 - auc_roc: 0.7849 - loss: 0.6642 - max_f1_score: 0.7514 - val_auc_pr: 0.7826 - val_auc_roc: 0.8329 - val_loss: 0.9177 - val_max_f1_score: 0.7891\n",
      "Epoch 20/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8182 - auc_roc: 0.8149 - loss: 0.6219 - max_f1_score: 0.7547 - val_auc_pr: 0.7830 - val_auc_roc: 0.8338 - val_loss: 0.9013 - val_max_f1_score: 0.7891\n",
      "Epoch 21/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8224 - auc_roc: 0.7946 - loss: 0.6570 - max_f1_score: 0.7443 - val_auc_pr: 0.7817 - val_auc_roc: 0.8335 - val_loss: 0.8777 - val_max_f1_score: 0.7919\n",
      "Epoch 22/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8465 - auc_roc: 0.8377 - loss: 0.5797 - max_f1_score: 0.7658 - val_auc_pr: 0.7807 - val_auc_roc: 0.8342 - val_loss: 0.8553 - val_max_f1_score: 0.7947\n",
      "Epoch 23/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8119 - auc_roc: 0.7937 - loss: 0.6600 - max_f1_score: 0.7337 - val_auc_pr: 0.7802 - val_auc_roc: 0.8350 - val_loss: 0.8398 - val_max_f1_score: 0.7895\n",
      "Epoch 24/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8556 - auc_roc: 0.8412 - loss: 0.5726 - max_f1_score: 0.7840 - val_auc_pr: 0.7803 - val_auc_roc: 0.8362 - val_loss: 0.8201 - val_max_f1_score: 0.7891\n",
      "Epoch 25/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8333 - auc_roc: 0.7957 - loss: 0.6422 - max_f1_score: 0.7411 - val_auc_pr: 0.7837 - val_auc_roc: 0.8389 - val_loss: 0.7993 - val_max_f1_score: 0.7891\n",
      "Epoch 26/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8526 - auc_roc: 0.8500 - loss: 0.5711 - max_f1_score: 0.8123 - val_auc_pr: 0.7833 - val_auc_roc: 0.8401 - val_loss: 0.7757 - val_max_f1_score: 0.7891\n",
      "Epoch 27/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8035 - auc_roc: 0.8083 - loss: 0.6383 - max_f1_score: 0.7561 - val_auc_pr: 0.7830 - val_auc_roc: 0.8401 - val_loss: 0.7568 - val_max_f1_score: 0.7929\n",
      "Epoch 28/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8310 - auc_roc: 0.8240 - loss: 0.5919 - max_f1_score: 0.7561 - val_auc_pr: 0.7835 - val_auc_roc: 0.8386 - val_loss: 0.7415 - val_max_f1_score: 0.7929\n",
      "Epoch 29/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8555 - auc_roc: 0.8484 - loss: 0.5623 - max_f1_score: 0.7918 - val_auc_pr: 0.7824 - val_auc_roc: 0.8364 - val_loss: 0.7207 - val_max_f1_score: 0.7879\n",
      "Epoch 30/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8213 - auc_roc: 0.8208 - loss: 0.6065 - max_f1_score: 0.7533 - val_auc_pr: 0.7833 - val_auc_roc: 0.8369 - val_loss: 0.7040 - val_max_f1_score: 0.7867\n",
      "Epoch 31/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8687 - auc_roc: 0.8347 - loss: 0.5803 - max_f1_score: 0.7676 - val_auc_pr: 0.7810 - val_auc_roc: 0.8339 - val_loss: 0.6914 - val_max_f1_score: 0.7815\n",
      "Epoch 32/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8495 - auc_roc: 0.8415 - loss: 0.5717 - max_f1_score: 0.7749 - val_auc_pr: 0.7809 - val_auc_roc: 0.8338 - val_loss: 0.6794 - val_max_f1_score: 0.7808\n",
      "Epoch 33/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8719 - auc_roc: 0.8398 - loss: 0.5905 - max_f1_score: 0.8080 - val_auc_pr: 0.7794 - val_auc_roc: 0.8328 - val_loss: 0.6683 - val_max_f1_score: 0.7805\n",
      "Epoch 34/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8469 - auc_roc: 0.8415 - loss: 0.5825 - max_f1_score: 0.7846 - val_auc_pr: 0.7814 - val_auc_roc: 0.8360 - val_loss: 0.6586 - val_max_f1_score: 0.7853\n",
      "Epoch 35/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8454 - auc_roc: 0.8223 - loss: 0.6015 - max_f1_score: 0.7580 - val_auc_pr: 0.7812 - val_auc_roc: 0.8346 - val_loss: 0.6531 - val_max_f1_score: 0.7838\n",
      "Epoch 36/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8561 - auc_roc: 0.8372 - loss: 0.5798 - max_f1_score: 0.7814 - val_auc_pr: 0.7825 - val_auc_roc: 0.8352 - val_loss: 0.6467 - val_max_f1_score: 0.7805\n",
      "Epoch 37/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8379 - auc_roc: 0.8242 - loss: 0.6048 - max_f1_score: 0.7617 - val_auc_pr: 0.7821 - val_auc_roc: 0.8349 - val_loss: 0.6426 - val_max_f1_score: 0.7898\n",
      "Epoch 38/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8314 - auc_roc: 0.8047 - loss: 0.6231 - max_f1_score: 0.7486 - val_auc_pr: 0.7818 - val_auc_roc: 0.8349 - val_loss: 0.6378 - val_max_f1_score: 0.7853\n",
      "Epoch 39/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8464 - auc_roc: 0.8214 - loss: 0.6011 - max_f1_score: 0.7723 - val_auc_pr: 0.7821 - val_auc_roc: 0.8346 - val_loss: 0.6371 - val_max_f1_score: 0.7848\n",
      "Epoch 40/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8563 - auc_roc: 0.8285 - loss: 0.6015 - max_f1_score: 0.7821 - val_auc_pr: 0.7839 - val_auc_roc: 0.8349 - val_loss: 0.6345 - val_max_f1_score: 0.7875\n",
      "Epoch 41/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8458 - auc_roc: 0.8407 - loss: 0.5763 - max_f1_score: 0.7873 - val_auc_pr: 0.7849 - val_auc_roc: 0.8354 - val_loss: 0.6326 - val_max_f1_score: 0.7898\n",
      "Epoch 42/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8780 - auc_roc: 0.8656 - loss: 0.5380 - max_f1_score: 0.8035 - val_auc_pr: 0.7850 - val_auc_roc: 0.8354 - val_loss: 0.6319 - val_max_f1_score: 0.7925\n",
      "Epoch 43/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8461 - auc_roc: 0.8152 - loss: 0.6082 - max_f1_score: 0.7528 - val_auc_pr: 0.7839 - val_auc_roc: 0.8352 - val_loss: 0.6313 - val_max_f1_score: 0.7901\n",
      "Epoch 44/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8367 - auc_roc: 0.8236 - loss: 0.6035 - max_f1_score: 0.7755 - val_auc_pr: 0.7855 - val_auc_roc: 0.8355 - val_loss: 0.6289 - val_max_f1_score: 0.7925\n",
      "Epoch 45/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8735 - auc_roc: 0.8483 - loss: 0.5619 - max_f1_score: 0.7748 - val_auc_pr: 0.7848 - val_auc_roc: 0.8352 - val_loss: 0.6292 - val_max_f1_score: 0.7925\n",
      "Epoch 46/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8189 - auc_roc: 0.8314 - loss: 0.5931 - max_f1_score: 0.7629 - val_auc_pr: 0.7862 - val_auc_roc: 0.8354 - val_loss: 0.6304 - val_max_f1_score: 0.7871\n",
      "Epoch 47/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8521 - auc_roc: 0.8487 - loss: 0.5644 - max_f1_score: 0.7779 - val_auc_pr: 0.7845 - val_auc_roc: 0.8351 - val_loss: 0.6302 - val_max_f1_score: 0.7848\n",
      "Epoch 48/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8631 - auc_roc: 0.8367 - loss: 0.5769 - max_f1_score: 0.7880 - val_auc_pr: 0.7862 - val_auc_roc: 0.8352 - val_loss: 0.6285 - val_max_f1_score: 0.7871\n",
      "Epoch 49/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8591 - auc_roc: 0.8491 - loss: 0.5620 - max_f1_score: 0.7802 - val_auc_pr: 0.7848 - val_auc_roc: 0.8352 - val_loss: 0.6280 - val_max_f1_score: 0.7871\n",
      "Epoch 50/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8792 - auc_roc: 0.8683 - loss: 0.5209 - max_f1_score: 0.7913 - val_auc_pr: 0.7870 - val_auc_roc: 0.8363 - val_loss: 0.6283 - val_max_f1_score: 0.7871\n",
      "Epoch 51/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8494 - auc_roc: 0.8327 - loss: 0.5863 - max_f1_score: 0.7604 - val_auc_pr: 0.7868 - val_auc_roc: 0.8354 - val_loss: 0.6271 - val_max_f1_score: 0.7875\n",
      "Epoch 52/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8694 - auc_roc: 0.8628 - loss: 0.5488 - max_f1_score: 0.7990 - val_auc_pr: 0.7838 - val_auc_roc: 0.8351 - val_loss: 0.6266 - val_max_f1_score: 0.7848\n",
      "Epoch 53/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8558 - auc_roc: 0.8335 - loss: 0.5814 - max_f1_score: 0.7713 - val_auc_pr: 0.7852 - val_auc_roc: 0.8355 - val_loss: 0.6261 - val_max_f1_score: 0.7898\n",
      "Epoch 54/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8531 - auc_roc: 0.8377 - loss: 0.5818 - max_f1_score: 0.7753 - val_auc_pr: 0.7858 - val_auc_roc: 0.8364 - val_loss: 0.6274 - val_max_f1_score: 0.7925\n",
      "Epoch 55/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8736 - auc_roc: 0.8592 - loss: 0.5438 - max_f1_score: 0.8056 - val_auc_pr: 0.7857 - val_auc_roc: 0.8363 - val_loss: 0.6265 - val_max_f1_score: 0.7898\n",
      "Epoch 56/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8664 - auc_roc: 0.8403 - loss: 0.5782 - max_f1_score: 0.7727 - val_auc_pr: 0.7850 - val_auc_roc: 0.8352 - val_loss: 0.6269 - val_max_f1_score: 0.7925\n",
      "Epoch 57/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8541 - auc_roc: 0.8369 - loss: 0.5762 - max_f1_score: 0.7783 - val_auc_pr: 0.7855 - val_auc_roc: 0.8358 - val_loss: 0.6271 - val_max_f1_score: 0.7925\n",
      "Epoch 58/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8678 - auc_roc: 0.8586 - loss: 0.5529 - max_f1_score: 0.7928 - val_auc_pr: 0.7866 - val_auc_roc: 0.8367 - val_loss: 0.6270 - val_max_f1_score: 0.7898\n",
      "Epoch 59/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8547 - auc_roc: 0.8327 - loss: 0.5909 - max_f1_score: 0.7813 - val_auc_pr: 0.7854 - val_auc_roc: 0.8369 - val_loss: 0.6270 - val_max_f1_score: 0.7925\n",
      "Epoch 60/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8504 - auc_roc: 0.8528 - loss: 0.5720 - max_f1_score: 0.7775 - val_auc_pr: 0.7868 - val_auc_roc: 0.8368 - val_loss: 0.6260 - val_max_f1_score: 0.7925\n",
      "Epoch 61/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8631 - auc_roc: 0.8480 - loss: 0.5626 - max_f1_score: 0.7896 - val_auc_pr: 0.7856 - val_auc_roc: 0.8370 - val_loss: 0.6257 - val_max_f1_score: 0.7975\n",
      "Epoch 62/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8583 - auc_roc: 0.8422 - loss: 0.5524 - max_f1_score: 0.7618 - val_auc_pr: 0.7847 - val_auc_roc: 0.8373 - val_loss: 0.6256 - val_max_f1_score: 0.7975\n",
      "Epoch 63/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8661 - auc_roc: 0.8484 - loss: 0.5577 - max_f1_score: 0.7738 - val_auc_pr: 0.7858 - val_auc_roc: 0.8377 - val_loss: 0.6259 - val_max_f1_score: 0.7975\n",
      "Epoch 64/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8888 - auc_roc: 0.8598 - loss: 0.5446 - max_f1_score: 0.8048 - val_auc_pr: 0.7849 - val_auc_roc: 0.8366 - val_loss: 0.6255 - val_max_f1_score: 0.7975\n",
      "Epoch 65/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8702 - auc_roc: 0.8552 - loss: 0.5527 - max_f1_score: 0.8002 - val_auc_pr: 0.7854 - val_auc_roc: 0.8376 - val_loss: 0.6257 - val_max_f1_score: 0.7975\n",
      "Epoch 66/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8627 - auc_roc: 0.8570 - loss: 0.5459 - max_f1_score: 0.7818 - val_auc_pr: 0.7858 - val_auc_roc: 0.8376 - val_loss: 0.6252 - val_max_f1_score: 0.7975\n",
      "Epoch 67/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8567 - auc_roc: 0.8429 - loss: 0.5746 - max_f1_score: 0.7779 - val_auc_pr: 0.7864 - val_auc_roc: 0.8380 - val_loss: 0.6246 - val_max_f1_score: 0.7975\n",
      "Epoch 68/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8460 - auc_roc: 0.8319 - loss: 0.5973 - max_f1_score: 0.7882 - val_auc_pr: 0.7868 - val_auc_roc: 0.8385 - val_loss: 0.6247 - val_max_f1_score: 0.7975\n",
      "Epoch 69/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8689 - auc_roc: 0.8358 - loss: 0.5849 - max_f1_score: 0.8036 - val_auc_pr: 0.7843 - val_auc_roc: 0.8375 - val_loss: 0.6260 - val_max_f1_score: 0.7975\n",
      "Epoch 70/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8474 - auc_roc: 0.8483 - loss: 0.5695 - max_f1_score: 0.7835 - val_auc_pr: 0.7858 - val_auc_roc: 0.8380 - val_loss: 0.6260 - val_max_f1_score: 0.7975\n",
      "Epoch 71/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8910 - auc_roc: 0.8770 - loss: 0.5263 - max_f1_score: 0.8168 - val_auc_pr: 0.7857 - val_auc_roc: 0.8379 - val_loss: 0.6263 - val_max_f1_score: 0.7975\n",
      "Epoch 72/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8695 - auc_roc: 0.8414 - loss: 0.5940 - max_f1_score: 0.8094 - val_auc_pr: 0.7860 - val_auc_roc: 0.8371 - val_loss: 0.6262 - val_max_f1_score: 0.7975\n",
      "Epoch 73/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8553 - auc_roc: 0.8426 - loss: 0.5580 - max_f1_score: 0.7691 - val_auc_pr: 0.7849 - val_auc_roc: 0.8370 - val_loss: 0.6259 - val_max_f1_score: 0.7975\n",
      "Epoch 74/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8376 - auc_roc: 0.8189 - loss: 0.6034 - max_f1_score: 0.7524 - val_auc_pr: 0.7858 - val_auc_roc: 0.8372 - val_loss: 0.6258 - val_max_f1_score: 0.7975\n",
      "Epoch 75/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8815 - auc_roc: 0.8619 - loss: 0.5356 - max_f1_score: 0.7969 - val_auc_pr: 0.7857 - val_auc_roc: 0.8370 - val_loss: 0.6257 - val_max_f1_score: 0.7975\n",
      "Epoch 76/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8598 - auc_roc: 0.8502 - loss: 0.5648 - max_f1_score: 0.8070 - val_auc_pr: 0.7849 - val_auc_roc: 0.8362 - val_loss: 0.6239 - val_max_f1_score: 0.7975\n",
      "Epoch 77/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8515 - auc_roc: 0.8474 - loss: 0.5528 - max_f1_score: 0.7593 - val_auc_pr: 0.7853 - val_auc_roc: 0.8363 - val_loss: 0.6246 - val_max_f1_score: 0.7975\n",
      "Epoch 78/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8450 - auc_roc: 0.8463 - loss: 0.5724 - max_f1_score: 0.7782 - val_auc_pr: 0.7847 - val_auc_roc: 0.8355 - val_loss: 0.6252 - val_max_f1_score: 0.7975\n",
      "Epoch 79/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8724 - auc_roc: 0.8472 - loss: 0.5512 - max_f1_score: 0.7942 - val_auc_pr: 0.7848 - val_auc_roc: 0.8358 - val_loss: 0.6260 - val_max_f1_score: 0.7975\n",
      "Epoch 80/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8684 - auc_roc: 0.8585 - loss: 0.5408 - max_f1_score: 0.8049 - val_auc_pr: 0.7854 - val_auc_roc: 0.8364 - val_loss: 0.6260 - val_max_f1_score: 0.7975\n",
      "Epoch 81/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8202 - auc_roc: 0.8371 - loss: 0.5931 - max_f1_score: 0.7578 - val_auc_pr: 0.7846 - val_auc_roc: 0.8359 - val_loss: 0.6257 - val_max_f1_score: 0.7975\n",
      "Epoch 82/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8658 - auc_roc: 0.8519 - loss: 0.5574 - max_f1_score: 0.7893 - val_auc_pr: 0.7847 - val_auc_roc: 0.8360 - val_loss: 0.6258 - val_max_f1_score: 0.7975\n",
      "Epoch 83/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8562 - auc_roc: 0.8530 - loss: 0.5498 - max_f1_score: 0.7789 - val_auc_pr: 0.7863 - val_auc_roc: 0.8358 - val_loss: 0.6272 - val_max_f1_score: 0.7949\n",
      "Epoch 84/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8673 - auc_roc: 0.8573 - loss: 0.5458 - max_f1_score: 0.7847 - val_auc_pr: 0.7862 - val_auc_roc: 0.8365 - val_loss: 0.6274 - val_max_f1_score: 0.7949\n",
      "Epoch 85/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8974 - auc_roc: 0.8903 - loss: 0.4893 - max_f1_score: 0.8341 - val_auc_pr: 0.7861 - val_auc_roc: 0.8363 - val_loss: 0.6277 - val_max_f1_score: 0.7975\n",
      "Epoch 86/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8489 - auc_roc: 0.8324 - loss: 0.5805 - max_f1_score: 0.7614 - val_auc_pr: 0.7861 - val_auc_roc: 0.8361 - val_loss: 0.6270 - val_max_f1_score: 0.7975\n",
      "Epoch 87/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8572 - auc_roc: 0.8511 - loss: 0.5575 - max_f1_score: 0.7864 - val_auc_pr: 0.7855 - val_auc_roc: 0.8361 - val_loss: 0.6278 - val_max_f1_score: 0.8025\n",
      "Epoch 88/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8410 - auc_roc: 0.8282 - loss: 0.5918 - max_f1_score: 0.7815 - val_auc_pr: 0.7851 - val_auc_roc: 0.8355 - val_loss: 0.6278 - val_max_f1_score: 0.7975\n",
      "Epoch 89/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8598 - auc_roc: 0.8514 - loss: 0.5667 - max_f1_score: 0.7875 - val_auc_pr: 0.7853 - val_auc_roc: 0.8355 - val_loss: 0.6265 - val_max_f1_score: 0.7975\n",
      "Epoch 90/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8466 - auc_roc: 0.8365 - loss: 0.5809 - max_f1_score: 0.7671 - val_auc_pr: 0.7858 - val_auc_roc: 0.8364 - val_loss: 0.6272 - val_max_f1_score: 0.8025\n",
      "Epoch 91/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8979 - auc_roc: 0.8860 - loss: 0.4928 - max_f1_score: 0.8109 - val_auc_pr: 0.7861 - val_auc_roc: 0.8371 - val_loss: 0.6278 - val_max_f1_score: 0.8000\n",
      "Epoch 92/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8858 - auc_roc: 0.8728 - loss: 0.5118 - max_f1_score: 0.7983 - val_auc_pr: 0.7858 - val_auc_roc: 0.8357 - val_loss: 0.6284 - val_max_f1_score: 0.7975\n",
      "Epoch 93/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8796 - auc_roc: 0.8592 - loss: 0.5556 - max_f1_score: 0.7919 - val_auc_pr: 0.7855 - val_auc_roc: 0.8351 - val_loss: 0.6287 - val_max_f1_score: 0.8000\n",
      "Epoch 94/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8747 - auc_roc: 0.8609 - loss: 0.5350 - max_f1_score: 0.7943 - val_auc_pr: 0.7865 - val_auc_roc: 0.8357 - val_loss: 0.6277 - val_max_f1_score: 0.8050\n",
      "Epoch 95/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8369 - auc_roc: 0.8346 - loss: 0.5861 - max_f1_score: 0.7580 - val_auc_pr: 0.7869 - val_auc_roc: 0.8362 - val_loss: 0.6278 - val_max_f1_score: 0.8000\n",
      "Epoch 96/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8777 - auc_roc: 0.8713 - loss: 0.5288 - max_f1_score: 0.8144 - val_auc_pr: 0.7870 - val_auc_roc: 0.8362 - val_loss: 0.6279 - val_max_f1_score: 0.8000\n",
      "Epoch 97/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8612 - auc_roc: 0.8481 - loss: 0.5774 - max_f1_score: 0.7989 - val_auc_pr: 0.7858 - val_auc_roc: 0.8350 - val_loss: 0.6281 - val_max_f1_score: 0.7925\n",
      "Epoch 98/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8936 - auc_roc: 0.8800 - loss: 0.5074 - max_f1_score: 0.8121 - val_auc_pr: 0.7866 - val_auc_roc: 0.8354 - val_loss: 0.6276 - val_max_f1_score: 0.7949\n",
      "Epoch 99/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8630 - auc_roc: 0.8292 - loss: 0.6093 - max_f1_score: 0.7967 - val_auc_pr: 0.7866 - val_auc_roc: 0.8346 - val_loss: 0.6275 - val_max_f1_score: 0.7949\n",
      "Epoch 100/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8915 - auc_roc: 0.8759 - loss: 0.5181 - max_f1_score: 0.8131 - val_auc_pr: 0.7862 - val_auc_roc: 0.8343 - val_loss: 0.6284 - val_max_f1_score: 0.7898\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f0c2db505e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 412ms/stepWARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f0c2db505e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 264ms/step - auc_pr: 0.4023 - auc_roc: 0.3873 - loss: 1.2218 - max_f1_score: 0.6337 - val_auc_pr: 0.5074 - val_auc_roc: 0.4798 - val_loss: 0.7729 - val_max_f1_score: 0.6636\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.5559 - auc_roc: 0.5721 - loss: 0.9132 - max_f1_score: 0.6456 - val_auc_pr: 0.5773 - val_auc_roc: 0.5909 - val_loss: 0.7809 - val_max_f1_score: 0.6636\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.6473 - auc_roc: 0.6359 - loss: 0.8403 - max_f1_score: 0.6915 - val_auc_pr: 0.6246 - val_auc_roc: 0.6373 - val_loss: 0.7953 - val_max_f1_score: 0.6702\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.7235 - auc_roc: 0.7092 - loss: 0.7608 - max_f1_score: 0.7021 - val_auc_pr: 0.6475 - val_auc_roc: 0.6677 - val_loss: 0.8163 - val_max_f1_score: 0.6667\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.7717 - auc_roc: 0.7531 - loss: 0.7021 - max_f1_score: 0.7415 - val_auc_pr: 0.6837 - val_auc_roc: 0.6950 - val_loss: 0.8413 - val_max_f1_score: 0.6904\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7521 - auc_roc: 0.7666 - loss: 0.6841 - max_f1_score: 0.7202 - val_auc_pr: 0.7044 - val_auc_roc: 0.7071 - val_loss: 0.8670 - val_max_f1_score: 0.6909\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.7483 - auc_roc: 0.7594 - loss: 0.7189 - max_f1_score: 0.7423 - val_auc_pr: 0.7217 - val_auc_roc: 0.7211 - val_loss: 0.8891 - val_max_f1_score: 0.7037\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.6976 - auc_roc: 0.7485 - loss: 0.7557 - max_f1_score: 0.6998 - val_auc_pr: 0.7403 - val_auc_roc: 0.7357 - val_loss: 0.9088 - val_max_f1_score: 0.6994\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7629 - auc_roc: 0.7873 - loss: 0.6822 - max_f1_score: 0.7495 - val_auc_pr: 0.7556 - val_auc_roc: 0.7468 - val_loss: 0.9300 - val_max_f1_score: 0.7176\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7786 - auc_roc: 0.8040 - loss: 0.6427 - max_f1_score: 0.7482 - val_auc_pr: 0.7722 - val_auc_roc: 0.7568 - val_loss: 0.9461 - val_max_f1_score: 0.7151\n",
      "Epoch 11/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7966 - auc_roc: 0.7693 - loss: 0.6984 - max_f1_score: 0.7370 - val_auc_pr: 0.7784 - val_auc_roc: 0.7605 - val_loss: 0.9555 - val_max_f1_score: 0.7263\n",
      "Epoch 12/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7863 - auc_roc: 0.8052 - loss: 0.6496 - max_f1_score: 0.7721 - val_auc_pr: 0.7885 - val_auc_roc: 0.7706 - val_loss: 0.9598 - val_max_f1_score: 0.7253\n",
      "Epoch 13/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8124 - auc_roc: 0.7975 - loss: 0.6564 - max_f1_score: 0.7361 - val_auc_pr: 0.7962 - val_auc_roc: 0.7773 - val_loss: 0.9655 - val_max_f1_score: 0.7283\n",
      "Epoch 14/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7822 - auc_roc: 0.7837 - loss: 0.6790 - max_f1_score: 0.7621 - val_auc_pr: 0.8008 - val_auc_roc: 0.7805 - val_loss: 0.9612 - val_max_f1_score: 0.7284\n",
      "Epoch 15/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8283 - auc_roc: 0.8175 - loss: 0.6163 - max_f1_score: 0.7686 - val_auc_pr: 0.8035 - val_auc_roc: 0.7842 - val_loss: 0.9557 - val_max_f1_score: 0.7283\n",
      "Epoch 16/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8358 - auc_roc: 0.8095 - loss: 0.6292 - max_f1_score: 0.7640 - val_auc_pr: 0.8091 - val_auc_roc: 0.7875 - val_loss: 0.9436 - val_max_f1_score: 0.7368\n",
      "Epoch 17/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8237 - auc_roc: 0.8093 - loss: 0.6163 - max_f1_score: 0.7627 - val_auc_pr: 0.8135 - val_auc_roc: 0.7924 - val_loss: 0.9316 - val_max_f1_score: 0.7368\n",
      "Epoch 18/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8047 - auc_roc: 0.7947 - loss: 0.6520 - max_f1_score: 0.7398 - val_auc_pr: 0.8156 - val_auc_roc: 0.7942 - val_loss: 0.9162 - val_max_f1_score: 0.7342\n",
      "Epoch 19/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8395 - auc_roc: 0.8253 - loss: 0.6098 - max_f1_score: 0.7841 - val_auc_pr: 0.8125 - val_auc_roc: 0.7898 - val_loss: 0.8993 - val_max_f1_score: 0.7229\n",
      "Epoch 20/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8428 - auc_roc: 0.8290 - loss: 0.6039 - max_f1_score: 0.7738 - val_auc_pr: 0.8110 - val_auc_roc: 0.7879 - val_loss: 0.8776 - val_max_f1_score: 0.7262\n",
      "Epoch 21/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8540 - auc_roc: 0.8442 - loss: 0.5729 - max_f1_score: 0.7878 - val_auc_pr: 0.8141 - val_auc_roc: 0.7922 - val_loss: 0.8581 - val_max_f1_score: 0.7329\n",
      "Epoch 22/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8269 - auc_roc: 0.8385 - loss: 0.5908 - max_f1_score: 0.7886 - val_auc_pr: 0.8175 - val_auc_roc: 0.7951 - val_loss: 0.8333 - val_max_f1_score: 0.7283\n",
      "Epoch 23/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8253 - auc_roc: 0.8180 - loss: 0.6189 - max_f1_score: 0.7594 - val_auc_pr: 0.8189 - val_auc_roc: 0.7966 - val_loss: 0.8096 - val_max_f1_score: 0.7337\n",
      "Epoch 24/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8315 - auc_roc: 0.8327 - loss: 0.5935 - max_f1_score: 0.7742 - val_auc_pr: 0.8182 - val_auc_roc: 0.7958 - val_loss: 0.7890 - val_max_f1_score: 0.7342\n",
      "Epoch 25/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8416 - auc_roc: 0.8368 - loss: 0.5827 - max_f1_score: 0.7652 - val_auc_pr: 0.8204 - val_auc_roc: 0.7991 - val_loss: 0.7636 - val_max_f1_score: 0.7407\n",
      "Epoch 26/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8352 - auc_roc: 0.8253 - loss: 0.6056 - max_f1_score: 0.7703 - val_auc_pr: 0.8212 - val_auc_roc: 0.8004 - val_loss: 0.7403 - val_max_f1_score: 0.7453\n",
      "Epoch 27/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8080 - auc_roc: 0.8032 - loss: 0.6375 - max_f1_score: 0.7464 - val_auc_pr: 0.8228 - val_auc_roc: 0.8029 - val_loss: 0.7237 - val_max_f1_score: 0.7500\n",
      "Epoch 28/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8280 - auc_roc: 0.8264 - loss: 0.5962 - max_f1_score: 0.7701 - val_auc_pr: 0.8210 - val_auc_roc: 0.8006 - val_loss: 0.7066 - val_max_f1_score: 0.7407\n",
      "Epoch 29/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8806 - auc_roc: 0.8593 - loss: 0.5366 - max_f1_score: 0.7833 - val_auc_pr: 0.8217 - val_auc_roc: 0.8018 - val_loss: 0.6903 - val_max_f1_score: 0.7500\n",
      "Epoch 30/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8276 - auc_roc: 0.8337 - loss: 0.5977 - max_f1_score: 0.7799 - val_auc_pr: 0.8231 - val_auc_roc: 0.8022 - val_loss: 0.6781 - val_max_f1_score: 0.7468\n",
      "Epoch 31/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8351 - auc_roc: 0.8183 - loss: 0.6199 - max_f1_score: 0.7595 - val_auc_pr: 0.8243 - val_auc_roc: 0.8034 - val_loss: 0.6665 - val_max_f1_score: 0.7456\n",
      "Epoch 32/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8677 - auc_roc: 0.8628 - loss: 0.5463 - max_f1_score: 0.8044 - val_auc_pr: 0.8244 - val_auc_roc: 0.8038 - val_loss: 0.6568 - val_max_f1_score: 0.7529\n",
      "Epoch 33/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8770 - auc_roc: 0.8727 - loss: 0.5236 - max_f1_score: 0.8232 - val_auc_pr: 0.8232 - val_auc_roc: 0.8026 - val_loss: 0.6481 - val_max_f1_score: 0.7456\n",
      "Epoch 34/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8842 - auc_roc: 0.8840 - loss: 0.5029 - max_f1_score: 0.8252 - val_auc_pr: 0.8243 - val_auc_roc: 0.8023 - val_loss: 0.6426 - val_max_f1_score: 0.7484\n",
      "Epoch 35/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8873 - auc_roc: 0.8733 - loss: 0.5286 - max_f1_score: 0.8168 - val_auc_pr: 0.8233 - val_auc_roc: 0.8005 - val_loss: 0.6391 - val_max_f1_score: 0.7484\n",
      "Epoch 36/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8400 - auc_roc: 0.8325 - loss: 0.5955 - max_f1_score: 0.7717 - val_auc_pr: 0.8222 - val_auc_roc: 0.7993 - val_loss: 0.6372 - val_max_f1_score: 0.7516\n",
      "Epoch 37/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8144 - auc_roc: 0.8072 - loss: 0.6242 - max_f1_score: 0.7586 - val_auc_pr: 0.8242 - val_auc_roc: 0.8015 - val_loss: 0.6320 - val_max_f1_score: 0.7516\n",
      "Epoch 38/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8500 - auc_roc: 0.8337 - loss: 0.5889 - max_f1_score: 0.7842 - val_auc_pr: 0.8250 - val_auc_roc: 0.8024 - val_loss: 0.6294 - val_max_f1_score: 0.7516\n",
      "Epoch 39/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8423 - auc_roc: 0.8473 - loss: 0.5685 - max_f1_score: 0.7906 - val_auc_pr: 0.8256 - val_auc_roc: 0.8031 - val_loss: 0.6286 - val_max_f1_score: 0.7613\n",
      "Epoch 40/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8517 - auc_roc: 0.8628 - loss: 0.5451 - max_f1_score: 0.7901 - val_auc_pr: 0.8254 - val_auc_roc: 0.8026 - val_loss: 0.6289 - val_max_f1_score: 0.7532\n",
      "Epoch 41/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8503 - auc_roc: 0.8382 - loss: 0.5917 - max_f1_score: 0.7857 - val_auc_pr: 0.8255 - val_auc_roc: 0.8025 - val_loss: 0.6290 - val_max_f1_score: 0.7516\n",
      "Epoch 42/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8531 - auc_roc: 0.8686 - loss: 0.5298 - max_f1_score: 0.7931 - val_auc_pr: 0.8271 - val_auc_roc: 0.8036 - val_loss: 0.6296 - val_max_f1_score: 0.7516\n",
      "Epoch 43/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8637 - auc_roc: 0.8572 - loss: 0.5447 - max_f1_score: 0.7872 - val_auc_pr: 0.8271 - val_auc_roc: 0.8039 - val_loss: 0.6286 - val_max_f1_score: 0.7451\n",
      "Epoch 44/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8271 - auc_roc: 0.8325 - loss: 0.5953 - max_f1_score: 0.7777 - val_auc_pr: 0.8271 - val_auc_roc: 0.8031 - val_loss: 0.6297 - val_max_f1_score: 0.7484\n",
      "Epoch 45/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8406 - auc_roc: 0.8272 - loss: 0.5838 - max_f1_score: 0.7501 - val_auc_pr: 0.8273 - val_auc_roc: 0.8041 - val_loss: 0.6307 - val_max_f1_score: 0.7468\n",
      "Epoch 46/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8614 - auc_roc: 0.8483 - loss: 0.5714 - max_f1_score: 0.7950 - val_auc_pr: 0.8300 - val_auc_roc: 0.8066 - val_loss: 0.6287 - val_max_f1_score: 0.7468\n",
      "Epoch 47/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8514 - auc_roc: 0.8545 - loss: 0.5658 - max_f1_score: 0.7976 - val_auc_pr: 0.8281 - val_auc_roc: 0.8050 - val_loss: 0.6292 - val_max_f1_score: 0.7439\n",
      "Epoch 48/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8698 - auc_roc: 0.8742 - loss: 0.5233 - max_f1_score: 0.8133 - val_auc_pr: 0.8289 - val_auc_roc: 0.8054 - val_loss: 0.6287 - val_max_f1_score: 0.7439\n",
      "Epoch 49/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8490 - auc_roc: 0.8520 - loss: 0.5659 - max_f1_score: 0.7769 - val_auc_pr: 0.8288 - val_auc_roc: 0.8053 - val_loss: 0.6287 - val_max_f1_score: 0.7421\n",
      "Epoch 50/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8624 - auc_roc: 0.8434 - loss: 0.5726 - max_f1_score: 0.7849 - val_auc_pr: 0.8292 - val_auc_roc: 0.8057 - val_loss: 0.6284 - val_max_f1_score: 0.7470\n",
      "Epoch 51/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8331 - auc_roc: 0.8399 - loss: 0.5775 - max_f1_score: 0.7658 - val_auc_pr: 0.8300 - val_auc_roc: 0.8066 - val_loss: 0.6276 - val_max_f1_score: 0.7470\n",
      "Epoch 52/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7983 - auc_roc: 0.8200 - loss: 0.6404 - max_f1_score: 0.7758 - val_auc_pr: 0.8311 - val_auc_roc: 0.8078 - val_loss: 0.6270 - val_max_f1_score: 0.7470\n",
      "Epoch 53/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8227 - auc_roc: 0.8128 - loss: 0.6292 - max_f1_score: 0.7699 - val_auc_pr: 0.8315 - val_auc_roc: 0.8078 - val_loss: 0.6289 - val_max_f1_score: 0.7470\n",
      "Epoch 54/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8677 - auc_roc: 0.8531 - loss: 0.5506 - max_f1_score: 0.7861 - val_auc_pr: 0.8298 - val_auc_roc: 0.8067 - val_loss: 0.6303 - val_max_f1_score: 0.7515\n",
      "Epoch 55/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8566 - auc_roc: 0.8653 - loss: 0.5364 - max_f1_score: 0.7884 - val_auc_pr: 0.8304 - val_auc_roc: 0.8072 - val_loss: 0.6309 - val_max_f1_score: 0.7470\n",
      "Epoch 56/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8509 - auc_roc: 0.8408 - loss: 0.5847 - max_f1_score: 0.7823 - val_auc_pr: 0.8306 - val_auc_roc: 0.8074 - val_loss: 0.6316 - val_max_f1_score: 0.7451\n",
      "Epoch 57/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8521 - auc_roc: 0.8496 - loss: 0.5630 - max_f1_score: 0.7863 - val_auc_pr: 0.8304 - val_auc_roc: 0.8070 - val_loss: 0.6315 - val_max_f1_score: 0.7485\n",
      "Epoch 58/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8680 - auc_roc: 0.8539 - loss: 0.5591 - max_f1_score: 0.7892 - val_auc_pr: 0.8302 - val_auc_roc: 0.8067 - val_loss: 0.6313 - val_max_f1_score: 0.7531\n",
      "Epoch 59/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8127 - auc_roc: 0.8248 - loss: 0.6082 - max_f1_score: 0.7664 - val_auc_pr: 0.8310 - val_auc_roc: 0.8078 - val_loss: 0.6307 - val_max_f1_score: 0.7561\n",
      "Epoch 60/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8383 - auc_roc: 0.8467 - loss: 0.5722 - max_f1_score: 0.7781 - val_auc_pr: 0.8309 - val_auc_roc: 0.8072 - val_loss: 0.6307 - val_max_f1_score: 0.7453\n",
      "Epoch 61/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8510 - auc_roc: 0.8598 - loss: 0.5555 - max_f1_score: 0.8038 - val_auc_pr: 0.8292 - val_auc_roc: 0.8056 - val_loss: 0.6332 - val_max_f1_score: 0.7436\n",
      "Epoch 62/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8508 - auc_roc: 0.8436 - loss: 0.5791 - max_f1_score: 0.7846 - val_auc_pr: 0.8294 - val_auc_roc: 0.8059 - val_loss: 0.6330 - val_max_f1_score: 0.7453\n",
      "Epoch 63/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8829 - auc_roc: 0.8903 - loss: 0.5034 - max_f1_score: 0.8284 - val_auc_pr: 0.8297 - val_auc_roc: 0.8064 - val_loss: 0.6330 - val_max_f1_score: 0.7436\n",
      "Epoch 64/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8869 - auc_roc: 0.8682 - loss: 0.5270 - max_f1_score: 0.8091 - val_auc_pr: 0.8294 - val_auc_roc: 0.8063 - val_loss: 0.6332 - val_max_f1_score: 0.7453\n",
      "Epoch 65/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8750 - auc_roc: 0.8693 - loss: 0.5288 - max_f1_score: 0.7964 - val_auc_pr: 0.8292 - val_auc_roc: 0.8064 - val_loss: 0.6326 - val_max_f1_score: 0.7485\n",
      "Epoch 66/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8565 - auc_roc: 0.8548 - loss: 0.5550 - max_f1_score: 0.7955 - val_auc_pr: 0.8285 - val_auc_roc: 0.8053 - val_loss: 0.6342 - val_max_f1_score: 0.7453\n",
      "Epoch 67/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8167 - auc_roc: 0.8373 - loss: 0.5913 - max_f1_score: 0.7772 - val_auc_pr: 0.8284 - val_auc_roc: 0.8047 - val_loss: 0.6355 - val_max_f1_score: 0.7561\n",
      "Epoch 68/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8429 - auc_roc: 0.8564 - loss: 0.5589 - max_f1_score: 0.7902 - val_auc_pr: 0.8283 - val_auc_roc: 0.8046 - val_loss: 0.6358 - val_max_f1_score: 0.7515\n",
      "Epoch 69/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8304 - auc_roc: 0.8303 - loss: 0.6069 - max_f1_score: 0.7713 - val_auc_pr: 0.8280 - val_auc_roc: 0.8043 - val_loss: 0.6354 - val_max_f1_score: 0.7515\n",
      "Epoch 70/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8465 - auc_roc: 0.8477 - loss: 0.5635 - max_f1_score: 0.7914 - val_auc_pr: 0.8284 - val_auc_roc: 0.8048 - val_loss: 0.6351 - val_max_f1_score: 0.7485\n",
      "Epoch 71/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8485 - auc_roc: 0.8690 - loss: 0.5391 - max_f1_score: 0.8074 - val_auc_pr: 0.8288 - val_auc_roc: 0.8055 - val_loss: 0.6349 - val_max_f1_score: 0.7561\n",
      "Epoch 72/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8684 - auc_roc: 0.8717 - loss: 0.5284 - max_f1_score: 0.8071 - val_auc_pr: 0.8283 - val_auc_roc: 0.8046 - val_loss: 0.6364 - val_max_f1_score: 0.7485\n",
      "Epoch 73/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8594 - auc_roc: 0.8525 - loss: 0.5707 - max_f1_score: 0.8085 - val_auc_pr: 0.8272 - val_auc_roc: 0.8044 - val_loss: 0.6376 - val_max_f1_score: 0.7485\n",
      "Epoch 74/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8771 - auc_roc: 0.8774 - loss: 0.5109 - max_f1_score: 0.8050 - val_auc_pr: 0.8275 - val_auc_roc: 0.8041 - val_loss: 0.6372 - val_max_f1_score: 0.7485\n",
      "Epoch 75/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8977 - auc_roc: 0.8845 - loss: 0.4956 - max_f1_score: 0.8123 - val_auc_pr: 0.8286 - val_auc_roc: 0.8052 - val_loss: 0.6363 - val_max_f1_score: 0.7515\n",
      "Epoch 76/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8519 - auc_roc: 0.8628 - loss: 0.5501 - max_f1_score: 0.8102 - val_auc_pr: 0.8284 - val_auc_roc: 0.8051 - val_loss: 0.6362 - val_max_f1_score: 0.7531\n",
      "Epoch 77/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8516 - auc_roc: 0.8241 - loss: 0.5898 - max_f1_score: 0.7532 - val_auc_pr: 0.8270 - val_auc_roc: 0.8043 - val_loss: 0.6375 - val_max_f1_score: 0.7531\n",
      "Epoch 78/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8723 - auc_roc: 0.8614 - loss: 0.5362 - max_f1_score: 0.8035 - val_auc_pr: 0.8270 - val_auc_roc: 0.8042 - val_loss: 0.6379 - val_max_f1_score: 0.7515\n",
      "Epoch 79/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8031 - auc_roc: 0.8026 - loss: 0.6551 - max_f1_score: 0.7496 - val_auc_pr: 0.8276 - val_auc_roc: 0.8051 - val_loss: 0.6369 - val_max_f1_score: 0.7485\n",
      "Epoch 80/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8406 - auc_roc: 0.8634 - loss: 0.5449 - max_f1_score: 0.7914 - val_auc_pr: 0.8280 - val_auc_roc: 0.8057 - val_loss: 0.6359 - val_max_f1_score: 0.7531\n",
      "Epoch 81/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8564 - auc_roc: 0.8656 - loss: 0.5320 - max_f1_score: 0.7948 - val_auc_pr: 0.8295 - val_auc_roc: 0.8072 - val_loss: 0.6345 - val_max_f1_score: 0.7531\n",
      "Epoch 82/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8782 - auc_roc: 0.8705 - loss: 0.5295 - max_f1_score: 0.8125 - val_auc_pr: 0.8287 - val_auc_roc: 0.8066 - val_loss: 0.6336 - val_max_f1_score: 0.7531\n",
      "Epoch 83/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8098 - auc_roc: 0.8301 - loss: 0.6053 - max_f1_score: 0.7536 - val_auc_pr: 0.8287 - val_auc_roc: 0.8068 - val_loss: 0.6348 - val_max_f1_score: 0.7531\n",
      "Epoch 84/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8753 - auc_roc: 0.8608 - loss: 0.5427 - max_f1_score: 0.8050 - val_auc_pr: 0.8286 - val_auc_roc: 0.8069 - val_loss: 0.6341 - val_max_f1_score: 0.7531\n",
      "Epoch 85/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8691 - auc_roc: 0.8654 - loss: 0.5438 - max_f1_score: 0.8068 - val_auc_pr: 0.8297 - val_auc_roc: 0.8078 - val_loss: 0.6336 - val_max_f1_score: 0.7531\n",
      "Epoch 86/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8720 - auc_roc: 0.8611 - loss: 0.5379 - max_f1_score: 0.7901 - val_auc_pr: 0.8299 - val_auc_roc: 0.8080 - val_loss: 0.6344 - val_max_f1_score: 0.7531\n",
      "Epoch 87/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8896 - auc_roc: 0.8737 - loss: 0.5220 - max_f1_score: 0.8015 - val_auc_pr: 0.8287 - val_auc_roc: 0.8071 - val_loss: 0.6340 - val_max_f1_score: 0.7531\n",
      "Epoch 88/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8920 - auc_roc: 0.8859 - loss: 0.4927 - max_f1_score: 0.8018 - val_auc_pr: 0.8297 - val_auc_roc: 0.8081 - val_loss: 0.6331 - val_max_f1_score: 0.7531\n",
      "Epoch 89/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8329 - auc_roc: 0.8300 - loss: 0.6009 - max_f1_score: 0.7750 - val_auc_pr: 0.8297 - val_auc_roc: 0.8081 - val_loss: 0.6328 - val_max_f1_score: 0.7485\n",
      "Epoch 90/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8852 - auc_roc: 0.8842 - loss: 0.5016 - max_f1_score: 0.8235 - val_auc_pr: 0.8288 - val_auc_roc: 0.8069 - val_loss: 0.6354 - val_max_f1_score: 0.7561\n",
      "Epoch 91/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8819 - auc_roc: 0.8813 - loss: 0.5086 - max_f1_score: 0.8162 - val_auc_pr: 0.8301 - val_auc_roc: 0.8082 - val_loss: 0.6340 - val_max_f1_score: 0.7561\n",
      "Epoch 92/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8797 - auc_roc: 0.8593 - loss: 0.5509 - max_f1_score: 0.8050 - val_auc_pr: 0.8297 - val_auc_roc: 0.8079 - val_loss: 0.6347 - val_max_f1_score: 0.7531\n",
      "Epoch 93/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8760 - auc_roc: 0.8761 - loss: 0.5146 - max_f1_score: 0.7918 - val_auc_pr: 0.8291 - val_auc_roc: 0.8068 - val_loss: 0.6337 - val_max_f1_score: 0.7531\n",
      "Epoch 94/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8632 - auc_roc: 0.8741 - loss: 0.5349 - max_f1_score: 0.8154 - val_auc_pr: 0.8294 - val_auc_roc: 0.8071 - val_loss: 0.6347 - val_max_f1_score: 0.7531\n",
      "Epoch 95/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8833 - auc_roc: 0.8855 - loss: 0.5013 - max_f1_score: 0.8216 - val_auc_pr: 0.8294 - val_auc_roc: 0.8078 - val_loss: 0.6348 - val_max_f1_score: 0.7515\n",
      "Epoch 96/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8797 - auc_roc: 0.8752 - loss: 0.5173 - max_f1_score: 0.8178 - val_auc_pr: 0.8290 - val_auc_roc: 0.8071 - val_loss: 0.6355 - val_max_f1_score: 0.7515\n",
      "Epoch 97/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8888 - auc_roc: 0.8753 - loss: 0.5147 - max_f1_score: 0.8107 - val_auc_pr: 0.8295 - val_auc_roc: 0.8078 - val_loss: 0.6345 - val_max_f1_score: 0.7484\n",
      "Epoch 98/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8690 - auc_roc: 0.8727 - loss: 0.5287 - max_f1_score: 0.8165 - val_auc_pr: 0.8296 - val_auc_roc: 0.8078 - val_loss: 0.6345 - val_max_f1_score: 0.7484\n",
      "Epoch 99/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8605 - auc_roc: 0.8453 - loss: 0.5773 - max_f1_score: 0.7822 - val_auc_pr: 0.8292 - val_auc_roc: 0.8076 - val_loss: 0.6341 - val_max_f1_score: 0.7515\n",
      "Epoch 100/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8935 - auc_roc: 0.8755 - loss: 0.5194 - max_f1_score: 0.8133 - val_auc_pr: 0.8293 - val_auc_roc: 0.8082 - val_loss: 0.6345 - val_max_f1_score: 0.7531\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step\n",
      "Epoch 1/100\n",
      "\u001b[1m 4/19\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.5107 - auc_roc: 0.4572 - loss: 1.1762 - max_f1_score: 0.6513 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-26 16:48:05.845564: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_510', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 516ms/step - auc_pr: 0.5091 - auc_roc: 0.4523 - loss: 1.1464 - max_f1_score: 0.6689 - val_auc_pr: 0.4598 - val_auc_roc: 0.3959 - val_loss: 0.7754 - val_max_f1_score: 0.6667\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.5761 - auc_roc: 0.5931 - loss: 0.9017 - max_f1_score: 0.6681 - val_auc_pr: 0.5998 - val_auc_roc: 0.5540 - val_loss: 0.7821 - val_max_f1_score: 0.6728\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.6434 - auc_roc: 0.6627 - loss: 0.8187 - max_f1_score: 0.6394 - val_auc_pr: 0.6872 - val_auc_roc: 0.6791 - val_loss: 0.7977 - val_max_f1_score: 0.6800\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.6376 - auc_roc: 0.6740 - loss: 0.8304 - max_f1_score: 0.6859 - val_auc_pr: 0.7478 - val_auc_roc: 0.7315 - val_loss: 0.8172 - val_max_f1_score: 0.6970\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.7129 - auc_roc: 0.7103 - loss: 0.7592 - max_f1_score: 0.7204 - val_auc_pr: 0.7799 - val_auc_roc: 0.7654 - val_loss: 0.8387 - val_max_f1_score: 0.7312\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.7229 - auc_roc: 0.7609 - loss: 0.7118 - max_f1_score: 0.7458 - val_auc_pr: 0.8061 - val_auc_roc: 0.7896 - val_loss: 0.8614 - val_max_f1_score: 0.7340\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7389 - auc_roc: 0.7476 - loss: 0.7319 - max_f1_score: 0.7049 - val_auc_pr: 0.8266 - val_auc_roc: 0.8021 - val_loss: 0.8848 - val_max_f1_score: 0.7543\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.7920 - auc_roc: 0.7883 - loss: 0.6673 - max_f1_score: 0.7378 - val_auc_pr: 0.8325 - val_auc_roc: 0.8109 - val_loss: 0.9067 - val_max_f1_score: 0.7349\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7959 - auc_roc: 0.7460 - loss: 0.7239 - max_f1_score: 0.7268 - val_auc_pr: 0.8448 - val_auc_roc: 0.8226 - val_loss: 0.9258 - val_max_f1_score: 0.7486\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7905 - auc_roc: 0.8036 - loss: 0.6346 - max_f1_score: 0.7401 - val_auc_pr: 0.8474 - val_auc_roc: 0.8235 - val_loss: 0.9433 - val_max_f1_score: 0.7368\n",
      "Epoch 11/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7487 - auc_roc: 0.7555 - loss: 0.7016 - max_f1_score: 0.7116 - val_auc_pr: 0.8496 - val_auc_roc: 0.8240 - val_loss: 0.9565 - val_max_f1_score: 0.7340\n",
      "Epoch 12/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8029 - auc_roc: 0.8143 - loss: 0.6115 - max_f1_score: 0.7750 - val_auc_pr: 0.8503 - val_auc_roc: 0.8205 - val_loss: 0.9635 - val_max_f1_score: 0.7347\n",
      "Epoch 13/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8455 - auc_roc: 0.8420 - loss: 0.5792 - max_f1_score: 0.7850 - val_auc_pr: 0.8552 - val_auc_roc: 0.8254 - val_loss: 0.9625 - val_max_f1_score: 0.7429\n",
      "Epoch 14/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7602 - auc_roc: 0.7941 - loss: 0.6580 - max_f1_score: 0.7247 - val_auc_pr: 0.8565 - val_auc_roc: 0.8273 - val_loss: 0.9670 - val_max_f1_score: 0.7342\n",
      "Epoch 15/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7579 - auc_roc: 0.7897 - loss: 0.6709 - max_f1_score: 0.7395 - val_auc_pr: 0.8546 - val_auc_roc: 0.8257 - val_loss: 0.9620 - val_max_f1_score: 0.7368\n",
      "Epoch 16/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8216 - auc_roc: 0.8141 - loss: 0.6144 - max_f1_score: 0.7563 - val_auc_pr: 0.8596 - val_auc_roc: 0.8266 - val_loss: 0.9500 - val_max_f1_score: 0.7399\n",
      "Epoch 17/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7865 - auc_roc: 0.7945 - loss: 0.6593 - max_f1_score: 0.7702 - val_auc_pr: 0.8618 - val_auc_roc: 0.8290 - val_loss: 0.9369 - val_max_f1_score: 0.7451\n",
      "Epoch 18/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7797 - auc_roc: 0.7776 - loss: 0.6793 - max_f1_score: 0.7313 - val_auc_pr: 0.8632 - val_auc_roc: 0.8294 - val_loss: 0.9212 - val_max_f1_score: 0.7413\n",
      "Epoch 19/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7874 - auc_roc: 0.8020 - loss: 0.6417 - max_f1_score: 0.7423 - val_auc_pr: 0.8616 - val_auc_roc: 0.8286 - val_loss: 0.9031 - val_max_f1_score: 0.7368\n",
      "Epoch 20/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8399 - auc_roc: 0.8188 - loss: 0.6106 - max_f1_score: 0.7777 - val_auc_pr: 0.8610 - val_auc_roc: 0.8286 - val_loss: 0.8886 - val_max_f1_score: 0.7482\n",
      "Epoch 21/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8131 - auc_roc: 0.8116 - loss: 0.6203 - max_f1_score: 0.7464 - val_auc_pr: 0.8597 - val_auc_roc: 0.8268 - val_loss: 0.8678 - val_max_f1_score: 0.7465\n",
      "Epoch 22/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8066 - auc_roc: 0.8129 - loss: 0.6283 - max_f1_score: 0.7705 - val_auc_pr: 0.8611 - val_auc_roc: 0.8281 - val_loss: 0.8459 - val_max_f1_score: 0.7626\n",
      "Epoch 23/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8061 - auc_roc: 0.8084 - loss: 0.6298 - max_f1_score: 0.7276 - val_auc_pr: 0.8610 - val_auc_roc: 0.8287 - val_loss: 0.8231 - val_max_f1_score: 0.7518\n",
      "Epoch 24/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8190 - auc_roc: 0.8215 - loss: 0.6069 - max_f1_score: 0.7565 - val_auc_pr: 0.8635 - val_auc_roc: 0.8308 - val_loss: 0.7948 - val_max_f1_score: 0.7518\n",
      "Epoch 25/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8149 - auc_roc: 0.8071 - loss: 0.6537 - max_f1_score: 0.7822 - val_auc_pr: 0.8636 - val_auc_roc: 0.8311 - val_loss: 0.7690 - val_max_f1_score: 0.7518\n",
      "Epoch 26/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.7958 - auc_roc: 0.8214 - loss: 0.6149 - max_f1_score: 0.7740 - val_auc_pr: 0.8642 - val_auc_roc: 0.8300 - val_loss: 0.7458 - val_max_f1_score: 0.7536\n",
      "Epoch 27/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8599 - auc_roc: 0.8620 - loss: 0.5380 - max_f1_score: 0.7969 - val_auc_pr: 0.8651 - val_auc_roc: 0.8317 - val_loss: 0.7229 - val_max_f1_score: 0.7500\n",
      "Epoch 28/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8691 - auc_roc: 0.8616 - loss: 0.5367 - max_f1_score: 0.7894 - val_auc_pr: 0.8644 - val_auc_roc: 0.8307 - val_loss: 0.6981 - val_max_f1_score: 0.7536\n",
      "Epoch 29/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8023 - auc_roc: 0.8252 - loss: 0.5987 - max_f1_score: 0.7539 - val_auc_pr: 0.8644 - val_auc_roc: 0.8312 - val_loss: 0.6792 - val_max_f1_score: 0.7591\n",
      "Epoch 30/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8521 - auc_roc: 0.8263 - loss: 0.6033 - max_f1_score: 0.7759 - val_auc_pr: 0.8636 - val_auc_roc: 0.8294 - val_loss: 0.6604 - val_max_f1_score: 0.7591\n",
      "Epoch 31/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8056 - auc_roc: 0.8282 - loss: 0.6004 - max_f1_score: 0.7567 - val_auc_pr: 0.8642 - val_auc_roc: 0.8292 - val_loss: 0.6442 - val_max_f1_score: 0.7536\n",
      "Epoch 32/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8691 - auc_roc: 0.8588 - loss: 0.5505 - max_f1_score: 0.7974 - val_auc_pr: 0.8634 - val_auc_roc: 0.8267 - val_loss: 0.6317 - val_max_f1_score: 0.7536\n",
      "Epoch 33/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8032 - auc_roc: 0.8083 - loss: 0.6243 - max_f1_score: 0.7672 - val_auc_pr: 0.8646 - val_auc_roc: 0.8295 - val_loss: 0.6198 - val_max_f1_score: 0.7536\n",
      "Epoch 34/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8334 - auc_roc: 0.8495 - loss: 0.5653 - max_f1_score: 0.7872 - val_auc_pr: 0.8645 - val_auc_roc: 0.8284 - val_loss: 0.6096 - val_max_f1_score: 0.7536\n",
      "Epoch 35/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8333 - auc_roc: 0.8642 - loss: 0.5477 - max_f1_score: 0.7835 - val_auc_pr: 0.8655 - val_auc_roc: 0.8290 - val_loss: 0.6031 - val_max_f1_score: 0.7556\n",
      "Epoch 36/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8449 - auc_roc: 0.8489 - loss: 0.5628 - max_f1_score: 0.8001 - val_auc_pr: 0.8659 - val_auc_roc: 0.8291 - val_loss: 0.5984 - val_max_f1_score: 0.7536\n",
      "Epoch 37/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8529 - auc_roc: 0.8631 - loss: 0.5542 - max_f1_score: 0.8205 - val_auc_pr: 0.8658 - val_auc_roc: 0.8279 - val_loss: 0.5943 - val_max_f1_score: 0.7500\n",
      "Epoch 38/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8285 - auc_roc: 0.8239 - loss: 0.6024 - max_f1_score: 0.7724 - val_auc_pr: 0.8653 - val_auc_roc: 0.8265 - val_loss: 0.5908 - val_max_f1_score: 0.7445\n",
      "Epoch 39/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7905 - auc_roc: 0.8176 - loss: 0.6264 - max_f1_score: 0.7711 - val_auc_pr: 0.8653 - val_auc_roc: 0.8265 - val_loss: 0.5873 - val_max_f1_score: 0.7500\n",
      "Epoch 40/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8363 - auc_roc: 0.8289 - loss: 0.6032 - max_f1_score: 0.7861 - val_auc_pr: 0.8660 - val_auc_roc: 0.8268 - val_loss: 0.5839 - val_max_f1_score: 0.7538\n",
      "Epoch 41/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8610 - auc_roc: 0.8526 - loss: 0.5467 - max_f1_score: 0.7733 - val_auc_pr: 0.8668 - val_auc_roc: 0.8273 - val_loss: 0.5830 - val_max_f1_score: 0.7481\n",
      "Epoch 42/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8273 - auc_roc: 0.8404 - loss: 0.5836 - max_f1_score: 0.7747 - val_auc_pr: 0.8670 - val_auc_roc: 0.8280 - val_loss: 0.5800 - val_max_f1_score: 0.7538\n",
      "Epoch 43/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8237 - auc_roc: 0.8326 - loss: 0.5914 - max_f1_score: 0.7673 - val_auc_pr: 0.8672 - val_auc_roc: 0.8279 - val_loss: 0.5776 - val_max_f1_score: 0.7538\n",
      "Epoch 44/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7809 - auc_roc: 0.8066 - loss: 0.6573 - max_f1_score: 0.7680 - val_auc_pr: 0.8679 - val_auc_roc: 0.8285 - val_loss: 0.5766 - val_max_f1_score: 0.7538\n",
      "Epoch 45/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8244 - auc_roc: 0.8374 - loss: 0.5866 - max_f1_score: 0.7803 - val_auc_pr: 0.8680 - val_auc_roc: 0.8283 - val_loss: 0.5756 - val_max_f1_score: 0.7538\n",
      "Epoch 46/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8355 - auc_roc: 0.8326 - loss: 0.5972 - max_f1_score: 0.7790 - val_auc_pr: 0.8678 - val_auc_roc: 0.8283 - val_loss: 0.5752 - val_max_f1_score: 0.7481\n",
      "Epoch 47/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8493 - auc_roc: 0.8454 - loss: 0.5660 - max_f1_score: 0.8014 - val_auc_pr: 0.8671 - val_auc_roc: 0.8278 - val_loss: 0.5745 - val_max_f1_score: 0.7538\n",
      "Epoch 48/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8377 - auc_roc: 0.8236 - loss: 0.6038 - max_f1_score: 0.7589 - val_auc_pr: 0.8667 - val_auc_roc: 0.8280 - val_loss: 0.5738 - val_max_f1_score: 0.7538\n",
      "Epoch 49/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8322 - auc_roc: 0.8580 - loss: 0.5574 - max_f1_score: 0.7905 - val_auc_pr: 0.8677 - val_auc_roc: 0.8293 - val_loss: 0.5725 - val_max_f1_score: 0.7538\n",
      "Epoch 50/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8425 - auc_roc: 0.8437 - loss: 0.5742 - max_f1_score: 0.7910 - val_auc_pr: 0.8686 - val_auc_roc: 0.8302 - val_loss: 0.5724 - val_max_f1_score: 0.7538\n",
      "Epoch 51/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7979 - auc_roc: 0.8278 - loss: 0.6115 - max_f1_score: 0.7661 - val_auc_pr: 0.8681 - val_auc_roc: 0.8293 - val_loss: 0.5727 - val_max_f1_score: 0.7538\n",
      "Epoch 52/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8466 - auc_roc: 0.8389 - loss: 0.5825 - max_f1_score: 0.7830 - val_auc_pr: 0.8682 - val_auc_roc: 0.8294 - val_loss: 0.5727 - val_max_f1_score: 0.7556\n",
      "Epoch 53/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8495 - auc_roc: 0.8460 - loss: 0.5719 - max_f1_score: 0.7913 - val_auc_pr: 0.8672 - val_auc_roc: 0.8282 - val_loss: 0.5721 - val_max_f1_score: 0.7538\n",
      "Epoch 54/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8684 - auc_roc: 0.8590 - loss: 0.5424 - max_f1_score: 0.8097 - val_auc_pr: 0.8676 - val_auc_roc: 0.8286 - val_loss: 0.5718 - val_max_f1_score: 0.7556\n",
      "Epoch 55/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8482 - auc_roc: 0.8423 - loss: 0.5714 - max_f1_score: 0.7780 - val_auc_pr: 0.8675 - val_auc_roc: 0.8287 - val_loss: 0.5711 - val_max_f1_score: 0.7556\n",
      "Epoch 56/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8390 - auc_roc: 0.8492 - loss: 0.5706 - max_f1_score: 0.7898 - val_auc_pr: 0.8680 - val_auc_roc: 0.8292 - val_loss: 0.5711 - val_max_f1_score: 0.7556\n",
      "Epoch 57/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8423 - auc_roc: 0.8393 - loss: 0.5769 - max_f1_score: 0.7766 - val_auc_pr: 0.8677 - val_auc_roc: 0.8288 - val_loss: 0.5711 - val_max_f1_score: 0.7556\n",
      "Epoch 58/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8505 - auc_roc: 0.8420 - loss: 0.5779 - max_f1_score: 0.7906 - val_auc_pr: 0.8675 - val_auc_roc: 0.8280 - val_loss: 0.5719 - val_max_f1_score: 0.7556\n",
      "Epoch 59/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8034 - auc_roc: 0.8164 - loss: 0.6273 - max_f1_score: 0.7543 - val_auc_pr: 0.8676 - val_auc_roc: 0.8278 - val_loss: 0.5727 - val_max_f1_score: 0.7556\n",
      "Epoch 60/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8118 - auc_roc: 0.8263 - loss: 0.6162 - max_f1_score: 0.7780 - val_auc_pr: 0.8676 - val_auc_roc: 0.8277 - val_loss: 0.5723 - val_max_f1_score: 0.7556\n",
      "Epoch 61/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8145 - auc_roc: 0.8155 - loss: 0.6209 - max_f1_score: 0.7583 - val_auc_pr: 0.8676 - val_auc_roc: 0.8283 - val_loss: 0.5721 - val_max_f1_score: 0.7556\n",
      "Epoch 62/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8076 - auc_roc: 0.8299 - loss: 0.5954 - max_f1_score: 0.7622 - val_auc_pr: 0.8672 - val_auc_roc: 0.8276 - val_loss: 0.5718 - val_max_f1_score: 0.7556\n",
      "Epoch 63/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8336 - auc_roc: 0.8304 - loss: 0.5906 - max_f1_score: 0.7734 - val_auc_pr: 0.8681 - val_auc_roc: 0.8285 - val_loss: 0.5713 - val_max_f1_score: 0.7556\n",
      "Epoch 64/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8520 - auc_roc: 0.8419 - loss: 0.5724 - max_f1_score: 0.7846 - val_auc_pr: 0.8672 - val_auc_roc: 0.8274 - val_loss: 0.5715 - val_max_f1_score: 0.7556\n",
      "Epoch 65/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8620 - auc_roc: 0.8472 - loss: 0.5717 - max_f1_score: 0.7833 - val_auc_pr: 0.8678 - val_auc_roc: 0.8278 - val_loss: 0.5719 - val_max_f1_score: 0.7538\n",
      "Epoch 66/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8377 - auc_roc: 0.8304 - loss: 0.5956 - max_f1_score: 0.7710 - val_auc_pr: 0.8678 - val_auc_roc: 0.8282 - val_loss: 0.5721 - val_max_f1_score: 0.7556\n",
      "Epoch 67/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8230 - auc_roc: 0.8309 - loss: 0.5861 - max_f1_score: 0.7793 - val_auc_pr: 0.8679 - val_auc_roc: 0.8280 - val_loss: 0.5725 - val_max_f1_score: 0.7556\n",
      "Epoch 68/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8446 - auc_roc: 0.8527 - loss: 0.5554 - max_f1_score: 0.8069 - val_auc_pr: 0.8678 - val_auc_roc: 0.8278 - val_loss: 0.5726 - val_max_f1_score: 0.7556\n",
      "Epoch 69/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8202 - auc_roc: 0.8504 - loss: 0.5777 - max_f1_score: 0.7838 - val_auc_pr: 0.8676 - val_auc_roc: 0.8287 - val_loss: 0.5722 - val_max_f1_score: 0.7556\n",
      "Epoch 70/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8421 - auc_roc: 0.8513 - loss: 0.5631 - max_f1_score: 0.7895 - val_auc_pr: 0.8679 - val_auc_roc: 0.8286 - val_loss: 0.5718 - val_max_f1_score: 0.7556\n",
      "Epoch 71/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8571 - auc_roc: 0.8415 - loss: 0.5679 - max_f1_score: 0.7697 - val_auc_pr: 0.8683 - val_auc_roc: 0.8297 - val_loss: 0.5713 - val_max_f1_score: 0.7556\n",
      "Epoch 72/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8540 - auc_roc: 0.8476 - loss: 0.5538 - max_f1_score: 0.7788 - val_auc_pr: 0.8684 - val_auc_roc: 0.8296 - val_loss: 0.5711 - val_max_f1_score: 0.7556\n",
      "Epoch 73/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8537 - auc_roc: 0.8480 - loss: 0.5645 - max_f1_score: 0.7837 - val_auc_pr: 0.8683 - val_auc_roc: 0.8295 - val_loss: 0.5706 - val_max_f1_score: 0.7612\n",
      "Epoch 74/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8306 - auc_roc: 0.8533 - loss: 0.5671 - max_f1_score: 0.7926 - val_auc_pr: 0.8677 - val_auc_roc: 0.8283 - val_loss: 0.5705 - val_max_f1_score: 0.7612\n",
      "Epoch 75/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8525 - auc_roc: 0.8475 - loss: 0.5754 - max_f1_score: 0.7895 - val_auc_pr: 0.8688 - val_auc_roc: 0.8294 - val_loss: 0.5702 - val_max_f1_score: 0.7669\n",
      "Epoch 76/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8313 - auc_roc: 0.8398 - loss: 0.5822 - max_f1_score: 0.7862 - val_auc_pr: 0.8688 - val_auc_roc: 0.8293 - val_loss: 0.5702 - val_max_f1_score: 0.7669\n",
      "Epoch 77/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8556 - auc_roc: 0.8591 - loss: 0.5517 - max_f1_score: 0.8010 - val_auc_pr: 0.8690 - val_auc_roc: 0.8297 - val_loss: 0.5695 - val_max_f1_score: 0.7669\n",
      "Epoch 78/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8275 - auc_roc: 0.8343 - loss: 0.6037 - max_f1_score: 0.7874 - val_auc_pr: 0.8690 - val_auc_roc: 0.8297 - val_loss: 0.5696 - val_max_f1_score: 0.7669\n",
      "Epoch 79/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8642 - auc_roc: 0.8497 - loss: 0.5575 - max_f1_score: 0.7948 - val_auc_pr: 0.8686 - val_auc_roc: 0.8286 - val_loss: 0.5707 - val_max_f1_score: 0.7669\n",
      "Epoch 80/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8737 - auc_roc: 0.8711 - loss: 0.5255 - max_f1_score: 0.7974 - val_auc_pr: 0.8691 - val_auc_roc: 0.8292 - val_loss: 0.5708 - val_max_f1_score: 0.7669\n",
      "Epoch 81/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8409 - auc_roc: 0.8395 - loss: 0.5888 - max_f1_score: 0.7823 - val_auc_pr: 0.8694 - val_auc_roc: 0.8299 - val_loss: 0.5700 - val_max_f1_score: 0.7669\n",
      "Epoch 82/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8541 - auc_roc: 0.8405 - loss: 0.5713 - max_f1_score: 0.7692 - val_auc_pr: 0.8698 - val_auc_roc: 0.8309 - val_loss: 0.5694 - val_max_f1_score: 0.7669\n",
      "Epoch 83/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8423 - auc_roc: 0.8445 - loss: 0.5707 - max_f1_score: 0.7973 - val_auc_pr: 0.8692 - val_auc_roc: 0.8306 - val_loss: 0.5691 - val_max_f1_score: 0.7669\n",
      "Epoch 84/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8315 - auc_roc: 0.8546 - loss: 0.5609 - max_f1_score: 0.7834 - val_auc_pr: 0.8692 - val_auc_roc: 0.8305 - val_loss: 0.5698 - val_max_f1_score: 0.7669\n",
      "Epoch 85/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8491 - auc_roc: 0.8497 - loss: 0.5654 - max_f1_score: 0.8037 - val_auc_pr: 0.8691 - val_auc_roc: 0.8300 - val_loss: 0.5698 - val_max_f1_score: 0.7669\n",
      "Epoch 86/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8544 - auc_roc: 0.8460 - loss: 0.5728 - max_f1_score: 0.7884 - val_auc_pr: 0.8704 - val_auc_roc: 0.8315 - val_loss: 0.5694 - val_max_f1_score: 0.7612\n",
      "Epoch 87/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8327 - auc_roc: 0.8458 - loss: 0.5828 - max_f1_score: 0.7826 - val_auc_pr: 0.8706 - val_auc_roc: 0.8316 - val_loss: 0.5698 - val_max_f1_score: 0.7669\n",
      "Epoch 88/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8290 - auc_roc: 0.8482 - loss: 0.5618 - max_f1_score: 0.7810 - val_auc_pr: 0.8704 - val_auc_roc: 0.8316 - val_loss: 0.5697 - val_max_f1_score: 0.7669\n",
      "Epoch 89/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8157 - auc_roc: 0.8269 - loss: 0.6116 - max_f1_score: 0.7626 - val_auc_pr: 0.8704 - val_auc_roc: 0.8317 - val_loss: 0.5695 - val_max_f1_score: 0.7612\n",
      "Epoch 90/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8327 - auc_roc: 0.8448 - loss: 0.5823 - max_f1_score: 0.7916 - val_auc_pr: 0.8708 - val_auc_roc: 0.8321 - val_loss: 0.5687 - val_max_f1_score: 0.7576\n",
      "Epoch 91/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8651 - auc_roc: 0.8587 - loss: 0.5511 - max_f1_score: 0.7990 - val_auc_pr: 0.8709 - val_auc_roc: 0.8323 - val_loss: 0.5669 - val_max_f1_score: 0.7634\n",
      "Epoch 92/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8574 - auc_roc: 0.8573 - loss: 0.5418 - max_f1_score: 0.7698 - val_auc_pr: 0.8702 - val_auc_roc: 0.8321 - val_loss: 0.5665 - val_max_f1_score: 0.7576\n",
      "Epoch 93/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8291 - auc_roc: 0.8415 - loss: 0.5797 - max_f1_score: 0.7714 - val_auc_pr: 0.8703 - val_auc_roc: 0.8321 - val_loss: 0.5668 - val_max_f1_score: 0.7669\n",
      "Epoch 94/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8584 - auc_roc: 0.8529 - loss: 0.5455 - max_f1_score: 0.7773 - val_auc_pr: 0.8701 - val_auc_roc: 0.8320 - val_loss: 0.5673 - val_max_f1_score: 0.7669\n",
      "Epoch 95/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7898 - auc_roc: 0.8203 - loss: 0.6261 - max_f1_score: 0.7897 - val_auc_pr: 0.8700 - val_auc_roc: 0.8314 - val_loss: 0.5675 - val_max_f1_score: 0.7669\n",
      "Epoch 96/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8511 - auc_roc: 0.8396 - loss: 0.5831 - max_f1_score: 0.7977 - val_auc_pr: 0.8706 - val_auc_roc: 0.8323 - val_loss: 0.5671 - val_max_f1_score: 0.7669\n",
      "Epoch 97/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8473 - auc_roc: 0.8555 - loss: 0.5519 - max_f1_score: 0.7745 - val_auc_pr: 0.8705 - val_auc_roc: 0.8323 - val_loss: 0.5666 - val_max_f1_score: 0.7669\n",
      "Epoch 98/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8509 - auc_roc: 0.8592 - loss: 0.5466 - max_f1_score: 0.7988 - val_auc_pr: 0.8704 - val_auc_roc: 0.8324 - val_loss: 0.5661 - val_max_f1_score: 0.7669\n",
      "Epoch 99/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8537 - auc_roc: 0.8676 - loss: 0.5334 - max_f1_score: 0.8122 - val_auc_pr: 0.8702 - val_auc_roc: 0.8320 - val_loss: 0.5667 - val_max_f1_score: 0.7669\n",
      "Epoch 100/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8617 - auc_roc: 0.8621 - loss: 0.5454 - max_f1_score: 0.7945 - val_auc_pr: 0.8704 - val_auc_roc: 0.8317 - val_loss: 0.5663 - val_max_f1_score: 0.7669\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 256ms/step - auc_pr: 0.4637 - auc_roc: 0.4061 - loss: 1.1869 - max_f1_score: 0.6723 - val_auc_pr: 0.5734 - val_auc_roc: 0.5385 - val_loss: 0.7704 - val_max_f1_score: 0.6636\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.5074 - auc_roc: 0.5139 - loss: 1.0202 - max_f1_score: 0.6522 - val_auc_pr: 0.7178 - val_auc_roc: 0.6906 - val_loss: 0.7759 - val_max_f1_score: 0.6667\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.6641 - auc_roc: 0.6625 - loss: 0.8159 - max_f1_score: 0.7103 - val_auc_pr: 0.7777 - val_auc_roc: 0.7458 - val_loss: 0.7907 - val_max_f1_score: 0.6882\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.6890 - auc_roc: 0.7041 - loss: 0.7768 - max_f1_score: 0.6821 - val_auc_pr: 0.7946 - val_auc_roc: 0.7763 - val_loss: 0.8123 - val_max_f1_score: 0.7119\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.7081 - auc_roc: 0.7118 - loss: 0.7723 - max_f1_score: 0.6909 - val_auc_pr: 0.8040 - val_auc_roc: 0.7856 - val_loss: 0.8371 - val_max_f1_score: 0.7250\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7379 - auc_roc: 0.7581 - loss: 0.7018 - max_f1_score: 0.7045 - val_auc_pr: 0.8150 - val_auc_roc: 0.7961 - val_loss: 0.8621 - val_max_f1_score: 0.7284\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7504 - auc_roc: 0.7326 - loss: 0.7577 - max_f1_score: 0.7118 - val_auc_pr: 0.8232 - val_auc_roc: 0.8028 - val_loss: 0.8860 - val_max_f1_score: 0.7200\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7376 - auc_roc: 0.7553 - loss: 0.7191 - max_f1_score: 0.7131 - val_auc_pr: 0.8312 - val_auc_roc: 0.8092 - val_loss: 0.9061 - val_max_f1_score: 0.7259\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7809 - auc_roc: 0.7792 - loss: 0.6933 - max_f1_score: 0.7266 - val_auc_pr: 0.8324 - val_auc_roc: 0.8128 - val_loss: 0.9272 - val_max_f1_score: 0.7234\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8115 - auc_roc: 0.7970 - loss: 0.6458 - max_f1_score: 0.7423 - val_auc_pr: 0.8339 - val_auc_roc: 0.8147 - val_loss: 0.9421 - val_max_f1_score: 0.7261\n",
      "Epoch 11/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.7950 - auc_roc: 0.7919 - loss: 0.6546 - max_f1_score: 0.7348 - val_auc_pr: 0.8323 - val_auc_roc: 0.8136 - val_loss: 0.9572 - val_max_f1_score: 0.7320\n",
      "Epoch 12/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7365 - auc_roc: 0.7462 - loss: 0.7483 - max_f1_score: 0.7066 - val_auc_pr: 0.8373 - val_auc_roc: 0.8197 - val_loss: 0.9661 - val_max_f1_score: 0.7314\n",
      "Epoch 13/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8062 - auc_roc: 0.7862 - loss: 0.6666 - max_f1_score: 0.7442 - val_auc_pr: 0.8336 - val_auc_roc: 0.8188 - val_loss: 0.9647 - val_max_f1_score: 0.7467\n",
      "Epoch 14/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8202 - auc_roc: 0.8058 - loss: 0.6387 - max_f1_score: 0.7626 - val_auc_pr: 0.8346 - val_auc_roc: 0.8198 - val_loss: 0.9624 - val_max_f1_score: 0.7516\n",
      "Epoch 15/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7835 - auc_roc: 0.7954 - loss: 0.6540 - max_f1_score: 0.7533 - val_auc_pr: 0.8384 - val_auc_roc: 0.8248 - val_loss: 0.9583 - val_max_f1_score: 0.7500\n",
      "Epoch 16/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8505 - auc_roc: 0.8255 - loss: 0.6024 - max_f1_score: 0.7822 - val_auc_pr: 0.8364 - val_auc_roc: 0.8224 - val_loss: 0.9503 - val_max_f1_score: 0.7517\n",
      "Epoch 17/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8135 - auc_roc: 0.8124 - loss: 0.6227 - max_f1_score: 0.7482 - val_auc_pr: 0.8405 - val_auc_roc: 0.8277 - val_loss: 0.9364 - val_max_f1_score: 0.7531\n",
      "Epoch 18/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8460 - auc_roc: 0.8240 - loss: 0.6018 - max_f1_score: 0.7735 - val_auc_pr: 0.8406 - val_auc_roc: 0.8284 - val_loss: 0.9199 - val_max_f1_score: 0.7531\n",
      "Epoch 19/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8436 - auc_roc: 0.8209 - loss: 0.6064 - max_f1_score: 0.7624 - val_auc_pr: 0.8404 - val_auc_roc: 0.8307 - val_loss: 0.9040 - val_max_f1_score: 0.7578\n",
      "Epoch 20/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7733 - auc_roc: 0.7886 - loss: 0.6812 - max_f1_score: 0.7422 - val_auc_pr: 0.8390 - val_auc_roc: 0.8303 - val_loss: 0.8852 - val_max_f1_score: 0.7712\n",
      "Epoch 21/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8342 - auc_roc: 0.8209 - loss: 0.6160 - max_f1_score: 0.7597 - val_auc_pr: 0.8402 - val_auc_roc: 0.8326 - val_loss: 0.8630 - val_max_f1_score: 0.7662\n",
      "Epoch 22/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8110 - auc_roc: 0.8345 - loss: 0.5923 - max_f1_score: 0.7727 - val_auc_pr: 0.8406 - val_auc_roc: 0.8328 - val_loss: 0.8446 - val_max_f1_score: 0.7662\n",
      "Epoch 23/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8759 - auc_roc: 0.8555 - loss: 0.5568 - max_f1_score: 0.8012 - val_auc_pr: 0.8397 - val_auc_roc: 0.8329 - val_loss: 0.8237 - val_max_f1_score: 0.7742\n",
      "Epoch 24/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8136 - auc_roc: 0.8141 - loss: 0.6330 - max_f1_score: 0.7808 - val_auc_pr: 0.8384 - val_auc_roc: 0.8329 - val_loss: 0.8038 - val_max_f1_score: 0.7692\n",
      "Epoch 25/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8535 - auc_roc: 0.8451 - loss: 0.5702 - max_f1_score: 0.7798 - val_auc_pr: 0.8397 - val_auc_roc: 0.8337 - val_loss: 0.7880 - val_max_f1_score: 0.7692\n",
      "Epoch 26/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8044 - auc_roc: 0.8086 - loss: 0.6398 - max_f1_score: 0.7688 - val_auc_pr: 0.8377 - val_auc_roc: 0.8326 - val_loss: 0.7626 - val_max_f1_score: 0.7673\n",
      "Epoch 27/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8535 - auc_roc: 0.8653 - loss: 0.5409 - max_f1_score: 0.7983 - val_auc_pr: 0.8341 - val_auc_roc: 0.8309 - val_loss: 0.7401 - val_max_f1_score: 0.7730\n",
      "Epoch 28/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8362 - auc_roc: 0.8508 - loss: 0.5737 - max_f1_score: 0.7902 - val_auc_pr: 0.8357 - val_auc_roc: 0.8340 - val_loss: 0.7211 - val_max_f1_score: 0.7730\n",
      "Epoch 29/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8877 - auc_roc: 0.8756 - loss: 0.5106 - max_f1_score: 0.7983 - val_auc_pr: 0.8379 - val_auc_roc: 0.8347 - val_loss: 0.7008 - val_max_f1_score: 0.7712\n",
      "Epoch 30/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8234 - auc_roc: 0.8387 - loss: 0.6011 - max_f1_score: 0.7921 - val_auc_pr: 0.8399 - val_auc_roc: 0.8372 - val_loss: 0.6831 - val_max_f1_score: 0.7848\n",
      "Epoch 31/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8477 - auc_roc: 0.8439 - loss: 0.5867 - max_f1_score: 0.7981 - val_auc_pr: 0.8388 - val_auc_roc: 0.8367 - val_loss: 0.6664 - val_max_f1_score: 0.7792\n",
      "Epoch 32/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8271 - auc_roc: 0.8362 - loss: 0.5824 - max_f1_score: 0.7855 - val_auc_pr: 0.8379 - val_auc_roc: 0.8373 - val_loss: 0.6537 - val_max_f1_score: 0.7778\n",
      "Epoch 33/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8458 - auc_roc: 0.8303 - loss: 0.6031 - max_f1_score: 0.7940 - val_auc_pr: 0.8360 - val_auc_roc: 0.8346 - val_loss: 0.6462 - val_max_f1_score: 0.7750\n",
      "Epoch 34/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8672 - auc_roc: 0.8435 - loss: 0.5709 - max_f1_score: 0.7727 - val_auc_pr: 0.8383 - val_auc_roc: 0.8376 - val_loss: 0.6342 - val_max_f1_score: 0.7826\n",
      "Epoch 35/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8508 - auc_roc: 0.8297 - loss: 0.5918 - max_f1_score: 0.7683 - val_auc_pr: 0.8393 - val_auc_roc: 0.8388 - val_loss: 0.6250 - val_max_f1_score: 0.7758\n",
      "Epoch 36/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8643 - auc_roc: 0.8441 - loss: 0.5700 - max_f1_score: 0.7933 - val_auc_pr: 0.8384 - val_auc_roc: 0.8366 - val_loss: 0.6184 - val_max_f1_score: 0.7758\n",
      "Epoch 37/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8680 - auc_roc: 0.8501 - loss: 0.5627 - max_f1_score: 0.7967 - val_auc_pr: 0.8386 - val_auc_roc: 0.8378 - val_loss: 0.6135 - val_max_f1_score: 0.7758\n",
      "Epoch 38/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8062 - auc_roc: 0.8125 - loss: 0.6440 - max_f1_score: 0.7532 - val_auc_pr: 0.8368 - val_auc_roc: 0.8369 - val_loss: 0.6090 - val_max_f1_score: 0.7730\n",
      "Epoch 39/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8095 - auc_roc: 0.8240 - loss: 0.6144 - max_f1_score: 0.7690 - val_auc_pr: 0.8361 - val_auc_roc: 0.8374 - val_loss: 0.6045 - val_max_f1_score: 0.7778\n",
      "Epoch 40/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8908 - auc_roc: 0.8709 - loss: 0.5193 - max_f1_score: 0.7994 - val_auc_pr: 0.8365 - val_auc_roc: 0.8374 - val_loss: 0.6019 - val_max_f1_score: 0.7758\n",
      "Epoch 41/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8216 - auc_roc: 0.8558 - loss: 0.5812 - max_f1_score: 0.8069 - val_auc_pr: 0.8369 - val_auc_roc: 0.8381 - val_loss: 0.5992 - val_max_f1_score: 0.7805\n",
      "Epoch 42/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8689 - auc_roc: 0.8510 - loss: 0.5608 - max_f1_score: 0.7936 - val_auc_pr: 0.8377 - val_auc_roc: 0.8391 - val_loss: 0.5962 - val_max_f1_score: 0.7805\n",
      "Epoch 43/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8377 - auc_roc: 0.8277 - loss: 0.6019 - max_f1_score: 0.7676 - val_auc_pr: 0.8373 - val_auc_roc: 0.8385 - val_loss: 0.5937 - val_max_f1_score: 0.7805\n",
      "Epoch 44/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8479 - auc_roc: 0.8364 - loss: 0.5887 - max_f1_score: 0.7904 - val_auc_pr: 0.8389 - val_auc_roc: 0.8393 - val_loss: 0.5909 - val_max_f1_score: 0.7805\n",
      "Epoch 45/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8384 - auc_roc: 0.8395 - loss: 0.5843 - max_f1_score: 0.7803 - val_auc_pr: 0.8408 - val_auc_roc: 0.8409 - val_loss: 0.5888 - val_max_f1_score: 0.7805\n",
      "Epoch 46/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8394 - auc_roc: 0.8334 - loss: 0.5920 - max_f1_score: 0.7780 - val_auc_pr: 0.8392 - val_auc_roc: 0.8401 - val_loss: 0.5871 - val_max_f1_score: 0.7805\n",
      "Epoch 47/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8410 - auc_roc: 0.8368 - loss: 0.5905 - max_f1_score: 0.7838 - val_auc_pr: 0.8396 - val_auc_roc: 0.8399 - val_loss: 0.5864 - val_max_f1_score: 0.7805\n",
      "Epoch 48/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8468 - auc_roc: 0.8576 - loss: 0.5501 - max_f1_score: 0.8110 - val_auc_pr: 0.8393 - val_auc_roc: 0.8397 - val_loss: 0.5865 - val_max_f1_score: 0.7805\n",
      "Epoch 49/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8951 - auc_roc: 0.8834 - loss: 0.5058 - max_f1_score: 0.8159 - val_auc_pr: 0.8397 - val_auc_roc: 0.8396 - val_loss: 0.5862 - val_max_f1_score: 0.7805\n",
      "Epoch 50/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8671 - auc_roc: 0.8617 - loss: 0.5502 - max_f1_score: 0.8091 - val_auc_pr: 0.8405 - val_auc_roc: 0.8396 - val_loss: 0.5853 - val_max_f1_score: 0.7805\n",
      "Epoch 51/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7988 - auc_roc: 0.8272 - loss: 0.6131 - max_f1_score: 0.7626 - val_auc_pr: 0.8392 - val_auc_roc: 0.8392 - val_loss: 0.5843 - val_max_f1_score: 0.7805\n",
      "Epoch 52/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8467 - auc_roc: 0.8245 - loss: 0.5971 - max_f1_score: 0.7572 - val_auc_pr: 0.8414 - val_auc_roc: 0.8409 - val_loss: 0.5833 - val_max_f1_score: 0.7805\n",
      "Epoch 53/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8686 - auc_roc: 0.8637 - loss: 0.5388 - max_f1_score: 0.8056 - val_auc_pr: 0.8414 - val_auc_roc: 0.8406 - val_loss: 0.5844 - val_max_f1_score: 0.7805\n",
      "Epoch 54/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.9021 - auc_roc: 0.8821 - loss: 0.5036 - max_f1_score: 0.8177 - val_auc_pr: 0.8438 - val_auc_roc: 0.8417 - val_loss: 0.5841 - val_max_f1_score: 0.7805\n",
      "Epoch 55/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8497 - auc_roc: 0.8380 - loss: 0.5746 - max_f1_score: 0.7684 - val_auc_pr: 0.8422 - val_auc_roc: 0.8415 - val_loss: 0.5834 - val_max_f1_score: 0.7805\n",
      "Epoch 56/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8763 - auc_roc: 0.8606 - loss: 0.5545 - max_f1_score: 0.8031 - val_auc_pr: 0.8423 - val_auc_roc: 0.8416 - val_loss: 0.5841 - val_max_f1_score: 0.7805\n",
      "Epoch 57/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8738 - auc_roc: 0.8584 - loss: 0.5447 - max_f1_score: 0.7929 - val_auc_pr: 0.8423 - val_auc_roc: 0.8415 - val_loss: 0.5841 - val_max_f1_score: 0.7805\n",
      "Epoch 58/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8253 - auc_roc: 0.8415 - loss: 0.5813 - max_f1_score: 0.7769 - val_auc_pr: 0.8428 - val_auc_roc: 0.8419 - val_loss: 0.5842 - val_max_f1_score: 0.7805\n",
      "Epoch 59/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8878 - auc_roc: 0.8504 - loss: 0.5813 - max_f1_score: 0.8079 - val_auc_pr: 0.8421 - val_auc_roc: 0.8418 - val_loss: 0.5845 - val_max_f1_score: 0.7805\n",
      "Epoch 60/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8951 - auc_roc: 0.8677 - loss: 0.5420 - max_f1_score: 0.8124 - val_auc_pr: 0.8429 - val_auc_roc: 0.8428 - val_loss: 0.5838 - val_max_f1_score: 0.7771\n",
      "Epoch 61/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8619 - auc_roc: 0.8601 - loss: 0.5394 - max_f1_score: 0.7874 - val_auc_pr: 0.8417 - val_auc_roc: 0.8420 - val_loss: 0.5841 - val_max_f1_score: 0.7826\n",
      "Epoch 62/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8745 - auc_roc: 0.8640 - loss: 0.5368 - max_f1_score: 0.7914 - val_auc_pr: 0.8412 - val_auc_roc: 0.8410 - val_loss: 0.5832 - val_max_f1_score: 0.7805\n",
      "Epoch 63/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8687 - auc_roc: 0.8654 - loss: 0.5347 - max_f1_score: 0.7994 - val_auc_pr: 0.8403 - val_auc_roc: 0.8409 - val_loss: 0.5833 - val_max_f1_score: 0.7826\n",
      "Epoch 64/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8322 - auc_roc: 0.8237 - loss: 0.6095 - max_f1_score: 0.7758 - val_auc_pr: 0.8433 - val_auc_roc: 0.8419 - val_loss: 0.5831 - val_max_f1_score: 0.7826\n",
      "Epoch 65/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8402 - auc_roc: 0.8339 - loss: 0.5911 - max_f1_score: 0.7640 - val_auc_pr: 0.8423 - val_auc_roc: 0.8420 - val_loss: 0.5834 - val_max_f1_score: 0.7826\n",
      "Epoch 66/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8330 - auc_roc: 0.8519 - loss: 0.5744 - max_f1_score: 0.7989 - val_auc_pr: 0.8427 - val_auc_roc: 0.8422 - val_loss: 0.5827 - val_max_f1_score: 0.7805\n",
      "Epoch 67/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8893 - auc_roc: 0.8761 - loss: 0.5124 - max_f1_score: 0.8080 - val_auc_pr: 0.8432 - val_auc_roc: 0.8425 - val_loss: 0.5821 - val_max_f1_score: 0.7826\n",
      "Epoch 68/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8506 - auc_roc: 0.8325 - loss: 0.5881 - max_f1_score: 0.7644 - val_auc_pr: 0.8431 - val_auc_roc: 0.8423 - val_loss: 0.5831 - val_max_f1_score: 0.7826\n",
      "Epoch 69/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8308 - auc_roc: 0.8159 - loss: 0.6117 - max_f1_score: 0.7543 - val_auc_pr: 0.8424 - val_auc_roc: 0.8417 - val_loss: 0.5839 - val_max_f1_score: 0.7805\n",
      "Epoch 70/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8690 - auc_roc: 0.8753 - loss: 0.5181 - max_f1_score: 0.7961 - val_auc_pr: 0.8433 - val_auc_roc: 0.8419 - val_loss: 0.5834 - val_max_f1_score: 0.7805\n",
      "Epoch 71/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8457 - auc_roc: 0.8343 - loss: 0.5929 - max_f1_score: 0.7747 - val_auc_pr: 0.8416 - val_auc_roc: 0.8410 - val_loss: 0.5822 - val_max_f1_score: 0.7805\n",
      "Epoch 72/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8402 - auc_roc: 0.8500 - loss: 0.5670 - max_f1_score: 0.7845 - val_auc_pr: 0.8419 - val_auc_roc: 0.8414 - val_loss: 0.5811 - val_max_f1_score: 0.7826\n",
      "Epoch 73/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8459 - auc_roc: 0.8589 - loss: 0.5508 - max_f1_score: 0.8018 - val_auc_pr: 0.8433 - val_auc_roc: 0.8431 - val_loss: 0.5796 - val_max_f1_score: 0.7826\n",
      "Epoch 74/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8552 - auc_roc: 0.8546 - loss: 0.5631 - max_f1_score: 0.7910 - val_auc_pr: 0.8426 - val_auc_roc: 0.8425 - val_loss: 0.5804 - val_max_f1_score: 0.7805\n",
      "Epoch 75/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8514 - auc_roc: 0.8618 - loss: 0.5458 - max_f1_score: 0.8074 - val_auc_pr: 0.8436 - val_auc_roc: 0.8418 - val_loss: 0.5810 - val_max_f1_score: 0.7805\n",
      "Epoch 76/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8779 - auc_roc: 0.8607 - loss: 0.5395 - max_f1_score: 0.7853 - val_auc_pr: 0.8428 - val_auc_roc: 0.8418 - val_loss: 0.5811 - val_max_f1_score: 0.7826\n",
      "Epoch 77/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8406 - auc_roc: 0.8319 - loss: 0.5927 - max_f1_score: 0.7711 - val_auc_pr: 0.8434 - val_auc_roc: 0.8424 - val_loss: 0.5816 - val_max_f1_score: 0.7826\n",
      "Epoch 78/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8592 - auc_roc: 0.8525 - loss: 0.5616 - max_f1_score: 0.7946 - val_auc_pr: 0.8430 - val_auc_roc: 0.8426 - val_loss: 0.5818 - val_max_f1_score: 0.7826\n",
      "Epoch 79/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8656 - auc_roc: 0.8733 - loss: 0.5207 - max_f1_score: 0.7925 - val_auc_pr: 0.8431 - val_auc_roc: 0.8423 - val_loss: 0.5817 - val_max_f1_score: 0.7848\n",
      "Epoch 80/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8463 - auc_roc: 0.8383 - loss: 0.6045 - max_f1_score: 0.7872 - val_auc_pr: 0.8415 - val_auc_roc: 0.8420 - val_loss: 0.5822 - val_max_f1_score: 0.7826\n",
      "Epoch 81/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8691 - auc_roc: 0.8583 - loss: 0.5459 - max_f1_score: 0.8022 - val_auc_pr: 0.8429 - val_auc_roc: 0.8426 - val_loss: 0.5811 - val_max_f1_score: 0.7805\n",
      "Epoch 82/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8568 - auc_roc: 0.8516 - loss: 0.5598 - max_f1_score: 0.7842 - val_auc_pr: 0.8446 - val_auc_roc: 0.8442 - val_loss: 0.5797 - val_max_f1_score: 0.7805\n",
      "Epoch 83/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8640 - auc_roc: 0.8624 - loss: 0.5378 - max_f1_score: 0.7950 - val_auc_pr: 0.8424 - val_auc_roc: 0.8427 - val_loss: 0.5808 - val_max_f1_score: 0.7778\n",
      "Epoch 84/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8606 - auc_roc: 0.8624 - loss: 0.5384 - max_f1_score: 0.7970 - val_auc_pr: 0.8431 - val_auc_roc: 0.8426 - val_loss: 0.5827 - val_max_f1_score: 0.7778\n",
      "Epoch 85/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8551 - auc_roc: 0.8509 - loss: 0.5582 - max_f1_score: 0.7853 - val_auc_pr: 0.8423 - val_auc_roc: 0.8422 - val_loss: 0.5843 - val_max_f1_score: 0.7805\n",
      "Epoch 86/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8547 - auc_roc: 0.8446 - loss: 0.5637 - max_f1_score: 0.7815 - val_auc_pr: 0.8431 - val_auc_roc: 0.8427 - val_loss: 0.5837 - val_max_f1_score: 0.7826\n",
      "Epoch 87/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8712 - auc_roc: 0.8691 - loss: 0.5257 - max_f1_score: 0.7986 - val_auc_pr: 0.8427 - val_auc_roc: 0.8423 - val_loss: 0.5844 - val_max_f1_score: 0.7805\n",
      "Epoch 88/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8689 - auc_roc: 0.8668 - loss: 0.5335 - max_f1_score: 0.8082 - val_auc_pr: 0.8423 - val_auc_roc: 0.8435 - val_loss: 0.5832 - val_max_f1_score: 0.7875\n",
      "Epoch 89/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8729 - auc_roc: 0.8799 - loss: 0.5271 - max_f1_score: 0.8255 - val_auc_pr: 0.8428 - val_auc_roc: 0.8434 - val_loss: 0.5821 - val_max_f1_score: 0.7826\n",
      "Epoch 90/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8674 - auc_roc: 0.8503 - loss: 0.5687 - max_f1_score: 0.7953 - val_auc_pr: 0.8439 - val_auc_roc: 0.8439 - val_loss: 0.5818 - val_max_f1_score: 0.7826\n",
      "Epoch 91/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8612 - auc_roc: 0.8279 - loss: 0.6194 - max_f1_score: 0.7925 - val_auc_pr: 0.8437 - val_auc_roc: 0.8437 - val_loss: 0.5805 - val_max_f1_score: 0.7848\n",
      "Epoch 92/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8763 - auc_roc: 0.8671 - loss: 0.5280 - max_f1_score: 0.7931 - val_auc_pr: 0.8430 - val_auc_roc: 0.8431 - val_loss: 0.5800 - val_max_f1_score: 0.7778\n",
      "Epoch 93/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8713 - auc_roc: 0.8462 - loss: 0.5741 - max_f1_score: 0.7929 - val_auc_pr: 0.8436 - val_auc_roc: 0.8442 - val_loss: 0.5800 - val_max_f1_score: 0.7848\n",
      "Epoch 94/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8574 - auc_roc: 0.8726 - loss: 0.5372 - max_f1_score: 0.8114 - val_auc_pr: 0.8442 - val_auc_roc: 0.8443 - val_loss: 0.5798 - val_max_f1_score: 0.7925\n",
      "Epoch 95/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8561 - auc_roc: 0.8467 - loss: 0.5738 - max_f1_score: 0.8037 - val_auc_pr: 0.8437 - val_auc_roc: 0.8438 - val_loss: 0.5801 - val_max_f1_score: 0.7848\n",
      "Epoch 96/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8718 - auc_roc: 0.8656 - loss: 0.5340 - max_f1_score: 0.8017 - val_auc_pr: 0.8439 - val_auc_roc: 0.8446 - val_loss: 0.5796 - val_max_f1_score: 0.7848\n",
      "Epoch 97/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8540 - auc_roc: 0.8502 - loss: 0.5576 - max_f1_score: 0.7756 - val_auc_pr: 0.8433 - val_auc_roc: 0.8440 - val_loss: 0.5794 - val_max_f1_score: 0.7799\n",
      "Epoch 98/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8102 - auc_roc: 0.8213 - loss: 0.6266 - max_f1_score: 0.7913 - val_auc_pr: 0.8434 - val_auc_roc: 0.8445 - val_loss: 0.5792 - val_max_f1_score: 0.7799\n",
      "Epoch 99/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8475 - auc_roc: 0.8361 - loss: 0.5960 - max_f1_score: 0.7989 - val_auc_pr: 0.8429 - val_auc_roc: 0.8443 - val_loss: 0.5778 - val_max_f1_score: 0.7898\n",
      "Epoch 100/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8682 - auc_roc: 0.8557 - loss: 0.5506 - max_f1_score: 0.7984 - val_auc_pr: 0.8434 - val_auc_roc: 0.8445 - val_loss: 0.5781 - val_max_f1_score: 0.7898\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 272ms/step - auc_pr: 0.4685 - auc_roc: 0.4552 - loss: 1.1082 - max_f1_score: 0.6520 - val_auc_pr: 0.4587 - val_auc_roc: 0.4780 - val_loss: 0.7717 - val_max_f1_score: 0.6636\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.5307 - auc_roc: 0.5510 - loss: 0.9799 - max_f1_score: 0.6593 - val_auc_pr: 0.6039 - val_auc_roc: 0.6329 - val_loss: 0.7778 - val_max_f1_score: 0.6778\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.6743 - auc_roc: 0.6859 - loss: 0.7766 - max_f1_score: 0.6784 - val_auc_pr: 0.6899 - val_auc_roc: 0.7032 - val_loss: 0.7912 - val_max_f1_score: 0.6788\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7054 - auc_roc: 0.7222 - loss: 0.7588 - max_f1_score: 0.7073 - val_auc_pr: 0.7102 - val_auc_roc: 0.7087 - val_loss: 0.8111 - val_max_f1_score: 0.6832\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.6973 - auc_roc: 0.7032 - loss: 0.7893 - max_f1_score: 0.7272 - val_auc_pr: 0.7401 - val_auc_roc: 0.7279 - val_loss: 0.8335 - val_max_f1_score: 0.6854\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7628 - auc_roc: 0.7525 - loss: 0.7217 - max_f1_score: 0.7175 - val_auc_pr: 0.7487 - val_auc_roc: 0.7351 - val_loss: 0.8589 - val_max_f1_score: 0.6971\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.7534 - auc_roc: 0.7544 - loss: 0.7021 - max_f1_score: 0.7243 - val_auc_pr: 0.7699 - val_auc_roc: 0.7412 - val_loss: 0.8858 - val_max_f1_score: 0.6882\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7495 - auc_roc: 0.7346 - loss: 0.7347 - max_f1_score: 0.7172 - val_auc_pr: 0.7725 - val_auc_roc: 0.7528 - val_loss: 0.9059 - val_max_f1_score: 0.7030\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7685 - auc_roc: 0.7769 - loss: 0.6855 - max_f1_score: 0.7452 - val_auc_pr: 0.7840 - val_auc_roc: 0.7573 - val_loss: 0.9267 - val_max_f1_score: 0.7011\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7776 - auc_roc: 0.7912 - loss: 0.6550 - max_f1_score: 0.7552 - val_auc_pr: 0.7854 - val_auc_roc: 0.7614 - val_loss: 0.9425 - val_max_f1_score: 0.7073\n",
      "Epoch 11/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7490 - auc_roc: 0.7600 - loss: 0.7087 - max_f1_score: 0.7154 - val_auc_pr: 0.7907 - val_auc_roc: 0.7674 - val_loss: 0.9549 - val_max_f1_score: 0.7083\n",
      "Epoch 12/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8252 - auc_roc: 0.8229 - loss: 0.6157 - max_f1_score: 0.7756 - val_auc_pr: 0.7880 - val_auc_roc: 0.7691 - val_loss: 0.9634 - val_max_f1_score: 0.7066\n",
      "Epoch 13/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7701 - auc_roc: 0.7660 - loss: 0.7028 - max_f1_score: 0.7279 - val_auc_pr: 0.7946 - val_auc_roc: 0.7714 - val_loss: 0.9698 - val_max_f1_score: 0.7286\n",
      "Epoch 14/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8147 - auc_roc: 0.8136 - loss: 0.6180 - max_f1_score: 0.7372 - val_auc_pr: 0.7968 - val_auc_roc: 0.7752 - val_loss: 0.9698 - val_max_f1_score: 0.7059\n",
      "Epoch 15/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8188 - auc_roc: 0.8361 - loss: 0.5913 - max_f1_score: 0.7714 - val_auc_pr: 0.8006 - val_auc_roc: 0.7773 - val_loss: 0.9674 - val_max_f1_score: 0.7172\n",
      "Epoch 16/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.7823 - auc_roc: 0.7859 - loss: 0.6742 - max_f1_score: 0.7363 - val_auc_pr: 0.8008 - val_auc_roc: 0.7793 - val_loss: 0.9631 - val_max_f1_score: 0.7172\n",
      "Epoch 17/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7958 - auc_roc: 0.8002 - loss: 0.6553 - max_f1_score: 0.7435 - val_auc_pr: 0.8004 - val_auc_roc: 0.7828 - val_loss: 0.9506 - val_max_f1_score: 0.7286\n",
      "Epoch 18/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.7916 - auc_roc: 0.7786 - loss: 0.6807 - max_f1_score: 0.7363 - val_auc_pr: 0.8027 - val_auc_roc: 0.7829 - val_loss: 0.9418 - val_max_f1_score: 0.7324\n",
      "Epoch 19/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8411 - auc_roc: 0.8264 - loss: 0.6039 - max_f1_score: 0.7689 - val_auc_pr: 0.8042 - val_auc_roc: 0.7832 - val_loss: 0.9252 - val_max_f1_score: 0.7324\n",
      "Epoch 20/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8203 - auc_roc: 0.8161 - loss: 0.6138 - max_f1_score: 0.7651 - val_auc_pr: 0.8055 - val_auc_roc: 0.7831 - val_loss: 0.9077 - val_max_f1_score: 0.7273\n",
      "Epoch 21/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8260 - auc_roc: 0.8371 - loss: 0.5884 - max_f1_score: 0.7775 - val_auc_pr: 0.8047 - val_auc_roc: 0.7815 - val_loss: 0.8863 - val_max_f1_score: 0.7324\n",
      "Epoch 22/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7996 - auc_roc: 0.8101 - loss: 0.6302 - max_f1_score: 0.7544 - val_auc_pr: 0.8100 - val_auc_roc: 0.7858 - val_loss: 0.8685 - val_max_f1_score: 0.7324\n",
      "Epoch 23/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8213 - auc_roc: 0.8160 - loss: 0.6106 - max_f1_score: 0.7685 - val_auc_pr: 0.8086 - val_auc_roc: 0.7845 - val_loss: 0.8498 - val_max_f1_score: 0.7429\n",
      "Epoch 24/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8053 - auc_roc: 0.8217 - loss: 0.6106 - max_f1_score: 0.7641 - val_auc_pr: 0.8137 - val_auc_roc: 0.7903 - val_loss: 0.8310 - val_max_f1_score: 0.7391\n",
      "Epoch 25/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8267 - auc_roc: 0.7957 - loss: 0.6447 - max_f1_score: 0.7695 - val_auc_pr: 0.8134 - val_auc_roc: 0.7881 - val_loss: 0.8082 - val_max_f1_score: 0.7333\n",
      "Epoch 26/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8576 - auc_roc: 0.8444 - loss: 0.5659 - max_f1_score: 0.7907 - val_auc_pr: 0.8143 - val_auc_roc: 0.7896 - val_loss: 0.7876 - val_max_f1_score: 0.7333\n",
      "Epoch 27/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8182 - auc_roc: 0.8229 - loss: 0.6098 - max_f1_score: 0.7581 - val_auc_pr: 0.8152 - val_auc_roc: 0.7903 - val_loss: 0.7672 - val_max_f1_score: 0.7383\n",
      "Epoch 28/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8554 - auc_roc: 0.8593 - loss: 0.5546 - max_f1_score: 0.8041 - val_auc_pr: 0.8151 - val_auc_roc: 0.7896 - val_loss: 0.7464 - val_max_f1_score: 0.7333\n",
      "Epoch 29/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8391 - auc_roc: 0.8514 - loss: 0.5596 - max_f1_score: 0.7751 - val_auc_pr: 0.8144 - val_auc_roc: 0.7897 - val_loss: 0.7321 - val_max_f1_score: 0.7347\n",
      "Epoch 30/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8301 - auc_roc: 0.8341 - loss: 0.5806 - max_f1_score: 0.7570 - val_auc_pr: 0.8152 - val_auc_roc: 0.7905 - val_loss: 0.7185 - val_max_f1_score: 0.7429\n",
      "Epoch 31/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8525 - auc_roc: 0.8480 - loss: 0.5614 - max_f1_score: 0.7766 - val_auc_pr: 0.8161 - val_auc_roc: 0.7914 - val_loss: 0.7054 - val_max_f1_score: 0.7432\n",
      "Epoch 32/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8804 - auc_roc: 0.8612 - loss: 0.5528 - max_f1_score: 0.8031 - val_auc_pr: 0.8161 - val_auc_roc: 0.7913 - val_loss: 0.6945 - val_max_f1_score: 0.7432\n",
      "Epoch 33/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8490 - auc_roc: 0.8569 - loss: 0.5566 - max_f1_score: 0.8139 - val_auc_pr: 0.8163 - val_auc_roc: 0.7922 - val_loss: 0.6843 - val_max_f1_score: 0.7518\n",
      "Epoch 34/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8303 - auc_roc: 0.8289 - loss: 0.5955 - max_f1_score: 0.7740 - val_auc_pr: 0.8140 - val_auc_roc: 0.7911 - val_loss: 0.6778 - val_max_f1_score: 0.7397\n",
      "Epoch 35/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8537 - auc_roc: 0.8444 - loss: 0.5752 - max_f1_score: 0.7994 - val_auc_pr: 0.8167 - val_auc_roc: 0.7923 - val_loss: 0.6727 - val_max_f1_score: 0.7518\n",
      "Epoch 36/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8600 - auc_roc: 0.8605 - loss: 0.5397 - max_f1_score: 0.7883 - val_auc_pr: 0.8169 - val_auc_roc: 0.7931 - val_loss: 0.6690 - val_max_f1_score: 0.7413\n",
      "Epoch 37/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8665 - auc_roc: 0.8582 - loss: 0.5508 - max_f1_score: 0.8004 - val_auc_pr: 0.8166 - val_auc_roc: 0.7933 - val_loss: 0.6642 - val_max_f1_score: 0.7397\n",
      "Epoch 38/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8634 - auc_roc: 0.8657 - loss: 0.5372 - max_f1_score: 0.7990 - val_auc_pr: 0.8165 - val_auc_roc: 0.7925 - val_loss: 0.6613 - val_max_f1_score: 0.7383\n",
      "Epoch 39/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8048 - auc_roc: 0.8091 - loss: 0.6341 - max_f1_score: 0.7568 - val_auc_pr: 0.8160 - val_auc_roc: 0.7939 - val_loss: 0.6581 - val_max_f1_score: 0.7391\n",
      "Epoch 40/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8321 - auc_roc: 0.8347 - loss: 0.5985 - max_f1_score: 0.7739 - val_auc_pr: 0.8176 - val_auc_roc: 0.7947 - val_loss: 0.6575 - val_max_f1_score: 0.7391\n",
      "Epoch 41/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8589 - auc_roc: 0.8501 - loss: 0.5639 - max_f1_score: 0.7819 - val_auc_pr: 0.8177 - val_auc_roc: 0.7953 - val_loss: 0.6572 - val_max_f1_score: 0.7391\n",
      "Epoch 42/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8781 - auc_roc: 0.8629 - loss: 0.5412 - max_f1_score: 0.7944 - val_auc_pr: 0.8174 - val_auc_roc: 0.7955 - val_loss: 0.6578 - val_max_f1_score: 0.7413\n",
      "Epoch 43/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8302 - auc_roc: 0.8297 - loss: 0.5918 - max_f1_score: 0.7774 - val_auc_pr: 0.8189 - val_auc_roc: 0.7964 - val_loss: 0.6580 - val_max_f1_score: 0.7397\n",
      "Epoch 44/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8743 - auc_roc: 0.8647 - loss: 0.5353 - max_f1_score: 0.7955 - val_auc_pr: 0.8178 - val_auc_roc: 0.7952 - val_loss: 0.6567 - val_max_f1_score: 0.7413\n",
      "Epoch 45/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8421 - auc_roc: 0.8387 - loss: 0.5855 - max_f1_score: 0.7897 - val_auc_pr: 0.8172 - val_auc_roc: 0.7938 - val_loss: 0.6574 - val_max_f1_score: 0.7391\n",
      "Epoch 46/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8732 - auc_roc: 0.8751 - loss: 0.5174 - max_f1_score: 0.8093 - val_auc_pr: 0.8171 - val_auc_roc: 0.7946 - val_loss: 0.6579 - val_max_f1_score: 0.7391\n",
      "Epoch 47/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8673 - auc_roc: 0.8591 - loss: 0.5445 - max_f1_score: 0.7940 - val_auc_pr: 0.8170 - val_auc_roc: 0.7946 - val_loss: 0.6574 - val_max_f1_score: 0.7397\n",
      "Epoch 48/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8260 - auc_roc: 0.8445 - loss: 0.5811 - max_f1_score: 0.7905 - val_auc_pr: 0.8186 - val_auc_roc: 0.7947 - val_loss: 0.6570 - val_max_f1_score: 0.7391\n",
      "Epoch 49/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8749 - auc_roc: 0.8630 - loss: 0.5366 - max_f1_score: 0.7913 - val_auc_pr: 0.8184 - val_auc_roc: 0.7950 - val_loss: 0.6570 - val_max_f1_score: 0.7397\n",
      "Epoch 50/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8757 - auc_roc: 0.8700 - loss: 0.5255 - max_f1_score: 0.8038 - val_auc_pr: 0.8169 - val_auc_roc: 0.7946 - val_loss: 0.6574 - val_max_f1_score: 0.7391\n",
      "Epoch 51/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8005 - auc_roc: 0.8119 - loss: 0.6335 - max_f1_score: 0.7625 - val_auc_pr: 0.8177 - val_auc_roc: 0.7946 - val_loss: 0.6570 - val_max_f1_score: 0.7391\n",
      "Epoch 52/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8415 - auc_roc: 0.8618 - loss: 0.5506 - max_f1_score: 0.7920 - val_auc_pr: 0.8184 - val_auc_roc: 0.7951 - val_loss: 0.6572 - val_max_f1_score: 0.7448\n",
      "Epoch 53/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8211 - auc_roc: 0.8303 - loss: 0.6015 - max_f1_score: 0.7703 - val_auc_pr: 0.8189 - val_auc_roc: 0.7954 - val_loss: 0.6566 - val_max_f1_score: 0.7448\n",
      "Epoch 54/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8470 - auc_roc: 0.8393 - loss: 0.5723 - max_f1_score: 0.7761 - val_auc_pr: 0.8196 - val_auc_roc: 0.7959 - val_loss: 0.6560 - val_max_f1_score: 0.7448\n",
      "Epoch 55/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8656 - auc_roc: 0.8675 - loss: 0.5319 - max_f1_score: 0.7944 - val_auc_pr: 0.8200 - val_auc_roc: 0.7958 - val_loss: 0.6562 - val_max_f1_score: 0.7448\n",
      "Epoch 56/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8253 - auc_roc: 0.8293 - loss: 0.5937 - max_f1_score: 0.7667 - val_auc_pr: 0.8198 - val_auc_roc: 0.7960 - val_loss: 0.6567 - val_max_f1_score: 0.7448\n",
      "Epoch 57/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8516 - auc_roc: 0.8509 - loss: 0.5809 - max_f1_score: 0.7901 - val_auc_pr: 0.8206 - val_auc_roc: 0.7965 - val_loss: 0.6561 - val_max_f1_score: 0.7448\n",
      "Epoch 58/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8495 - auc_roc: 0.8517 - loss: 0.5609 - max_f1_score: 0.7812 - val_auc_pr: 0.8207 - val_auc_roc: 0.7959 - val_loss: 0.6560 - val_max_f1_score: 0.7448\n",
      "Epoch 59/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8277 - auc_roc: 0.8255 - loss: 0.6045 - max_f1_score: 0.7615 - val_auc_pr: 0.8202 - val_auc_roc: 0.7955 - val_loss: 0.6556 - val_max_f1_score: 0.7448\n",
      "Epoch 60/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8524 - auc_roc: 0.8525 - loss: 0.5546 - max_f1_score: 0.7876 - val_auc_pr: 0.8219 - val_auc_roc: 0.7969 - val_loss: 0.6556 - val_max_f1_score: 0.7448\n",
      "Epoch 61/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8899 - auc_roc: 0.8723 - loss: 0.5221 - max_f1_score: 0.8059 - val_auc_pr: 0.8196 - val_auc_roc: 0.7957 - val_loss: 0.6559 - val_max_f1_score: 0.7448\n",
      "Epoch 62/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8272 - auc_roc: 0.8273 - loss: 0.6003 - max_f1_score: 0.7809 - val_auc_pr: 0.8200 - val_auc_roc: 0.7960 - val_loss: 0.6561 - val_max_f1_score: 0.7448\n",
      "Epoch 63/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8667 - auc_roc: 0.8658 - loss: 0.5302 - max_f1_score: 0.8007 - val_auc_pr: 0.8194 - val_auc_roc: 0.7952 - val_loss: 0.6564 - val_max_f1_score: 0.7448\n",
      "Epoch 64/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8673 - auc_roc: 0.8655 - loss: 0.5372 - max_f1_score: 0.8023 - val_auc_pr: 0.8198 - val_auc_roc: 0.7954 - val_loss: 0.6561 - val_max_f1_score: 0.7448\n",
      "Epoch 65/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8669 - auc_roc: 0.8588 - loss: 0.5435 - max_f1_score: 0.7866 - val_auc_pr: 0.8201 - val_auc_roc: 0.7963 - val_loss: 0.6558 - val_max_f1_score: 0.7448\n",
      "Epoch 66/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8736 - auc_roc: 0.8606 - loss: 0.5478 - max_f1_score: 0.8103 - val_auc_pr: 0.8209 - val_auc_roc: 0.7961 - val_loss: 0.6555 - val_max_f1_score: 0.7448\n",
      "Epoch 67/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8416 - auc_roc: 0.8532 - loss: 0.5605 - max_f1_score: 0.7939 - val_auc_pr: 0.8208 - val_auc_roc: 0.7963 - val_loss: 0.6557 - val_max_f1_score: 0.7448\n",
      "Epoch 68/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8606 - auc_roc: 0.8503 - loss: 0.5640 - max_f1_score: 0.7945 - val_auc_pr: 0.8222 - val_auc_roc: 0.7965 - val_loss: 0.6558 - val_max_f1_score: 0.7448\n",
      "Epoch 69/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8902 - auc_roc: 0.8846 - loss: 0.5018 - max_f1_score: 0.8227 - val_auc_pr: 0.8226 - val_auc_roc: 0.7973 - val_loss: 0.6551 - val_max_f1_score: 0.7448\n",
      "Epoch 70/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8976 - auc_roc: 0.8759 - loss: 0.5120 - max_f1_score: 0.8061 - val_auc_pr: 0.8241 - val_auc_roc: 0.7978 - val_loss: 0.6550 - val_max_f1_score: 0.7448\n",
      "Epoch 71/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8389 - auc_roc: 0.8613 - loss: 0.5483 - max_f1_score: 0.7874 - val_auc_pr: 0.8236 - val_auc_roc: 0.7979 - val_loss: 0.6553 - val_max_f1_score: 0.7500\n",
      "Epoch 72/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8494 - auc_roc: 0.8720 - loss: 0.5387 - max_f1_score: 0.8246 - val_auc_pr: 0.8250 - val_auc_roc: 0.7994 - val_loss: 0.6556 - val_max_f1_score: 0.7448\n",
      "Epoch 73/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8362 - auc_roc: 0.8441 - loss: 0.5664 - max_f1_score: 0.7839 - val_auc_pr: 0.8240 - val_auc_roc: 0.7983 - val_loss: 0.6558 - val_max_f1_score: 0.7448\n",
      "Epoch 74/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8753 - auc_roc: 0.8565 - loss: 0.5440 - max_f1_score: 0.7903 - val_auc_pr: 0.8245 - val_auc_roc: 0.7986 - val_loss: 0.6557 - val_max_f1_score: 0.7448\n",
      "Epoch 75/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8767 - auc_roc: 0.8687 - loss: 0.5227 - max_f1_score: 0.7942 - val_auc_pr: 0.8231 - val_auc_roc: 0.7979 - val_loss: 0.6556 - val_max_f1_score: 0.7448\n",
      "Epoch 76/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.7727 - auc_roc: 0.8243 - loss: 0.6108 - max_f1_score: 0.7242 - val_auc_pr: 0.8232 - val_auc_roc: 0.7976 - val_loss: 0.6542 - val_max_f1_score: 0.7448\n",
      "Epoch 77/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8395 - auc_roc: 0.8528 - loss: 0.5575 - max_f1_score: 0.7744 - val_auc_pr: 0.8253 - val_auc_roc: 0.7990 - val_loss: 0.6545 - val_max_f1_score: 0.7448\n",
      "Epoch 78/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8428 - auc_roc: 0.8427 - loss: 0.5814 - max_f1_score: 0.7867 - val_auc_pr: 0.8259 - val_auc_roc: 0.7986 - val_loss: 0.6547 - val_max_f1_score: 0.7448\n",
      "Epoch 79/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8689 - auc_roc: 0.8794 - loss: 0.5211 - max_f1_score: 0.8290 - val_auc_pr: 0.8243 - val_auc_roc: 0.7981 - val_loss: 0.6545 - val_max_f1_score: 0.7448\n",
      "Epoch 80/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8376 - auc_roc: 0.8507 - loss: 0.5704 - max_f1_score: 0.7967 - val_auc_pr: 0.8241 - val_auc_roc: 0.7980 - val_loss: 0.6547 - val_max_f1_score: 0.7448\n",
      "Epoch 81/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8628 - auc_roc: 0.8667 - loss: 0.5384 - max_f1_score: 0.8076 - val_auc_pr: 0.8226 - val_auc_roc: 0.7971 - val_loss: 0.6546 - val_max_f1_score: 0.7448\n",
      "Epoch 82/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8707 - auc_roc: 0.8539 - loss: 0.5673 - max_f1_score: 0.8103 - val_auc_pr: 0.8237 - val_auc_roc: 0.7977 - val_loss: 0.6542 - val_max_f1_score: 0.7448\n",
      "Epoch 83/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8865 - auc_roc: 0.8766 - loss: 0.5103 - max_f1_score: 0.8115 - val_auc_pr: 0.8229 - val_auc_roc: 0.7976 - val_loss: 0.6544 - val_max_f1_score: 0.7448\n",
      "Epoch 84/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8633 - auc_roc: 0.8692 - loss: 0.5281 - max_f1_score: 0.8010 - val_auc_pr: 0.8244 - val_auc_roc: 0.7984 - val_loss: 0.6546 - val_max_f1_score: 0.7448\n",
      "Epoch 85/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8950 - auc_roc: 0.8795 - loss: 0.5131 - max_f1_score: 0.8215 - val_auc_pr: 0.8235 - val_auc_roc: 0.7977 - val_loss: 0.6551 - val_max_f1_score: 0.7448\n",
      "Epoch 86/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8694 - auc_roc: 0.8635 - loss: 0.5377 - max_f1_score: 0.8041 - val_auc_pr: 0.8237 - val_auc_roc: 0.7975 - val_loss: 0.6549 - val_max_f1_score: 0.7448\n",
      "Epoch 87/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8565 - auc_roc: 0.8712 - loss: 0.5239 - max_f1_score: 0.7850 - val_auc_pr: 0.8244 - val_auc_roc: 0.7982 - val_loss: 0.6544 - val_max_f1_score: 0.7448\n",
      "Epoch 88/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8852 - auc_roc: 0.8758 - loss: 0.5242 - max_f1_score: 0.8162 - val_auc_pr: 0.8239 - val_auc_roc: 0.7982 - val_loss: 0.6543 - val_max_f1_score: 0.7448\n",
      "Epoch 89/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8585 - auc_roc: 0.8600 - loss: 0.5420 - max_f1_score: 0.7918 - val_auc_pr: 0.8241 - val_auc_roc: 0.7985 - val_loss: 0.6544 - val_max_f1_score: 0.7448\n",
      "Epoch 90/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.9001 - auc_roc: 0.8912 - loss: 0.4886 - max_f1_score: 0.8189 - val_auc_pr: 0.8238 - val_auc_roc: 0.7984 - val_loss: 0.6540 - val_max_f1_score: 0.7448\n",
      "Epoch 91/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8642 - auc_roc: 0.8506 - loss: 0.5585 - max_f1_score: 0.8022 - val_auc_pr: 0.8237 - val_auc_roc: 0.7978 - val_loss: 0.6537 - val_max_f1_score: 0.7448\n",
      "Epoch 92/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8771 - auc_roc: 0.8719 - loss: 0.5213 - max_f1_score: 0.7992 - val_auc_pr: 0.8240 - val_auc_roc: 0.7983 - val_loss: 0.6530 - val_max_f1_score: 0.7448\n",
      "Epoch 93/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc_pr: 0.8557 - auc_roc: 0.8458 - loss: 0.5766 - max_f1_score: 0.7831 - val_auc_pr: 0.8239 - val_auc_roc: 0.7984 - val_loss: 0.6530 - val_max_f1_score: 0.7500\n",
      "Epoch 94/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8448 - auc_roc: 0.8487 - loss: 0.5659 - max_f1_score: 0.7966 - val_auc_pr: 0.8247 - val_auc_roc: 0.7994 - val_loss: 0.6532 - val_max_f1_score: 0.7552\n",
      "Epoch 95/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8588 - auc_roc: 0.8534 - loss: 0.5519 - max_f1_score: 0.7974 - val_auc_pr: 0.8243 - val_auc_roc: 0.7982 - val_loss: 0.6533 - val_max_f1_score: 0.7552\n",
      "Epoch 96/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8709 - auc_roc: 0.8657 - loss: 0.5418 - max_f1_score: 0.8200 - val_auc_pr: 0.8239 - val_auc_roc: 0.7986 - val_loss: 0.6528 - val_max_f1_score: 0.7552\n",
      "Epoch 97/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8952 - auc_roc: 0.8865 - loss: 0.4926 - max_f1_score: 0.8087 - val_auc_pr: 0.8242 - val_auc_roc: 0.7991 - val_loss: 0.6524 - val_max_f1_score: 0.7552\n",
      "Epoch 98/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8790 - auc_roc: 0.8816 - loss: 0.5093 - max_f1_score: 0.8014 - val_auc_pr: 0.8234 - val_auc_roc: 0.7986 - val_loss: 0.6518 - val_max_f1_score: 0.7552\n",
      "Epoch 99/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8789 - auc_roc: 0.8773 - loss: 0.5092 - max_f1_score: 0.7977 - val_auc_pr: 0.8247 - val_auc_roc: 0.7989 - val_loss: 0.6524 - val_max_f1_score: 0.7500\n",
      "Epoch 100/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc_pr: 0.8859 - auc_roc: 0.8892 - loss: 0.4949 - max_f1_score: 0.8357 - val_auc_pr: 0.8244 - val_auc_roc: 0.7987 - val_loss: 0.6527 - val_max_f1_score: 0.7500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# from sklearn.model_selection import StratifiedKFold, KFold, train_test_split\n",
    "idxFolder = r'/home/wuat2/xray-quality/reruns/fastvit_ma36/objects'\n",
    "\n",
    "SEED = 9999 #not needed right now since loading from saved indices; here for consistency\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "numFolds = 5\n",
    "\n",
    "foldHistories = []\n",
    "\n",
    "def format_output(x, y):\n",
    "    y_reshaped = {k: tf.expand_dims(v, axis=-1) for k, v in y.items()}\n",
    "    return x, y_reshaped\n",
    "    \n",
    "for i in range(numFolds): #load the indices for 5 fold CV to ensure consistency\n",
    "    #build training and validation data\n",
    "    trainFileName = f\"fold_{i}_train_indices.arr\"\n",
    "    testFileName = f\"fold_{i}_test_indices.arr\"\n",
    "    trainFilePath = os.path.join(idxFolder, trainFileName)\n",
    "    testFilePath = os.path.join(idxFolder, testFileName)\n",
    "    \n",
    "    archiveTrain = np.load(trainFilePath, allow_pickle=True)\n",
    "    archiveTest = np.load(testFilePath, allow_pickle=True)\n",
    "\n",
    "    pklTrain = archiveTrain[f'fold_{i}_train_indices/data.pkl']\n",
    "    pklTest = archiveTest[f'fold_{i}_test_indices/data.pkl']\n",
    "\n",
    "    trainIdxs = pickle.loads(pklTrain)\n",
    "    testIdxs = pickle.loads(pklTest)\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((features[trainIdxs], {head_name: labels[trainIdxs]}))\n",
    "    train_dataset = train_dataset.shuffle(len(trainIdxs)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((features[testIdxs], {head_name: labels[testIdxs]}))\n",
    "    test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    train_dataset = train_dataset.map(format_output)\n",
    "    test_dataset = test_dataset.map(format_output)\n",
    "\n",
    "    #generate model\n",
    "    tf.keras.backend.clear_session()\n",
    "    foundationMLP = create_model([head_name], token_num=32, embeddings_size=128, dropout=0.3, hidden_layer_sizes=[256, 128], seed=SEED)\n",
    "\n",
    "    history = foundationMLP.fit(\n",
    "        x=train_dataset,\n",
    "        validation_data=test_dataset,\n",
    "        epochs=100,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    raw_probs = foundationMLP.predict(test_dataset)\n",
    "    history.history['int_val_probs'] = raw_probs\n",
    "    history.history['int_val_gts'] = labels[testIdxs]\n",
    "    history.history['int_val_indices'] = testIdxs\n",
    "\n",
    "    foldHistories.append(history)\n",
    "\n",
    "    saveWeightPath = os.path.join(base_dir, 'foundationCXRMLP', f'{i}_CXRWeights.weights.h5')\n",
    "    foundationMLP.save_weights(saveWeightPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5836a925-a3f5-4b26-9871-23c1c0f4a0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "toSaveHistory = False\n",
    "if toSaveHistory:\n",
    "    clean_histories = [h.history for h in foldHistories]\n",
    "    \n",
    "    save_path = os.path.join(base_dir, 'cxrfoundation_train_int_val_fold_histories.pkl')\n",
    "    \n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(clean_histories, f)\n",
    "    \n",
    "    print(f\"Successfully saved histories to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee412344-fe89-47c8-a06c-616c7f8a38ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['auc_pr', 'auc_roc', 'loss', 'max_f1_score', 'val_auc_pr', 'val_auc_roc', 'val_loss', 'val_max_f1_score', 'int_val_probs', 'int_val_gts', 'int_val_indices'])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "loadHistory = True\n",
    "\n",
    "if loadHistory:\n",
    "    load_path = os.path.join(base_dir, 'cxrfoundation_train_int_val_fold_histories.pkl')\n",
    "    \n",
    "    with open(load_path, 'rb') as f:\n",
    "        loaded_histories = pickle.load(f)\n",
    "    \n",
    "    # Access data just like before (but now it's a list of dicts, not History objects)\n",
    "    fold_0_data = loaded_histories[0]\n",
    "    print(loaded_histories[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "01492ff0-82a8-4fd0-b8ce-a55b6376daca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_f1_score(y_true, probs): #fixed to be specific to each fold; takes GT and post-sigmoid confidences as probs\n",
    "    max_f1 = 0\n",
    "    best_thresh = 0\n",
    "\n",
    "    for thresh in np.arange(0.01, 1.01, 0.01):\n",
    "        y_pred = (probs.flatten() > thresh).astype(int)\n",
    "\n",
    "        local_f1 = f1_score(y_true, y_pred)\n",
    "        if local_f1 > max_f1:\n",
    "            max_f1 = local_f1\n",
    "            best_thresh = thresh\n",
    "\n",
    "    return max_f1, best_thresh #maximum score, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3f7d3cf5-6f86-4d60-92cc-ab9f15c1ddfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foundation F1s: , 0.770, 0.017\n",
      "Foundation Accs:, 0.764, 0.021\n"
     ]
    }
   ],
   "source": [
    "foundationF1s = []\n",
    "foundationAccs = []\n",
    "\n",
    "for i in range(5):\n",
    "    # 1. Get raw data\n",
    "    raw_gts = loaded_histories[i]['int_val_gts']\n",
    "    raw_probs = loaded_histories[i]['int_val_probs']['repeatNeeded']\n",
    "    \n",
    "    # 2. Call function (This was already working because you flattened inside the call)\n",
    "    max_f1, best_thresh = max_f1_score(raw_gts, raw_probs)\n",
    "    foundationF1s.append(max_f1)\n",
    "    \n",
    "    # 3. CRITICAL FIX HERE: Flatten both arrays before comparison\n",
    "    # Without .flatten(), (N, 1) > threshold creates (N, 1)\n",
    "    # And if gts is (N,), comparison becomes (N, N) matrix broadcasting!\n",
    "    foundPreds = (raw_probs.flatten() > best_thresh).astype(int)\n",
    "    gts_flat = raw_gts.flatten().astype(int)\n",
    "    \n",
    "    # 4. Calculate Accuracy\n",
    "    foundAccs = (foundPreds == gts_flat).mean()\n",
    "    foundationAccs.append(foundAccs)\n",
    "\n",
    "foundationF1s = np.array(foundationF1s)\n",
    "foundationAccs = np.array(foundationAccs)\n",
    "\n",
    "print(f\"Foundation F1s: , {foundationF1s.mean():.3f}, {foundationF1s.std():.3f}\")\n",
    "print(f\"Foundation Accs:, {foundationAccs.mean():.3f}, {foundationAccs.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ace7aaf-be5e-468a-a221-667c30c9cdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: does not work with history objects. please save and load back in as pkl.\n",
      "Foundation CXR MLP| avg roc auc: 0.824±0.017| avg pr auc: 0.830±0.028| avg sens@spec90: 0.565±0.036| avg spec@sens90: 0.476±0.065\n"
     ]
    }
   ],
   "source": [
    "print(\"NOTE: does not work with history objects. please save and load back in as pkl.\")\n",
    "def val_metrics(y_true, probs, target_value=0.90): # sensitivity at specificity and vice versa and PR/ROC AUCs\n",
    "\n",
    "    fpr, tpr, roc_thresh = roc_curve(y_true, probs)\n",
    "    precision, recall, pr_thresh = precision_recall_curve(y_true, probs)\n",
    "    rocAUC = roc_auc_score(y_true, probs)\n",
    "    prAUC = auc(recall[::-1], precision[::-1]) #need to flip precision and recall to calculate auc\n",
    "    \n",
    "    target_fpr = 1 - target_value\n",
    "    calculated_sensitivity = np.interp(target_fpr, fpr, tpr)\n",
    "\n",
    "    # Ensure monotonicity for finding specificity at sensitivity\n",
    "    tpr_monotonic, idx = np.unique(tpr, return_index=True)\n",
    "    fpr_at_tpr = fpr[idx]\n",
    "    fpr_at_target = np.interp(target_value, tpr_monotonic, fpr_at_tpr)\n",
    "    calculated_specificity = 1 - fpr_at_target\n",
    "\n",
    "    return rocAUC, prAUC, calculated_sensitivity, calculated_specificity\n",
    "\n",
    "foundationMetrics = {'roc auc':[], 'pr auc':[], 'sens@spec90':[], 'spec@sens90':[]}\n",
    "for fold in range(len(loaded_histories)):\n",
    "    rocAUC, prAUC, calculated_sensitivity, calculated_specificity = val_metrics(loaded_histories[fold]['int_val_gts'],loaded_histories[fold]['int_val_probs']['repeatNeeded'])\n",
    "    foundationMetrics['roc auc'].append(rocAUC)\n",
    "    foundationMetrics['pr auc'].append(prAUC)\n",
    "    foundationMetrics['sens@spec90'].append(calculated_sensitivity)\n",
    "    foundationMetrics['spec@sens90'].append(calculated_specificity)\n",
    "    \n",
    "foundationMetrics['roc auc'] = np.array(foundationMetrics['roc auc'])\n",
    "foundationMetrics['pr auc'] = np.array(foundationMetrics['pr auc'])\n",
    "foundationMetrics['sens@spec90'] = np.array(foundationMetrics['sens@spec90'])\n",
    "foundationMetrics['spec@sens90'] = np.array(foundationMetrics['spec@sens90'])\n",
    "\n",
    "print(f\"Foundation CXR MLP| \"\n",
    "      f\"avg roc auc: {foundationMetrics['roc auc'].mean():.3f}±{foundationMetrics['roc auc'].std():.3f}| \"\n",
    "      f\"avg pr auc: {foundationMetrics['pr auc'].mean():.3f}±{foundationMetrics['pr auc'].std():.3f}| \"\n",
    "      f\"avg sens@spec90: {foundationMetrics['sens@spec90'].mean():.3f}±{foundationMetrics['sens@spec90'].std():.3f}| \"\n",
    "      f\"avg spec@sens90: {foundationMetrics['spec@sens90'].mean():.3f}±{foundationMetrics['spec@sens90'].std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6e037d-cbc3-4936-ad7b-38707fb98ead",
   "metadata": {},
   "source": [
    "# External Validation Testing (Zero-Shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10e89f93-8859-4421-976c-1fee7428d934",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.load(r\"/extra/xielab0/wuat2/AryaQualityViewProjectData/ExternalValData/labels.npy\")\n",
    "file_paths = np.load(r\"/extra/xielab0/wuat2/AryaQualityViewProjectData/ExternalValData/file_paths.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bf4e910-e2df-4966-8cf7-6eee53d4e32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extFeatures = []\n",
    "extLabels = [] #should be exactly the same order as the original pytorch dataset\n",
    "\n",
    "head_name = 'repeatNeeded'\n",
    "for imgIdx in range(len(file_paths)):\n",
    "    imageName = os.path.basename(file_paths[imgIdx])\n",
    "    saveName = imageName.replace('.png', '.npy').replace('/', '_')\n",
    "    embeddedDataPath = os.path.join(ext_encoded_dir, saveName)\n",
    "    if os.path.exists(embeddedDataPath):\n",
    "        emb = np.load(embeddedDataPath)\n",
    "        extFeatures.append(emb.flatten())\n",
    "        extLabels.append(dataset.labels[imgIdx])\n",
    "    else:\n",
    "        print(f'data file {embeddedDataPath} cannot be found. Please revise loop logic.')\n",
    "\n",
    "extFeatures = np.array(extFeatures).astype('float32')\n",
    "extLabels = np.array(extLabels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ec78fcf-20ee-43b3-9fb3-5805d5346bb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step\n",
      "Fold corr coeff -- mean: 0.884| std dev: 0.040\n",
      "Model name: CXR Foundation MLP \n",
      "\n",
      "Ext Test ROC AUC: 0.527\n",
      "Ext Test PR AUC: 0.413\n",
      "Ext Test sens @spec90%: 0.032\n",
      "Ext Test spec @sens90%: 0.113\n",
      "                ----------\n"
     ]
    }
   ],
   "source": [
    "SEED = 9999 #not needed right now since loading from saved indices; here for consistency\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "numFolds = 5\n",
    "\n",
    "def format_output(x, y):\n",
    "    y_reshaped = {k: tf.expand_dims(v, axis=-1) for k, v in y.items()}\n",
    "    return x, y_reshaped\n",
    "    \n",
    "foundCXRLogits = np.zeros((len(extLabels),1), dtype=np.float32)\n",
    "foldLogits = []\n",
    "ext_val_dataset = tf.data.Dataset.from_tensor_slices((extFeatures, {head_name: extLabels}))\n",
    "ext_val_dataset = ext_val_dataset.map(format_output)\n",
    "ext_val_dataset = ext_val_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "for i in range(numFolds):\n",
    "    #generate model\n",
    "    tf.keras.backend.clear_session()\n",
    "    #use no activation --> can combine logits later to use sigmoid of average like what was done in pytorch models\n",
    "    \n",
    "    foundationMLP = create_model([head_name], token_num=32, embeddings_size=128, dropout=0.3, hidden_layer_sizes=[256, 128], activation=None, loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),seed=SEED)\n",
    "\n",
    "    weightPath = os.path.join(base_dir, 'foundationCXRMLP', f'{i}_CXRWeights.weights.h5')\n",
    "    foundationMLP.load_weights(weightPath, skip_mismatch=True)\n",
    "\n",
    "    raw_logits = foundationMLP.predict(ext_val_dataset)[head_name]\n",
    "    foundCXRLogits = foundCXRLogits + raw_logits\n",
    "    foldLogits.append(raw_logits)\n",
    "    \n",
    "foundCXRLogits = (foundCXRLogits/5)\n",
    "foundCXRProbs = expit(foundCXRLogits)\n",
    "\n",
    "    # print(history.history.keys())\n",
    "foldSimilarity = []\n",
    "for i in range(5): #correlation analysis between folds\n",
    "    for j in range(i+1, 5):\n",
    "        p_i = expit(foldLogits[i]).flatten()\n",
    "        p_j = expit(foldLogits[j]).flatten()\n",
    "        foldSimilarity.append(np.corrcoef(p_i, p_j)[0,1])\n",
    "foldSimilarity = np.array(foldSimilarity)\n",
    "\n",
    "print(f\"Fold corr coeff -- mean: {foldSimilarity.mean():.3f}| std dev: {foldSimilarity.std():.3f}\")\n",
    "rocAUC, prAUC, sensAtSpec, specAtSens = val_metrics(extLabels, foundCXRProbs, target_value=0.90)\n",
    "\n",
    "print(f\"\"\"Model name: CXR Foundation MLP \\n\n",
    "Ext Test ROC AUC: {rocAUC:.3f}\n",
    "Ext Test PR AUC: {prAUC:.3f}\n",
    "Ext Test sens @spec90%: {sensAtSpec:.3f}\n",
    "Ext Test spec @sens90%: {specAtSens:.3f}\n",
    "                ----------\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ce1f44f-c4c4-41ea-ac53-cc8404643138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting random seed and bootstrapping indices. For reproducibility, only run this ONCE. \n",
      "If accidentally ran again, restart kernel and try again.\n",
      "Bootstrapping indices set.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(f\"\"\"Bootstrapping variable already set (value={needBootStrapping}). Are you sure you didn't already run this?\n",
    "bootstrap indices are stored in 'bootStrapIdxs'.\"\"\")\n",
    "\n",
    "except:\n",
    "    needBootStrapping = True\n",
    "    rng = np.random.default_rng(seed=SEED)\n",
    "    B = 5000\n",
    "    bootStrapIdxs = []\n",
    "    extValSize = len(extLabels)\n",
    "    \n",
    "    if needBootStrapping:\n",
    "        print(\"\"\"setting random seed and bootstrapping indices. For reproducibility, only run this ONCE. \n",
    "If accidentally ran again, restart kernel and try again.\"\"\")\n",
    "        for _ in range(B):\n",
    "            idx = np.random.randint(0, extValSize, extValSize)\n",
    "            while True:\n",
    "                if len(np.unique(extLabels[idx])) == 2:\n",
    "                    break #if samples only have one label, try again\n",
    "                idx = np.random.randint(0, extValSize, extValSize)\n",
    "            bootStrapIdxs.append(idx)\n",
    "        print(\"Bootstrapping indices set.\")\n",
    "    else:\n",
    "        print(\"Bootstrapping not enabled. Remember, only run this ONCE in script for reproducibility.\")\n",
    "    needBootstrapping = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f8649f6-9e6b-46a9-8ca1-6597327cbd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Starting Bootstrapping:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1046088/1579963452.py:14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  bootMetrics = pd.concat([bootMetrics, currMetrics], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocAUC CIs (2.5,97.5): 0.435, 0.621\n",
      "----------\n",
      "prAUC CIs (2.5,97.5): 0.322, 0.521\n",
      "----------\n",
      "sensAtSpec CIs (2.5,97.5): 0.000, 0.164\n",
      "----------\n",
      "specAtSens CIs (2.5,97.5): 0.000, 0.359\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "metricNames = [\"rocAUC\",\"prAUC\",\"sensAtSpec\",\"specAtSens\"]\n",
    "bootMetrics = pd.DataFrame(columns=metricNames)\n",
    "print(f\"----------\\nStarting Bootstrapping:\")\n",
    "for bootNum in range(B):\n",
    "    bootIdx = bootStrapIdxs[bootNum] #indices for this bootstrap\n",
    "    bootLabels = extLabels[bootIdx]\n",
    "    bootProbs = np.zeros(len(bootLabels))\n",
    "    for fold in range(5):\n",
    "        bootProbs = bootProbs + foldLogits[fold].flatten()[bootIdx]\n",
    "    bootProbs = expit(bootProbs/5) #average of the five folds\n",
    "    \n",
    "    rocAUC, prAUC, sensAtSpec, specAtSens = val_metrics(bootLabels, bootProbs, target_value=0.90)\n",
    "    currMetrics = pd.DataFrame([{\"rocAUC\": rocAUC, \"prAUC\": prAUC, \"sensAtSpec\": sensAtSpec, \"specAtSens\": specAtSens}])\n",
    "    bootMetrics = pd.concat([bootMetrics, currMetrics], ignore_index=True)\n",
    "# print(bootMetrics)\n",
    "CIs = pd.DataFrame(columns=metricNames)\n",
    "for metric in metricNames:\n",
    "    lower = np.percentile(bootMetrics[metric], 2.5)\n",
    "    upper = np.percentile(bootMetrics[metric], 97.5)\n",
    "    CIs[metric] = [lower, upper]\n",
    "    print(f\"{metric} CIs (2.5,97.5): {lower:.3f}, {upper:.3f}\\n----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd4cf3c-ddec-4fd4-bf91-b25d77ca548a",
   "metadata": {},
   "source": [
    "# External Validation Testing (Few-Shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1581f51a-a557-4ba4-8db9-c0d25ef71385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extValSet; fewshot_idx shows paths\n",
    "# fewShotResults = torch.load(r'/home/wuat2/xray-quality/external_validation_fewShotResults.pt')\n",
    "# domainAdaptIdxs = fewShotResults[0]['fewshot_idx']\n",
    "# textDAIdxs = fewShotResults[0]['test_idx']\n",
    "\n",
    "labels = np.load(r\"/extra/xielab0/wuat2/AryaQualityViewProjectData/ExternalValData/labels.npy\")\n",
    "file_paths = np.load(r\"/extra/xielab0/wuat2/AryaQualityViewProjectData/ExternalValData/file_paths.npy\")\n",
    "\n",
    "extTuneImgPaths = torch.load(r'/home/wuat2/xray-quality/external_validation_fewShotResults.pt')[0]['fewshot_idx']\n",
    "extTuneLabels = torch.load(r'/home/wuat2/xray-quality/external_validation_fewShotResults.pt')[0]['fewshot_labels']\n",
    "\n",
    "extTestImgPaths = torch.load(r'/home/wuat2/xray-quality/external_validation_fewShotResults.pt')[0]['test_idx']\n",
    "extTestLabels = torch.load(r'/home/wuat2/xray-quality/external_validation_fewShotResults.pt')[0]['test_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef718e31-a330-4ebe-a17c-0042688e4dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fineTuneFeatures = []\n",
    "fineTuneLabels = []\n",
    "fewShowTestFeatures = []\n",
    "fewShotTestLabels = []\n",
    "\n",
    "head_name = 'repeatNeeded'\n",
    "for imgIdx in range(len(extTuneImgPaths)):\n",
    "    imageName = os.path.basename(extTuneImgPaths[imgIdx])\n",
    "    saveName = imageName.replace('.png', '.npy').replace('/', '_')\n",
    "    embeddedDataPath = os.path.join(ext_encoded_dir, saveName)\n",
    "    if os.path.exists(embeddedDataPath):\n",
    "        emb = np.load(embeddedDataPath)\n",
    "        fineTuneFeatures.append(emb.flatten())\n",
    "        fineTuneLabels.append(extTuneLabels[imgIdx])\n",
    "    else:\n",
    "        print(f'data file {embeddedDataPath} cannot be found. Please revise loop logic.')\n",
    "        \n",
    "fineTuneFeatures = np.array(fineTuneFeatures).astype('float32')\n",
    "fineTuneLabels = np.array(fineTuneLabels).astype('float32')\n",
    "\n",
    "for imgIdx in range(len(extTestImgPaths)):\n",
    "    imageName = os.path.basename(extTestImgPaths[imgIdx])\n",
    "    saveName = imageName.replace('.png', '.npy').replace('/', '_')\n",
    "    embeddedDataPath = os.path.join(ext_encoded_dir, saveName)\n",
    "    if os.path.exists(embeddedDataPath):\n",
    "        emb = np.load(embeddedDataPath)\n",
    "        fewShowTestFeatures.append(emb.flatten())\n",
    "        fewShotTestLabels.append(extTestLabels[imgIdx])\n",
    "    else:\n",
    "        print(f'data file {embeddedDataPath} cannot be found. Please revise loop logic.')\n",
    "\n",
    "fewShowTestFeatures = np.array(fewShowTestFeatures).astype('float32')\n",
    "fewShotTestLabels = np.array(fewShotTestLabels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0717cad1-5515-4f34-aae6-5bd6604d7147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Few-Shot Data: 50 training, 100 testing.\n",
      "Starting Fine-Tuning...\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - acc: 0.6692 - auc: 0.7213 - loss: 1.3509 - val_acc: 0.6500 - val_auc: 0.4297 - val_loss: 2.0834\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - acc: 0.6112 - auc: 0.6726 - loss: 1.1780 - val_acc: 0.7200 - val_auc: 0.4891 - val_loss: 2.0562\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - acc: 0.6646 - auc: 0.7815 - loss: 1.0479 - val_acc: 0.7800 - val_auc: 0.5369 - val_loss: 2.1103\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - acc: 0.7508 - auc: 0.8336 - loss: 0.9391 - val_acc: 0.7800 - val_auc: 0.5756 - val_loss: 2.1641\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - acc: 0.7404 - auc: 0.9259 - loss: 0.7214 - val_acc: 0.7800 - val_auc: 0.5925 - val_loss: 2.2172\n",
      "Epoch 6/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - acc: 0.5933 - auc: 0.9207 - loss: 0.8771 - val_acc: 0.7900 - val_auc: 0.5987 - val_loss: 2.2068\n",
      "Epoch 7/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - acc: 0.7613 - auc: 0.9397 - loss: 0.6711 - val_acc: 0.7900 - val_auc: 0.5938 - val_loss: 2.1566\n",
      "Epoch 8/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - acc: 0.7538 - auc: 0.9674 - loss: 0.6392 - val_acc: 0.7900 - val_auc: 0.5891 - val_loss: 2.0963\n",
      "Epoch 9/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - acc: 0.7937 - auc: 0.9720 - loss: 0.5748 - val_acc: 0.7900 - val_auc: 0.5894 - val_loss: 2.0418\n",
      "Epoch 10/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - acc: 0.8012 - auc: 0.9867 - loss: 0.5497 - val_acc: 0.7900 - val_auc: 0.5866 - val_loss: 2.0102\n",
      "Epoch 11/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - acc: 0.8754 - auc: 0.9909 - loss: 0.5175 - val_acc: 0.7900 - val_auc: 0.5941 - val_loss: 1.9893\n",
      "Epoch 12/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.7862 - auc: 0.9678 - loss: 0.6678 - val_acc: 0.7900 - val_auc: 0.6056 - val_loss: 1.9790\n",
      "Epoch 13/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.8487 - auc: 1.0000 - loss: 0.4603 - val_acc: 0.7900 - val_auc: 0.6075 - val_loss: 1.9968\n",
      "Epoch 14/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.8517 - auc: 0.9967 - loss: 0.4719 - val_acc: 0.7700 - val_auc: 0.6034 - val_loss: 2.0381\n",
      "Epoch 15/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.8650 - auc: 0.9975 - loss: 0.4542 - val_acc: 0.7700 - val_auc: 0.6000 - val_loss: 2.0772\n",
      "Epoch 16/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - acc: 0.9125 - auc: 0.9912 - loss: 0.4148 - val_acc: 0.7700 - val_auc: 0.6006 - val_loss: 2.1286\n",
      "Epoch 17/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.8650 - auc: 0.9992 - loss: 0.4550 - val_acc: 0.7800 - val_auc: 0.6041 - val_loss: 2.1881\n",
      "Epoch 18/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.8621 - auc: 0.9841 - loss: 0.5201 - val_acc: 0.7800 - val_auc: 0.6025 - val_loss: 2.2731\n",
      "Epoch 19/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.8754 - auc: 1.0000 - loss: 0.3808 - val_acc: 0.7800 - val_auc: 0.6044 - val_loss: 2.3563\n",
      "Epoch 20/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.8888 - auc: 1.0000 - loss: 0.3285 - val_acc: 0.7700 - val_auc: 0.6069 - val_loss: 2.4398\n",
      "Epoch 21/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.8650 - auc: 1.0000 - loss: 0.3841 - val_acc: 0.7700 - val_auc: 0.6056 - val_loss: 2.5134\n",
      "Epoch 22/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.9125 - auc: 1.0000 - loss: 0.3426 - val_acc: 0.7700 - val_auc: 0.5997 - val_loss: 2.5437\n",
      "Epoch 23/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.9392 - auc: 1.0000 - loss: 0.3737 - val_acc: 0.7700 - val_auc: 0.6025 - val_loss: 2.5069\n",
      "Epoch 24/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.8650 - auc: 0.9789 - loss: 0.4437 - val_acc: 0.7800 - val_auc: 0.6019 - val_loss: 2.4394\n",
      "Epoch 25/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.9392 - auc: 1.0000 - loss: 0.3106 - val_acc: 0.7900 - val_auc: 0.6059 - val_loss: 2.3955\n",
      "Epoch 26/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.9154 - auc: 1.0000 - loss: 0.3260 - val_acc: 0.7900 - val_auc: 0.6100 - val_loss: 2.3712\n",
      "Epoch 27/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.9392 - auc: 0.9964 - loss: 0.3231 - val_acc: 0.7900 - val_auc: 0.6091 - val_loss: 2.3316\n",
      "Epoch 28/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - acc: 0.9392 - auc: 1.0000 - loss: 0.2590 - val_acc: 0.7900 - val_auc: 0.6153 - val_loss: 2.3064\n",
      "Epoch 29/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - acc: 0.9287 - auc: 0.9901 - loss: 0.4136 - val_acc: 0.7900 - val_auc: 0.6125 - val_loss: 2.3035\n",
      "Epoch 30/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.8679 - auc: 0.9983 - loss: 0.3799 - val_acc: 0.7900 - val_auc: 0.6156 - val_loss: 2.3248\n",
      "Evaluating on Test Set...\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step\n",
      "Starting Fine-Tuning...\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - acc: 0.6142 - auc: 0.6018 - loss: 1.3898 - val_acc: 0.5600 - val_auc: 0.4400 - val_loss: 1.7450\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - acc: 0.6217 - auc: 0.6482 - loss: 1.3506 - val_acc: 0.6600 - val_auc: 0.4941 - val_loss: 1.7291\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - acc: 0.6825 - auc: 0.8200 - loss: 0.9468 - val_acc: 0.7300 - val_auc: 0.5150 - val_loss: 1.8217\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - acc: 0.7404 - auc: 0.9583 - loss: 0.6781 - val_acc: 0.7400 - val_auc: 0.5172 - val_loss: 1.8868\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - acc: 0.8175 - auc: 0.9371 - loss: 0.6785 - val_acc: 0.7600 - val_auc: 0.5291 - val_loss: 1.9346\n",
      "Epoch 6/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.7404 - auc: 0.9268 - loss: 0.7124 - val_acc: 0.7700 - val_auc: 0.5494 - val_loss: 1.9377\n",
      "Epoch 7/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.7937 - auc: 0.9210 - loss: 0.7153 - val_acc: 0.7700 - val_auc: 0.5497 - val_loss: 1.9664\n",
      "Epoch 8/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.8279 - auc: 0.9683 - loss: 0.5286 - val_acc: 0.7700 - val_auc: 0.5500 - val_loss: 1.9837\n",
      "Epoch 9/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.7833 - auc: 0.9768 - loss: 0.5847 - val_acc: 0.7600 - val_auc: 0.5591 - val_loss: 1.9392\n",
      "Epoch 10/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.7358 - auc: 0.9880 - loss: 0.5738 - val_acc: 0.7600 - val_auc: 0.5694 - val_loss: 1.8830\n",
      "Epoch 11/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.8012 - auc: 0.9929 - loss: 0.5267 - val_acc: 0.7400 - val_auc: 0.5766 - val_loss: 1.8502\n",
      "Epoch 12/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.8517 - auc: 0.9929 - loss: 0.4387 - val_acc: 0.7400 - val_auc: 0.5841 - val_loss: 1.8333\n",
      "Epoch 13/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.8517 - auc: 0.9853 - loss: 0.4525 - val_acc: 0.7400 - val_auc: 0.5863 - val_loss: 1.8458\n",
      "Epoch 14/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.8413 - auc: 0.9389 - loss: 0.5074 - val_acc: 0.7400 - val_auc: 0.5994 - val_loss: 1.8745\n",
      "Epoch 15/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.8204 - auc: 0.9962 - loss: 0.4195 - val_acc: 0.7500 - val_auc: 0.6069 - val_loss: 1.9418\n",
      "Epoch 16/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.7625 - auc: 0.9371 - loss: 0.6814 - val_acc: 0.7500 - val_auc: 0.6094 - val_loss: 2.0673\n",
      "Epoch 17/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.7492 - auc: 0.9917 - loss: 0.5732 - val_acc: 0.7700 - val_auc: 0.6097 - val_loss: 2.1870\n",
      "Epoch 18/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.8812 - auc: 0.9933 - loss: 0.4735 - val_acc: 0.7800 - val_auc: 0.6041 - val_loss: 2.2792\n",
      "Epoch 19/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.9525 - auc: 1.0000 - loss: 0.3472 - val_acc: 0.7600 - val_auc: 0.5975 - val_loss: 2.3371\n",
      "Epoch 20/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.9496 - auc: 1.0000 - loss: 0.3255 - val_acc: 0.7600 - val_auc: 0.6022 - val_loss: 2.3710\n",
      "Epoch 21/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.8679 - auc: 0.9891 - loss: 0.4506 - val_acc: 0.7600 - val_auc: 0.6103 - val_loss: 2.3874\n",
      "Epoch 22/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.9154 - auc: 1.0000 - loss: 0.3493 - val_acc: 0.7600 - val_auc: 0.5984 - val_loss: 2.4258\n",
      "Epoch 23/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.8071 - auc: 0.9850 - loss: 0.4449 - val_acc: 0.7600 - val_auc: 0.6019 - val_loss: 2.4551\n",
      "Epoch 24/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.9096 - auc: 0.9933 - loss: 0.3568 - val_acc: 0.7600 - val_auc: 0.6034 - val_loss: 2.5046\n",
      "Epoch 25/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.9733 - auc: 1.0000 - loss: 0.2519 - val_acc: 0.7700 - val_auc: 0.6041 - val_loss: 2.5283\n",
      "Epoch 26/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.9762 - auc: 0.9983 - loss: 0.2725 - val_acc: 0.7800 - val_auc: 0.5925 - val_loss: 2.5708\n",
      "Epoch 27/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.8575 - auc: 1.0000 - loss: 0.3727 - val_acc: 0.7800 - val_auc: 0.5784 - val_loss: 2.6029\n",
      "Epoch 28/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.9733 - auc: 1.0000 - loss: 0.2656 - val_acc: 0.7800 - val_auc: 0.5903 - val_loss: 2.6066\n",
      "Epoch 29/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.9525 - auc: 0.9929 - loss: 0.3070 - val_acc: 0.7900 - val_auc: 0.5966 - val_loss: 2.6320\n",
      "Epoch 30/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.9629 - auc: 1.0000 - loss: 0.2500 - val_acc: 0.7900 - val_auc: 0.5962 - val_loss: 2.6580\n",
      "Evaluating on Test Set...\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step\n",
      "Starting Fine-Tuning...\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - acc: 0.5579 - auc: 0.5098 - loss: 1.6279 - val_acc: 0.6700 - val_auc: 0.3847 - val_loss: 2.2583\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - acc: 0.6587 - auc: 0.7759 - loss: 1.0145 - val_acc: 0.7100 - val_auc: 0.4072 - val_loss: 2.2352\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - acc: 0.6483 - auc: 0.8007 - loss: 0.9965 - val_acc: 0.7300 - val_auc: 0.4150 - val_loss: 2.2068\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - acc: 0.6617 - auc: 0.8171 - loss: 0.9744 - val_acc: 0.7400 - val_auc: 0.4359 - val_loss: 2.1821\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - acc: 0.7063 - auc: 0.9120 - loss: 0.8063 - val_acc: 0.7400 - val_auc: 0.4300 - val_loss: 2.1895\n",
      "Epoch 6/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - acc: 0.7746 - auc: 0.8857 - loss: 0.7698 - val_acc: 0.7400 - val_auc: 0.4413 - val_loss: 2.2279\n",
      "Epoch 7/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - acc: 0.7538 - auc: 0.9293 - loss: 0.7187 - val_acc: 0.7300 - val_auc: 0.4678 - val_loss: 2.2573\n",
      "Epoch 8/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.7775 - auc: 0.9767 - loss: 0.5645 - val_acc: 0.7600 - val_auc: 0.4809 - val_loss: 2.2985\n",
      "Epoch 9/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - acc: 0.7225 - auc: 0.9942 - loss: 0.5941 - val_acc: 0.7800 - val_auc: 0.4891 - val_loss: 2.3313\n",
      "Epoch 10/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.7671 - auc: 0.9879 - loss: 0.5693 - val_acc: 0.7800 - val_auc: 0.4934 - val_loss: 2.3489\n",
      "Epoch 11/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.7492 - auc: 0.9850 - loss: 0.5599 - val_acc: 0.7800 - val_auc: 0.4988 - val_loss: 2.3391\n",
      "Epoch 12/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.8071 - auc: 0.9958 - loss: 0.4837 - val_acc: 0.7800 - val_auc: 0.4953 - val_loss: 2.3803\n",
      "Epoch 13/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.8546 - auc: 0.9831 - loss: 0.4901 - val_acc: 0.7800 - val_auc: 0.5006 - val_loss: 2.4038\n",
      "Epoch 14/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.8413 - auc: 0.9929 - loss: 0.4625 - val_acc: 0.7800 - val_auc: 0.5119 - val_loss: 2.4007\n",
      "Epoch 15/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.8308 - auc: 0.9929 - loss: 0.4851 - val_acc: 0.7800 - val_auc: 0.5263 - val_loss: 2.3759\n",
      "Epoch 16/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.9154 - auc: 0.9942 - loss: 0.4320 - val_acc: 0.7900 - val_auc: 0.5337 - val_loss: 2.2950\n",
      "Epoch 17/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.8458 - auc: 0.9834 - loss: 0.4464 - val_acc: 0.7700 - val_auc: 0.5453 - val_loss: 2.2133\n",
      "Epoch 18/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.8754 - auc: 1.0000 - loss: 0.3608 - val_acc: 0.7800 - val_auc: 0.5456 - val_loss: 2.1382\n",
      "Epoch 19/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.8100 - auc: 0.9875 - loss: 0.4800 - val_acc: 0.7800 - val_auc: 0.5575 - val_loss: 2.0527\n",
      "Epoch 20/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.9050 - auc: 1.0000 - loss: 0.3705 - val_acc: 0.7800 - val_auc: 0.5622 - val_loss: 1.9860\n",
      "Epoch 21/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.9287 - auc: 1.0000 - loss: 0.3262 - val_acc: 0.7700 - val_auc: 0.5566 - val_loss: 1.9255\n",
      "Epoch 22/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.8963 - auc: 0.9867 - loss: 0.4014 - val_acc: 0.7500 - val_auc: 0.5578 - val_loss: 1.8792\n",
      "Epoch 23/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.9525 - auc: 1.0000 - loss: 0.2786 - val_acc: 0.7500 - val_auc: 0.5647 - val_loss: 1.8389\n",
      "Epoch 24/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 1.0000 - auc: 1.0000 - loss: 0.2385 - val_acc: 0.7400 - val_auc: 0.5663 - val_loss: 1.8085\n",
      "Epoch 25/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.9629 - auc: 1.0000 - loss: 0.2892 - val_acc: 0.7400 - val_auc: 0.5734 - val_loss: 1.7999\n",
      "Epoch 26/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.9733 - auc: 1.0000 - loss: 0.2732 - val_acc: 0.7500 - val_auc: 0.5772 - val_loss: 1.7795\n",
      "Epoch 27/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.9733 - auc: 1.0000 - loss: 0.2583 - val_acc: 0.7600 - val_auc: 0.5791 - val_loss: 1.7904\n",
      "Epoch 28/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.9392 - auc: 1.0000 - loss: 0.2521 - val_acc: 0.7600 - val_auc: 0.5847 - val_loss: 1.8133\n",
      "Epoch 29/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.9392 - auc: 0.9962 - loss: 0.3041 - val_acc: 0.7600 - val_auc: 0.5891 - val_loss: 1.8672\n",
      "Epoch 30/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.9525 - auc: 1.0000 - loss: 0.2858 - val_acc: 0.7600 - val_auc: 0.5906 - val_loss: 1.9422\n",
      "Evaluating on Test Set...\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step\n",
      "Starting Fine-Tuning...\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - acc: 0.5504 - auc: 0.5727 - loss: 1.5189 - val_acc: 0.7600 - val_auc: 0.3656 - val_loss: 2.3554\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - acc: 0.5608 - auc: 0.6192 - loss: 1.3819 - val_acc: 0.7500 - val_auc: 0.4062 - val_loss: 2.2796\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - acc: 0.7196 - auc: 0.9052 - loss: 0.7770 - val_acc: 0.7700 - val_auc: 0.4469 - val_loss: 2.2294\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - acc: 0.6958 - auc: 0.8349 - loss: 0.8703 - val_acc: 0.7800 - val_auc: 0.4797 - val_loss: 2.2504\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - acc: 0.6646 - auc: 0.7710 - loss: 1.0659 - val_acc: 0.7900 - val_auc: 0.5019 - val_loss: 2.3511\n",
      "Epoch 6/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.7462 - auc: 0.9726 - loss: 0.6152 - val_acc: 0.7900 - val_auc: 0.5034 - val_loss: 2.4655\n",
      "Epoch 7/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - acc: 0.7462 - auc: 0.9387 - loss: 0.6916 - val_acc: 0.7900 - val_auc: 0.5169 - val_loss: 2.5527\n",
      "Epoch 8/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.7462 - auc: 0.9464 - loss: 0.6865 - val_acc: 0.7900 - val_auc: 0.5275 - val_loss: 2.6368\n",
      "Epoch 9/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.8146 - auc: 0.9878 - loss: 0.5462 - val_acc: 0.7900 - val_auc: 0.5206 - val_loss: 2.6892\n",
      "Epoch 10/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.8146 - auc: 0.9911 - loss: 0.5173 - val_acc: 0.7800 - val_auc: 0.5194 - val_loss: 2.7190\n",
      "Epoch 11/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.7908 - auc: 0.9562 - loss: 0.5881 - val_acc: 0.7600 - val_auc: 0.5122 - val_loss: 2.7432\n",
      "Epoch 12/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.9021 - auc: 0.9983 - loss: 0.4289 - val_acc: 0.7700 - val_auc: 0.5084 - val_loss: 2.7398\n",
      "Epoch 13/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.8442 - auc: 0.9967 - loss: 0.4798 - val_acc: 0.7500 - val_auc: 0.5022 - val_loss: 2.7213\n",
      "Epoch 14/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.7671 - auc: 0.9704 - loss: 0.5576 - val_acc: 0.7500 - val_auc: 0.5081 - val_loss: 2.6922\n",
      "Epoch 15/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.8279 - auc: 1.0000 - loss: 0.3818 - val_acc: 0.7500 - val_auc: 0.5059 - val_loss: 2.6531\n",
      "Epoch 16/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.9125 - auc: 0.9879 - loss: 0.4776 - val_acc: 0.7400 - val_auc: 0.5166 - val_loss: 2.5383\n",
      "Epoch 17/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.8812 - auc: 1.0000 - loss: 0.4130 - val_acc: 0.7400 - val_auc: 0.5288 - val_loss: 2.4342\n",
      "Epoch 18/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.8679 - auc: 1.0000 - loss: 0.3775 - val_acc: 0.7300 - val_auc: 0.5359 - val_loss: 2.3498\n",
      "Epoch 19/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.9867 - auc: 1.0000 - loss: 0.2894 - val_acc: 0.7400 - val_auc: 0.5412 - val_loss: 2.3024\n",
      "Epoch 20/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.9050 - auc: 1.0000 - loss: 0.3291 - val_acc: 0.7700 - val_auc: 0.5594 - val_loss: 2.2681\n",
      "Epoch 21/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.8783 - auc: 1.0000 - loss: 0.4196 - val_acc: 0.7800 - val_auc: 0.5697 - val_loss: 2.2079\n",
      "Epoch 22/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.8992 - auc: 0.9866 - loss: 0.3918 - val_acc: 0.7800 - val_auc: 0.5675 - val_loss: 2.1888\n",
      "Epoch 23/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.8858 - auc: 1.0000 - loss: 0.3592 - val_acc: 0.7600 - val_auc: 0.5750 - val_loss: 2.1758\n",
      "Epoch 24/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.9154 - auc: 1.0000 - loss: 0.3139 - val_acc: 0.7500 - val_auc: 0.5784 - val_loss: 2.1827\n",
      "Epoch 25/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.9867 - auc: 1.0000 - loss: 0.2693 - val_acc: 0.7600 - val_auc: 0.5825 - val_loss: 2.1925\n",
      "Epoch 26/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.9392 - auc: 1.0000 - loss: 0.3516 - val_acc: 0.7600 - val_auc: 0.5828 - val_loss: 2.2292\n",
      "Epoch 27/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.9154 - auc: 1.0000 - loss: 0.3174 - val_acc: 0.7600 - val_auc: 0.5841 - val_loss: 2.2606\n",
      "Epoch 28/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.9867 - auc: 1.0000 - loss: 0.2786 - val_acc: 0.7600 - val_auc: 0.5778 - val_loss: 2.3081\n",
      "Epoch 29/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.9733 - auc: 0.9983 - loss: 0.2815 - val_acc: 0.7500 - val_auc: 0.5800 - val_loss: 2.3139\n",
      "Epoch 30/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.8621 - auc: 0.9983 - loss: 0.3425 - val_acc: 0.7500 - val_auc: 0.5897 - val_loss: 2.2703\n",
      "Evaluating on Test Set...\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step\n",
      "Starting Fine-Tuning...\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - acc: 0.5400 - auc: 0.5486 - loss: 1.6631 - val_acc: 0.5900 - val_auc: 0.4084 - val_loss: 2.1652\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.6083 - auc: 0.7628 - loss: 1.0442 - val_acc: 0.6800 - val_auc: 0.4509 - val_loss: 2.1520\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - acc: 0.6008 - auc: 0.7391 - loss: 1.2002 - val_acc: 0.7300 - val_auc: 0.4744 - val_loss: 2.1704\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.6617 - auc: 0.8607 - loss: 0.9007 - val_acc: 0.7500 - val_auc: 0.4966 - val_loss: 2.1752\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.6721 - auc: 0.8627 - loss: 0.9035 - val_acc: 0.7700 - val_auc: 0.5028 - val_loss: 2.1226\n",
      "Epoch 6/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.6825 - auc: 0.9292 - loss: 0.8074 - val_acc: 0.7700 - val_auc: 0.5228 - val_loss: 2.0557\n",
      "Epoch 7/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.7567 - auc: 0.9395 - loss: 0.7084 - val_acc: 0.7400 - val_auc: 0.5272 - val_loss: 1.9973\n",
      "Epoch 8/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.7433 - auc: 0.9506 - loss: 0.6685 - val_acc: 0.7400 - val_auc: 0.5347 - val_loss: 1.9340\n",
      "Epoch 9/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.7567 - auc: 0.9741 - loss: 0.6610 - val_acc: 0.7500 - val_auc: 0.5428 - val_loss: 1.9069\n",
      "Epoch 10/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.8308 - auc: 1.0000 - loss: 0.4812 - val_acc: 0.7500 - val_auc: 0.5528 - val_loss: 1.8622\n",
      "Epoch 11/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.8071 - auc: 0.9858 - loss: 0.5595 - val_acc: 0.7500 - val_auc: 0.5534 - val_loss: 1.8221\n",
      "Epoch 12/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.8621 - auc: 0.9930 - loss: 0.4318 - val_acc: 0.7500 - val_auc: 0.5572 - val_loss: 1.8208\n",
      "Epoch 13/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.8546 - auc: 0.9895 - loss: 0.4680 - val_acc: 0.7500 - val_auc: 0.5594 - val_loss: 1.8394\n",
      "Epoch 14/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.9287 - auc: 1.0000 - loss: 0.3628 - val_acc: 0.7300 - val_auc: 0.5631 - val_loss: 1.8591\n",
      "Epoch 15/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.8812 - auc: 1.0000 - loss: 0.3922 - val_acc: 0.7400 - val_auc: 0.5631 - val_loss: 1.8632\n",
      "Epoch 16/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.8279 - auc: 1.0000 - loss: 0.4268 - val_acc: 0.7400 - val_auc: 0.5581 - val_loss: 1.8805\n",
      "Epoch 17/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - acc: 0.8458 - auc: 0.9967 - loss: 0.4201 - val_acc: 0.7600 - val_auc: 0.5512 - val_loss: 1.9229\n",
      "Epoch 18/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - acc: 0.8812 - auc: 0.9962 - loss: 0.4002 - val_acc: 0.7600 - val_auc: 0.5588 - val_loss: 1.9270\n",
      "Epoch 19/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.8679 - auc: 0.9983 - loss: 0.4456 - val_acc: 0.7700 - val_auc: 0.5578 - val_loss: 1.9541\n",
      "Epoch 20/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.9258 - auc: 0.9967 - loss: 0.3773 - val_acc: 0.7700 - val_auc: 0.5700 - val_loss: 1.9630\n",
      "Epoch 21/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.9496 - auc: 1.0000 - loss: 0.3150 - val_acc: 0.7700 - val_auc: 0.5850 - val_loss: 2.0064\n",
      "Epoch 22/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.9154 - auc: 1.0000 - loss: 0.3474 - val_acc: 0.7700 - val_auc: 0.5997 - val_loss: 2.0476\n",
      "Epoch 23/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - acc: 0.8725 - auc: 1.0000 - loss: 0.3414 - val_acc: 0.7800 - val_auc: 0.6081 - val_loss: 2.0986\n",
      "Epoch 24/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.8679 - auc: 1.0000 - loss: 0.3511 - val_acc: 0.7700 - val_auc: 0.6147 - val_loss: 2.1428\n",
      "Epoch 25/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.9258 - auc: 1.0000 - loss: 0.3451 - val_acc: 0.7700 - val_auc: 0.6191 - val_loss: 2.1407\n",
      "Epoch 26/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - acc: 0.9525 - auc: 1.0000 - loss: 0.2703 - val_acc: 0.7800 - val_auc: 0.6144 - val_loss: 2.1158\n",
      "Epoch 27/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.9525 - auc: 0.9983 - loss: 0.2963 - val_acc: 0.7900 - val_auc: 0.6122 - val_loss: 2.1017\n",
      "Epoch 28/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.9287 - auc: 1.0000 - loss: 0.3399 - val_acc: 0.7900 - val_auc: 0.6194 - val_loss: 2.1067\n",
      "Epoch 29/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.8917 - auc: 1.0000 - loss: 0.3003 - val_acc: 0.7900 - val_auc: 0.6122 - val_loss: 2.1332\n",
      "Epoch 30/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.9050 - auc: 1.0000 - loss: 0.2805 - val_acc: 0.7900 - val_auc: 0.6125 - val_loss: 2.1220\n",
      "Evaluating on Test Set...\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 173ms/step\n",
      "Fold corr coeff -- mean: 0.946| std dev: 0.056\n",
      "========================================\n",
      "Few-Shot Results (50 shots):\n",
      "ROC AUC: 0.608\n",
      "PR AUC:  0.262\n",
      "Sens@Spec90: 0.150\n",
      "Spec@Sens90: 0.275\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# uses a smaller LR and smaller weight decay due to small MLP; original causes it to break\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "POS_WEIGHT = 4.0\n",
    "SEED = 9999\n",
    "\n",
    "fewShotData = torch.load(r'/home/wuat2/xray-quality/external_validation_fewShotResults.pt')[0]\n",
    "\n",
    "print(f\"Preparing Few-Shot Data: {len(fineTuneLabels)} training, {len(fewShotTestLabels)} testing.\")\n",
    "\n",
    "def format_example(x, y):\n",
    "    return x, tf.expand_dims(y, -1)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((fineTuneFeatures, fineTuneLabels))\n",
    "train_ds = train_ds.shuffle(len(fineTuneFeatures)).batch(BATCH_SIZE).map(format_example).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((fewShowTestFeatures, fewShotTestLabels))\n",
    "test_ds = test_ds.batch(BATCH_SIZE).map(format_example).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "foldLogits = []\n",
    "fineTunedLogits = np.zeros((len(fewShotTestLabels),1), dtype=np.float32)\n",
    "for fold in range(5):\n",
    "    finetune_model = create_model(\n",
    "        [head_name], \n",
    "        token_num=32, \n",
    "        embeddings_size=128, \n",
    "        dropout=0.3, \n",
    "        hidden_layer_sizes=[256, 128], \n",
    "        activation=None, # Logits output\n",
    "        seed=SEED\n",
    "    )\n",
    "    weightPath = os.path.join(base_dir, 'foundationCXRMLP', f'{fold}_CXRWeights.weights.h5')\n",
    "    finetune_model.load_weights(weightPath, skip_mismatch=True)\n",
    "    \n",
    "    def weighted_bce_loss(y_true, y_pred):\n",
    "        # y_pred are logits\n",
    "        return tf.nn.weighted_cross_entropy_with_logits(\n",
    "            labels=tf.cast(y_true, tf.float32),\n",
    "            logits=y_pred,\n",
    "            pos_weight=POS_WEIGHT,\n",
    "        )\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.AdamW(\n",
    "        learning_rate=LR, \n",
    "        weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "    \n",
    "    finetune_model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=weighted_bce_loss,\n",
    "        metrics=[\n",
    "            tf.keras.metrics.AUC(name='auc', from_logits=True),\n",
    "            tf.keras.metrics.BinaryAccuracy(name='acc', threshold=0.0) # 0.0 is threshold for logits\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # --- 4. Training Loop ---\n",
    "    print(\"Starting Fine-Tuning...\")\n",
    "    history = finetune_model.fit(\n",
    "        train_ds,\n",
    "        validation_data=test_ds,\n",
    "        epochs=EPOCHS,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # --- 5. Final Evaluation ---\n",
    "    print(\"Evaluating on Test Set...\")\n",
    "    # Predict logits\n",
    "    pred_logits = finetune_model.predict(test_ds)\n",
    "    # Handle dict output if your model returns {head_name: logits}\n",
    "    if isinstance(pred_logits, dict):\n",
    "        pred_logits = pred_logits[head_name]\n",
    "\n",
    "    fineTunedLogits = fineTunedLogits + pred_logits\n",
    "    foldLogits.append(fineTunedLogits)\n",
    "    \n",
    "fineTunedLogits = fineTunedLogits/5\n",
    "fewShotFoundProbs = tf.nn.sigmoid(fineTunedLogits).numpy().flatten()\n",
    "\n",
    "foldSimilarity = []\n",
    "for i in range(5): #correlation analysis between folds\n",
    "    for j in range(i+1, 5):\n",
    "        p_i = expit(foldLogits[i]).flatten()\n",
    "        p_j = expit(foldLogits[j]).flatten()\n",
    "        foldSimilarity.append(np.corrcoef(p_i, p_j)[0,1])\n",
    "foldSimilarity = np.array(foldSimilarity)\n",
    "\n",
    "print(f\"Fold corr coeff -- mean: {foldSimilarity.mean():.3f}| std dev: {foldSimilarity.std():.3f}\")\n",
    "rocAUC, prAUC, sens, spec = val_metrics(fewShotTestLabels, fewShotFoundProbs, target_value=0.90)\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(f\"Few-Shot Results ({len(fineTuneLabels)} shots):\")\n",
    "print(f\"ROC AUC: {rocAUC:.3f}\")\n",
    "print(f\"PR AUC:  {prAUC:.3f}\")\n",
    "print(f\"Sens@Spec90: {sens:.3f}\")\n",
    "print(f\"Spec@Sens90: {spec:.3f}\")\n",
    "print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b3401873-532c-4b17-adfd-29b766053626",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('foundationZeroShotPreds.npy', foundCXRProbs)\n",
    "np.save('foundationFewShotPreds.npy', fewShotFoundProbs)\n",
    "np.save('foundationZeroShotGTs.npy', extLabels)\n",
    "np.save('foundationFewShotGTs.npy', fewShotTestLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1c317da9-2db0-4606-b6f7-cd84d90d1972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting random seed and bootstrapping indices. For reproducibility, only run this ONCE. \n",
      "If accidentally ran again, restart kernel and try again.\n",
      "Bootstrapping indices set.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(f\"\"\"Bootstrapping variable already set (value={needExtValBootStrapping}). Are you sure you didn't already run this?\n",
    "bootstrap indices are stored in 'bootExtValStrapIdxs'.\"\"\")\n",
    "\n",
    "except:\n",
    "    needExtValBootStrapping = True\n",
    "    rng = np.random.default_rng(seed=SEED)\n",
    "    B = 5000\n",
    "    bootExtValStrapIdxs = []\n",
    "    extValSize = len(fewShotTestLabels)\n",
    "    \n",
    "    if needExtValBootStrapping:\n",
    "        print(\"\"\"setting random seed and bootstrapping indices. For reproducibility, only run this ONCE. \n",
    "If accidentally ran again, restart kernel and try again.\"\"\")\n",
    "        for _ in range(B):\n",
    "            idx = np.random.randint(0, extValSize, extValSize)\n",
    "            while True:\n",
    "                if len(np.unique(fewShotTestLabels[idx])) == 2:\n",
    "                    break #if samples only have one label, try again\n",
    "                idx = np.random.randint(0, extValSize, extValSize)\n",
    "            bootExtValStrapIdxs.append(idx)\n",
    "        print(\"needExtValBootStrapping indices set.\")\n",
    "    else:\n",
    "        print(\"needExtValBootStrapping not enabled. Remember, only run this ONCE in script for reproducibility.\")\n",
    "    needExtValBootStrapping = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4a0a578a-681c-4d4c-8660-1a1f6ccdbf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Starting Bootstrapping:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1046088/3985776196.py:14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  bootMetrics = pd.concat([bootMetrics, currMetrics], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocAUC CIs (2.5,97.5): 0.460, 0.739\n",
      "----------\n",
      "prAUC CIs (2.5,97.5): 0.142, 0.446\n",
      "----------\n",
      "sensAtSpec CIs (2.5,97.5): 0.000, 0.435\n",
      "----------\n",
      "specAtSens CIs (2.5,97.5): 0.150, 0.462\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "metricNames = [\"rocAUC\",\"prAUC\",\"sensAtSpec\",\"specAtSens\"]\n",
    "bootMetrics = pd.DataFrame(columns=metricNames)\n",
    "print(f\"----------\\nStarting Bootstrapping:\")\n",
    "for bootNum in range(B):\n",
    "    bootIdx = bootExtValStrapIdxs[bootNum] #indices for this bootstrap\n",
    "    bootLabels = fewShotTestLabels[bootIdx]\n",
    "    bootProbs = np.zeros(len(bootLabels))\n",
    "    for fold in range(5):\n",
    "        bootProbs = bootProbs + foldLogits[fold].flatten()[bootIdx]\n",
    "    bootProbs = expit(bootProbs/5) #average of the five folds\n",
    "    \n",
    "    rocAUC, prAUC, sensAtSpec, specAtSens = val_metrics(bootLabels, bootProbs, target_value=0.90)\n",
    "    currMetrics = pd.DataFrame([{\"rocAUC\": rocAUC, \"prAUC\": prAUC, \"sensAtSpec\": sensAtSpec, \"specAtSens\": specAtSens}])\n",
    "    bootMetrics = pd.concat([bootMetrics, currMetrics], ignore_index=True)\n",
    "# print(bootMetrics)\n",
    "CIs = pd.DataFrame(columns=metricNames)\n",
    "for metric in metricNames:\n",
    "    lower = np.percentile(bootMetrics[metric], 2.5)\n",
    "    upper = np.percentile(bootMetrics[metric], 97.5)\n",
    "    CIs[metric] = [lower, upper]\n",
    "    print(f\"{metric} CIs (2.5,97.5): {lower:.3f}, {upper:.3f}\\n----------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
